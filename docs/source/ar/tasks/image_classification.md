# ุชุตููู ุงูุตูุฑ

[[open-in-colab]]

<Youtube id="tjAIM7BOYhw"/>

ูููู ุชุตููู ุงูุตูุฑ ุจุชุนููู ุชุณููุฉ ุฃู ูุฆุฉ ูุตูุฑุฉ. ุนูู ุนูุณ ุชุตููู ุงููุต ุฃู ุงูุตูุชุ ุชููู ุงููุฏุฎูุงุช ูู ููู ุงูุจูุณู ุงูุชู ุชุชููู ูููุง ุงูุตูุฑุฉ. ููุงู ุงูุนุฏูุฏ ูู ุงูุชุทุจููุงุช ูุชุตููู ุงูุตูุฑุ ูุซู ุงููุดู ุนู ุงูุฃุถุฑุงุฑ ุจุนุฏ ูุงุฑุซุฉ ุทุจูุนูุฉุ ุฃู ูุฑุงูุจุฉ ุตุญุฉ ุงููุญุงุตููุ ุฃู ุงููุณุงุนุฏุฉ ูู ูุญุต ุงูุตูุฑ ุงูุทุจูุฉ ููุจุญุซ ุนู ุนูุงูุงุช ุงููุฑุถ.

ููุถุญ ูุฐุง ุงูุฏููู ููููุฉ:

1. ุถุจุท ูููุฐุฌ [ViT](model_doc/vit) ุงูุฏููู ุนูู ูุฌููุนุฉ ุจูุงูุงุช [Food-101](https://huggingface.co/datasets/food101) ูุชุตููู ุนูุตุฑ ุบุฐุงุฆู ูู ุตูุฑุฉ.
2. ุงุณุชุฎุฏุงู ูููุฐุฌู ุงูุฏููู ููุงุณุชูุชุงุฌ.

<Tip>

ูุฑุคูุฉ ุฌููุน ุงูุจูู ูููุงุท ุงูุชูุชูุด ุงููุชูุงููุฉ ูุน ูุฐู ุงููููุฉุ ููุตู ุจุงูุชุญูู ูู [ุตูุญุฉ ุงููููุฉ](https://huggingface.co/tasks/image-classification)

</Tip>

ูุจู ุงูุจุฏุกุ ุชุฃูุฏ ูู ุชุซุจูุช ุฌููุน ุงูููุชุจุงุช ุงูุถุฑูุฑูุฉ:

```bash
pip install transformers datasets evaluate accelerate pillow torchvision scikit-learn
```

ูุญู ูุดุฌุนู ุนูู ุชุณุฌูู ุงูุฏุฎูู ุฅูู ุญุณุงุจ Hugging Face ุงูุฎุงุต ุจู ูุชุญููู ููุดุงุฑูุฉ ูููุฐุฌู ูุน ุงููุฌุชูุน. ุนูุฏูุง ููุทูุจ ููู ุฐููุ ุฃุฏุฎู ุฑูุฒู ููุชุณุฌูู:

```py
>>> from huggingface_hub import notebook_login

>>> notebook_login()
```

## ุชุญููู ูุฌููุนุฉ ุจูุงูุงุช Food-101

ุงุจุฏุฃ ุจุชุญููู ุฌุฒุก ูุฑุนู ุฃุตุบุฑ ูู ูุฌููุนุฉ ุจูุงูุงุช Food-101 ูู ููุชุจุฉ Datasets ๐ค. ุณูุนุทูู ูุฐุง ูุฑุตุฉ ูุชุฌุฑุจุฉ ูุงูุชุฃูุฏ ูู ุฃู ูู ุดูุก ูุนูู ูุจู ูุถุงุก ุงููุฒูุฏ ูู ุงูููุช ูู ุงูุชุฏุฑูุจ ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงููุงููุฉ.

```py
>>> from datasets import load_dataset

>>> food = load_dataset("food101", split="train[:5000]")
```

ูุณููู ูุฌููุนุฉ ุงูุจูุงูุงุช ุฅูู ูุฌููุนุชูู ูุฑุนูุชูู ููุชุฏุฑูุจ ูุงูุงุฎุชุจุงุฑ ุจุงุณุชุฎุฏุงู ุทุฑููุฉ [`~datasets.Dataset.train_test_split`]:

```py
>>> food = food.train_test_split(test_size=0.2)
```

ุซู ุงูู ูุธุฑุฉ ุนูู ูุซุงู:

```py
>>> food["train"][0]
{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=512x512 at 0x7F52AFC8AC50>,
 'label': 79}
```

ูุญุชูู ูู ูุซุงู ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุนูู ุญูููู:

- `image`: ุตูุฑุฉ PIL ูุตูู ุงูุทุนุงู
- `label`: ูุฆุฉ ุงูุชุณููุฉ ูุตูู ุงูุทุนุงู

ููุชุณููู ุงูุฃูุฑ ุนูู ุงููููุฐุฌ ููุญุตูู ุนูู ุงุณู ุงูุชุณููุฉ ูู ูุนุฑู ุงูุชุณููุฉุ ูู ุจุฅูุดุงุก ูุงููุณ ูููู ุจุชุนููู ุงุณู ุงูุชุณููุฉ ุฅูู ุฑูู ุตุญูุญ ูุงูุนูุณ ุตุญูุญ:

```py
>>> labels = food["train"].features["label"].names
>>> label2id, id2label = dict(), dict()
>>> for i, label in enumerate(labels):
...     label2id[label] = str(i)
...     id2label[str(i)] = label
```

ุงูุขู ููููู ุชุญููู ูุนุฑู ุงูุชุณููุฉ ุฅูู ุงุณู ุงูุชุณููุฉ:

```py
>>> id2label[str(79)]
'prime_rib'
```

## ูุนุงูุฌุฉ ูุณุจูุฉ

ุงูุฎุทูุฉ ุงูุชุงููุฉ ูู ุชุญููู ูุนุงูุฌ ุตูุฑ ViT ููุนุงูุฌุฉ ุงูุตูุฑุฉ ุฅูู Tensor:

```py
>>> from transformers import AutoImageProcessor

>>> checkpoint = "google/vit-base-patch16-224-in21k"
>>> image_processor = AutoImageProcessor.from_pretrained(checkpoint)
```

<frameworkcontent>
<pt>
ุชุทุจูู ุจุนุถ ุงูุชุญููุงุช ุนูู ุงูุตูุฑ ูุฌุนู ุงููููุฐุฌ ุฃูุซุฑ ููุฉ ุถุฏ ุงูุฅูุฑุงุท ูู ุงูุชูููู. ููุง ุณุชุณุชุฎุฏู ูุญุฏุฉ [`transforms`](https://pytorch.org/vision/stable/transforms.html) ูู torchvisionุ ูููู ููููู ุฃูุถูุง ุงุณุชุฎุฏุงู ุฃู ููุชุจุฉ ุตูุฑ ุชูุถููุง.

ุงูุชุต ุฌุฒุกูุง ุนุดูุงุฆููุง ูู ุงูุตูุฑุฉุ ููู ุจุชุบููุฑ ุญุฌููุงุ ููู ุจุชุทุจูุนูุง ุจุงุณุชุฎุฏุงู ูุชูุณุท ุงูุตูุฑุฉ ูุงูุงูุญุฑุงู ุงููุนูุงุฑู:

```py
>>> from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor
Crop a random part of the image, resize it, and normalize it with the image mean and standard deviation:

```py
>>> from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor

>>> normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)
>>> size = (
...     image_processor.size["shortest_edge"]
...     if "shortest_edge" in image_processor.size
...     else (image_processor.size["height"], image_processor.size["width"])
... )
>>> _transforms = Compose([RandomResizedCrop(size), ToTensor(), normalize])
```

ุซู ูู ุจุฅูุดุงุก ุฏุงูุฉ ูุนุงูุฌุฉ ูุณุจูุฉ ูุชุทุจูู ุงูุชุญููุงุช ูุฅุฑุฌุงุน `pixel_values` - ุงููุฏุฎูุงุช ุฅูู ุงููููุฐุฌ - ููุตูุฑุฉ:

```py
>>> def transforms(examples):
...     examples["pixel_values"] = [_transforms(img.convert("RGB")) for img in examples["image"]]
...     del examples["image"]
...     return examples
```

ูุชุทุจูู ุฏุงูุฉ ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุจุฃููููุงุ ุงุณุชุฎุฏู ุทุฑููุฉ [`~datasets.Dataset.with_transform`] ูู ููุชุจุฉ ๐ค Datasets. ูุชู ุชุทุจูู ุงูุชุญููุงุช ุฃุซูุงุก ุงูุชููู ุนูุฏ ุชุญููู ุนูุตุฑ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช:

```py
>>> food = food.with_transform(transforms)
```

ุงูุขู ูู ุจุฅูุดุงุก ุฏูุนุฉ ูู ุงูุฃูุซูุฉ ุจุงุณุชุฎุฏุงู [`DefaultDataCollator`]. ุนูู ุนูุณ ุจุฑุงูุฌ ุงูุฌูุน ุงูุฃุฎุฑู ููุจูุงูุงุช ูู ููุชุจุฉ ๐ค Transformersุ ูุง ูุทุจู `DefaultDataCollator` ูุนุงูุฌุฉ ูุณุจูุฉ ุฅุถุงููุฉ ูุซู ุงูุชูุณูุฏ.

```py
>>> from transformers import DefaultDataCollator

>>> data_collator = DefaultDataCollator()
```
</pt>
</frameworkcontent>


<frameworkcontent>
<tf>

ูุชุฌูุจ ุงูุฅูุฑุงุท ูู ุงูุชูููู ูุฌุนู ุงููููุฐุฌ ุฃูุซุฑ ููุฉุ ุฃุถู ุจุนุถ ุงูุชุนุฒูุฒุงุช ููุจูุงูุงุช ุฅูู ุงูุฌุฒุก ุงูุชุฏุฑูุจู ูู ูุฌููุนุฉ ุงูุจูุงูุงุช.
ููุง ูุณุชุฎุฏู ุทุจูุงุช ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ูู Keras ูุชุญุฏูุฏ ุงูุชุญููุงุช ูุจูุงูุงุช ุงูุชุฏุฑูุจ (ุจูุง ูู ุฐูู ุชุนุฒูุฒ ุงูุจูุงูุงุช)ุ
ูุงูุชุญููุงุช ูุจูุงูุงุช ุงูุชุญูู (ุงูุงูุชุตุงุต ุงููุฑูุฒู ููุทุ ุชุบููุฑ ุงูุญุฌู ูุงูุชุทุจูุน). ููููู ุงุณุชุฎุฏุงู `tf.image` ุฃู
ุฃู ููุชุจุฉ ุฃุฎุฑู ุชูุถููุง.

```py
>>> from tensorflow import keras
>>> from tensorflow.keras import layers

>>> size = (image_processor.size["height"], image_processor.size["width"])

>>> train_data_augmentation = keras.Sequential(
...     [
...         layers.RandomCrop(size[0], size[1]),
...         layers.Rescaling(scale=1.0 / 127.5, offset=-1),
...         layers
...     ],
...     name="train_data_augmentation",
... )

>>> val_data_augmentation = keras.Sequential(
...     [
...         layers.CenterCrop(size[0], size[1]),
...         layers.Rescaling(scale=1.0 / 127.5, offset=-1),
...     ],
...     name="val_data_augmentation",
... )
```

ุจุนุฏ ุฐููุ ูู ุจุฅูุดุงุก ูุธุงุฆู ูุชุทุจูู ุงูุชุญููุงุช ุงูููุงุณุจุฉ ุนูู ุฏูุนุฉ ูู ุงูุตูุฑุ ุจุฏูุงู ูู ุตูุฑุฉ ูุงุญุฏุฉ ูู ูู ูุฑุฉ.

```py
>>> import numpy as np
>>> import tensorflow as tf
>>> from PIL import Image


>>> def convert_to_tf_tensor(image: Image):
...     np_image = np.array(image)
...     tf_image = tf.convert_to_tensor(np_image)
...     # `expand_dims()` is used to add a batch dimension since
...     # the TF augmentation layers operates on batched inputs.
...     return tf.expand_dims(tf_image, 0)


>>> def preprocess_train(example_batch):
...     """Apply train_transforms across a batch."""
...     images = [
...         train_data_augmentation(convert_to_tf_tensor(image.convert("RGB"))) for image in example_batch["image"]
...     ]
...     example_batch["pixel_values"] = [tf.transpose(tf.squeeze(image)) for image in images]
...     return example_batch


... def preprocess_val(example_batch):
...     """Apply val_transforms across a batch."""
...     images = [
...         val_data_augmentation(convert_to_tf_tensor(image.convert("RGB"))) for image in example_batch["image"]
...     ]
...     example_batch["pixel_values"] = [tf.transpose(tf.squeeze(image)) for image in images]
...     return example_batch
```

ุงุณุชุฎุฏู ุทุฑููุฉ [`~datasets.Dataset.set_transform`] ูู ููุชุจุฉ ๐ค Datasets ูุชุทุจูู ุงูุชุญููุงุช ุฃุซูุงุก ุงูุชููู:
Use ๐ค Datasets [`~datasets.Dataset.set_transform`] to apply the transformations on the fly:

```py
food["train"].set_transform(preprocess_train)
food["test"].set_transform(preprocess_val)
```

ูุฎุทูุฉ ูุนุงูุฌุฉ ูุณุจูุฉ ููุงุฆูุฉุ ูู ุจุฅูุดุงุก ุฏูุนุฉ ูู ุงูุฃูุซูุฉ ุจุงุณุชุฎุฏุงู `DefaultDataCollator`. ุนูู ุนูุณ ุจุฑุงูุฌ ุงูุฌูุน ุงูุฃุฎุฑู ููุจูุงูุงุช ูู ููุชุจุฉ ๐ค Transformersุ ูุฅู
`DefaultDataCollator` ูุง ูุทุจู ูุนุงูุฌุฉ ูุณุจูุฉ ุฅุถุงููุฉุ ูุซู ุงูุชูุณูุฏ.

```py
>>> from transformers import DefaultDataCollator

>>> data_collator = DefaultDataCollator(return_tensors="tf")
```
</tf>
</frameworkcontent>

## ุชูููู

ุบุงูุจูุง ูุง ูููู ุชุถููู ูููุงุณ ุฃุซูุงุก ุงูุชุฏุฑูุจ ูููุฏูุง ูุชูููู ุฃุฏุงุก ูููุฐุฌู. ููููู ุชุญููู ุทุฑููุฉ ุชูููู ุจุณุฑุนุฉ ุจุงุณุชุฎุฏุงู ููุชุจุฉ ๐ค [Evaluate](https://huggingface.co/docs/evaluate/index). ุจุงููุณุจุฉ ููุฐู ุงููููุฉุ ูู ุจุชุญููู
ูููุงุณ [ุงูุฏูุฉ](https://huggingface.co/spaces/evaluate-metric/accuracy) (ุฑุงุฌุน ุฌููุฉ ๐ค Evaluate [ุงูุณุฑูุนุฉ](https://huggingface.co/docs/evaluate/a_quick_tour) ููุนุฑูุฉ ุงููุฒูุฏ ุญูู ููููุฉ ุชุญููู ูุญุณุงุจ ูููุงุณ):

```py
>>> import evaluate

>>> accuracy = evaluate.load("accuracy")
```

ุซู ูู ุจุฅูุดุงุก ุฏุงูุฉ ุชูุฑุฑ ุชูุจุคุงุชู ูุชุณููุงุชู ุฅูู [`~evaluate.EvaluationModule.compute`] ูุญุณุงุจ ุงูุฏูุฉ:

```py
>>> import numpy as np


>>> def compute_metrics(eval_pred):
...     predictions, labels = eval_pred
...     predictions = np.argmax(predictions, axis=1)
...     return accuracy.compute(predictions=predictions, references=labels)
```

ูุธููุชู `compute_metrics` ุฌุงูุฒุฉ ุงูุขูุ ูุณุชุนูุฏ ุฅูููุง ุนูุฏูุง ุชููู ุจุฅุนุฏุงุฏ ุชุฏุฑูุจู.

## ุชุฏุฑูุจ

<frameworkcontent>
<pt>
<Tip>

ุฅุฐุง ูู ุชูู ุนูู ุฏุฑุงูุฉ ุจุถุจุท ูููุฐุฌ ุจุงุณุชุฎุฏุงู [`Trainer`ุ ูุฑุงุฌุน ุงูุจุฑูุงูุฌ ุงูุชุนูููู ุงูุฃุณุงุณู [ููุง](../training#train-with-pytorch-trainer)!

</Tip>

ุฃูุช ูุณุชุนุฏ ุงูุขู ูุจุฏุก ุชุฏุฑูุจ ูููุฐุฌู! ูู ุจุชุญููู ViT ุจุงุณุชุฎุฏุงู [`AutoModelForImageClassification`]. ุญุฏุฏ ุนุฏุฏ ุงูุชุณููุงุช ุฅูู ุฌุงูุจ ุนุฏุฏ ุงูุชุณููุงุช ุงููุชููุนุฉุ ูุฎุฑุงุฆุท ุงูุชุณููุงุช:

```py
>>> from transformers import AutoModelForImageClassification, TrainingArguments, Trainer

>>> model = AutoModelForImageClassification.from_pretrained(
...     checkpoint,
...     num_labels=len(labels),
...     id2label=id2label,
...     label2id=label2id,
... )
```

ูู ูุฐู ุงููุฑุญูุฉุ ููุงู ุซูุงุซ ุฎุทูุงุช ููุท:

1. ุญุฏุฏ ูุฑุท ูุนููุงุช ุงูุชุฏุฑูุจ ุงูุฎุงุตุฉ ุจู ูู [`TrainingArguments`]. ูู ุงูููู ุฃูุง ุชููู ุจุฅุฒุงูุฉ ุงูุฃุนูุฏุฉ ุบูุฑ ุงููุณุชุฎุฏูุฉ ูุฃู ุฐูู ุณูุคุฏู ุฅูู ุฅุณูุงุท ุนููุฏ "ุงูุตูุฑุฉ". ุจุฏูู ุนููุฏ "ุงูุตูุฑุฉ"ุ ูุง ููููู ุฅูุดุงุก "pixel_values". ูู ุจุชุนููู `remove_unused_columns=False` ูููุน ูุฐุง ุงูุณููู! ุงููุนููุฉ ุงููุทููุจุฉ ุงููุญูุฏุฉ ูู `output_dir` ุงูุชู ุชุญุฏุฏ ุฃูู ูุชู ุญูุธ ูููุฐุฌู. ุณุชููู ุจุงูุฏูุน ุจูุฐุง ุงููููุฐุฌ ุฅูู Hub ุนู ุทุฑูู ุชุนููู `push_to_hub=True` (ูุฌุจ ุฃู ุชููู ูุณุฌูุงู ุงูุฏุฎูู ุฅูู Hugging Face ูุชุญููู ูููุฐุฌู). ูู ููุงูุฉ ูู ุญูุจุฉุ ุณูููู [`Trainer`] ุจุชูููู ุงูุฏูุฉ ูุญูุธ ููุทุฉ ุชูุชูุด ุงูุชุฏุฑูุจ.
2. ูู ุจุชูุฑูุฑ ูุฑุท ูุนููุงุช ุงูุชุฏุฑูุจ ุฅูู [`Trainer`] ุฅูู ุฌุงูุจ ุงููููุฐุฌ ููุฌููุนุฉ ุงูุจูุงูุงุช ููุนุงูุฌ ุงูุฑููุฒ ููุจุฑูุฌ ุงูุจูุงูุงุช ููุธููุฉ `compute_metrics`.
3. ุงุณุชุฏุนุงุก [`~Trainer.train`] ูุถุจุท ูููุฐุฌู ุจุดูู ุฏููู.

```py
>>> training_args = TrainingArguments(
...     output_dir="my_awesome_food_model",
...     remove_unused_columns=False,
...     eval_strategy="epoch"ุ
...     save_strategy="epoch"ุ
...     learning_rate=5e-5,
...     per_device_train_batch_size=16,
...     gradient_accumulation_steps=4,
...     per_device_eval_batch_size=16,
...     num_train_epochs=3,
...     warmup_ratio=0.1,
...     logging_steps=10,
...     load_best_model_at_end=True,
...     metric_for_best_model="accuracy"ุ
...     push_to_hub=True,
... )

>>> trainer = Trainer(
...     model=model,
...     args=training_args,
...     data_collator=data_collator,
...     train_dataset=food["train"]
...     eval_dataset=food["test"]
...     tokenizer=image_processor,
...     compute_metrics=compute_metrics,
... )

>>> trainer.train()
```

ุจูุฌุฑุฏ ุงูุชูุงู ุงูุชุฏุฑูุจุ ุดุงุฑู ูููุฐุฌู ุนูู Hub ุจุงุณุชุฎุฏุงู ุทุฑููุฉ [`~transformers.Trainer.push_to_hub`]:

```py
>>> trainer.push_to_hub()
```
</pt>
</frameworkcontent>

<frameworkcontent>
<tf>

<Tip>

ุฅุฐุง ููุช ุบูุฑ ูุนุชุงุฏ ุนูู ุถุจุท ูููุฐุฌ ุจุงุณุชุฎุฏุงู Kerasุ ูุฑุงุฌุน [ุงูุจุฑูุงูุฌ ุงูุชุนูููู ุงูุฃุณุงุณู](./training#train-a-tensorflow-model-with-keras) ุฃููุงู!

</Tip>

ูุถุจุท ูููุฐุฌ ูู TensorFlowุ ุงุชุจุน ุงูุฎุทูุงุช ุงูุชุงููุฉ:
1. ุญุฏุฏ ูุฑุท ูุนููุงุช ุงูุชุฏุฑูุจุ ููู ุจุฅุนุฏุงุฏ ูุซุงูููุง ููุนุฏู ุชุนูู ุฌุฏูู.
2. ูู ุจุชุญููู ูููุฐุฌ ูุณุจู ุงูุชุฏุฑูุจ.
3. ูู ุจุชุญููู ูุฌููุนุฉ ุจูุงูุงุช ๐ค ุฅูู ุชูุณูู `tf.data.Dataset`.
4. ูู ุจุชุฌููุน ูููุฐุฌู.
5. ุฃุถู ุงุณุชุฏุนุงุกุงุช ุงูุฅุฑุฌุงุน ูุงุณุชุฎุฏู ุทุฑููุฉ `fit()` ูุชุดุบูู ุงูุชุฏุฑูุจ.
6. ูู ุจุชุญููู ูููุฐุฌู ุฅูู ๐ค Hub ููุดุงุฑูุชู ูุน ุงููุฌุชูุน.

ุงุจุฏุฃ ุจุชุญุฏูุฏ ูุฑุท ูุนููุงุชูุ ููุซุงูููุง ููุนุฏู ุงูุชุนูู:

```py
>>> from transformers import create_optimizer

>>> batch_size = 16
>>> num_epochs = 5
>>> num_train_steps = len(food["train"]) * num_epochs
>>> learning_rate = 3e-5
>>> weight_decay_rate = 0.01

>>> optimizer, lr_schedule = create_optimizer(
...     init_lr=learning_rate,
...     num_train_steps=num_train_steps,
...     weight_decay_rate=weight_decay_rate,
...     num_warmup_steps=0,
... )
```

ุจุนุฏ ุฐููุ ูู ุจุชุญููู ViT ุจุงุณุชุฎุฏุงู [`TFAutoModelForImageClassification`] ุฅูู ุฌุงูุจ ุฎุฑุงุฆุท ุงูุชุณููุงุช:

```py
>>> from transformers import TFAutoModelForImageClassification

>>> model = TFAutoModelForImageClassification.from_pretrained(
...     checkpoint,
...     id2label=id2label,
...     label2id=label2id,
... )
```

ูู ุจุชุญููู ูุฌููุนุงุช ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจู ุฅูู ุชูุณูู `tf.data.Dataset` ุจุงุณุชุฎุฏุงู [`~datasets.Dataset.to_tf_dataset`] ูุจุฑูุงูุฌ ุงูุชุฌููุน ุงูุฎุงุต ุจู `data_collator`:

```py
>>> # converting our train dataset to tf.data.Dataset
>>> tf_train_dataset = food["train"].to_tf_dataset(
...     columns="pixel_values"ุ label_cols="label"ุ shuffle=Trueุ batch_size=batch_sizeุ collate_fn=data_collator
... )

>>> # converting our test dataset to tf.data.Dataset
>>> tf_eval_dataset = food["test"].to_tf_dataset(
...     columns="pixel_values"ุ label_cols="label"ุ shuffle=Trueุ batch_size=batch_sizeุ collate_fn=data_collator
... )
```

ูู ุจุชูููู ุงููููุฐุฌ ููุชุฏุฑูุจ ุจุงุณุชุฎุฏุงู `compile()`


```py
>>> from tensorflow.keras.losses import SparseCategoricalCrossentropy

>>> loss = tf.keras.lossetrops.SparseCategoricalCrosseny(from_logits=True)
>>> model.compile(optimizer=optimizer, loss=loss)
```

ูุญุณุงุจ ุงูุฏูุฉ ูู ุงูุชููุนุงุช ูุฏูุน ูููุฐุฌู ุฅูู ๐ค Hubุ ุงุณุชุฎุฏู [Keras callbacks](../main_classes/keras_callbacks).
ูุฑุฑ ุฏุงูุชู `compute_metrics` ุฅูู [KerasMetricCallback](../main_classes/keras_callbacks#transformers.KerasMetricCallback)ุ
ูุงุณุชุฎุฏู [PushToHubCallback](../main_classes/keras_callbacks#transformers.PushToHubCallback) ูุชุญููู ุงููููุฐุฌ:

```py
>>> from transformers.keras_callbacks import KerasMetricCallback, PushToHubCallback

>>> metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_eval_dataset)
>>> push_to_hub_callback = PushToHubCallback(
...     output_dir="food_classifier",
...     tokenizer=image_processor,
...     save_strategy="no",
... )
>>> callbacks = [metric_callback, push_to_hub_callback]
```

ุฃุฎูุฑูุงุ ุฃูุช ูุณุชุนุฏ ูุชุฏุฑูุจ ูููุฐุฌู! ุงุณุชุฏุน `fit()` ุจุงุณุชุฎุฏุงู ูุฌููุนุงุช ุงูุจูุงูุงุช ุงูุชุฏุฑูุจูุฉ ูุงูุชุญูู ูู ุงูุตุญุฉ ุงูุฎุงุตุฉ ุจูุ ูุนุฏุฏ ุงูุนุตูุฑุ
ูุงูุงุณุชุฏุนุงุกุงุช ุงูุฎุงุตุฉ ุจู ูุถุจุท ูููุฐุฌู ุจุฏูุฉ:

```py
>>> model.fit(tf_train_dataset, validation_data=tf_eval_dataset, epochs=num_epochs, callbacks=callbacks)
Epoch 1/5
250/250 [==============================] - 313s 1s/step - loss: 2.5623 - val_loss: 1.4161 - accuracy: 0.9290
Epoch 2/5
250/250 [==============================] - 265s 1s/step - loss: 0.9181 - val_loss: 0.6808 - accuracy: 0.9690
Epoch 3/5
250/250 [==============================] - 252s 1s/step - loss: 0.3910 - val_loss: 0.4303 - accuracy: 0.9820
Epoch 4/5
250/250 [==============================] - 251s 1s/step - loss: 0.2028 - val_loss: 0.3191 - accuracy: 0.9900
Epoch 5/5
250/250 [==============================] - 238s 949ms/step - loss: 0.1232 - val_loss: 0.3259 - accuracy: 0.9890
```

ุชูุงูููุง! ููุฏ ููุช ุจุถุจุท ูููุฐุฌู ุจุฏูุฉ ููุดุงุฑูุชู ุนูู ๐ค Hub. ููููู ุงูุขู ุงุณุชุฎุฏุงูู ููุงุณุชูุชุงุฌ!
</tf>
</frameworkcontent>


<Tip>

ููุญุตูู ุนูู ูุซุงู ุฃูุซุฑ ุชุนูููุง ุญูู ููููุฉ ุถุจุท ูููุฐุฌ ูุชุตููู ุงูุตูุฑุ ุฑุงุฌุน ุฏูุชุฑ ููุงุญุธุงุช PyTorch ุงูููุงุจู [ููุง](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb).

</Tip>

## ุงูุงุณุชูุชุงุฌ

ุฑุงุฆุนุ ุงูุขู ุจุนุฏ ุฃู ููุช ุจุถุจุท ูููุฐุฌ ุจุฏูุฉุ ููููู ุงุณุชุฎุฏุงูู ููุงุณุชูุชุงุฌ!

ูู ุจุชุญููู ุตูุฑุฉ ุชุฑูุฏ ุชุดุบูู ุงูุงุณุชูุชุงุฌ ุนูููุง:

```py
>>> ds = load_dataset("food101", split="validation[:10]")
>>> image = ds["image"][0]
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png" alt="ุตูุฑุฉ beignets"/>
</div>

ุฃุจุณุท ุทุฑููุฉ ูุชุฌุฑุจุฉ ูููุฐุฌู ุงููุถุจูุท ุงูุฏููู ููุงุณุชูุชุงุฌ ูู ุงุณุชุฎุฏุงูู ูู [`pipeline`]. ูู ุจุชูููุฐ ูุซูู `pipeline` ูุชุตููู ุงูุตูุฑ ุจุงุณุชุฎุฏุงู ูููุฐุฌูุ ููุฑุฑ ุตูุฑุชู ุฅููู:

```py
>>> from transformers import pipeline

>>> classifier = pipeline("image-classification", model="my_awesome_food_model")
>>> classifier(image)
[{'score': 0.31856709718704224ุ 'label': 'beignets'}ุ
 {'score': 0.015232225880026817ุ 'label': 'bruschetta'}ุ
 {'score': 0.01519392803311348ุ 'label': 'chicken_wings'}ุ
 {'score': 0.013022331520915031ุ 'label': 'pork_chop'}ุ
 {'score': 0.012728818692266941ุ 'label': 'prime_rib'}]
```

ููููู ุฃูุถูุง ูุญุงูุงุฉ ูุชุงุฆุฌ `pipeline` ูุฏูููุง ุฅุฐุง ุฃุฑุฏุช:

<frameworkcontent>
<pt>
ูู ุจุชุญููู ูุนุงูุฌ ุงูุตูุฑ ููุนุงูุฌุฉ ุงูุตูุฑุฉ ูุฅุฑุฌุงุน `input` ูุฑููุฒ ุชุนุจูุฑูุฉ PyTorch:

```py
>>> from transformers import AutoImageProcessor
>>> import torch

>>> image_processor = AutoImageProcessor.from_pretrained("my_awesome_food_model")
>>> inputs = image_processor(image, return_tensors="pt")
```

ูุฑุฑ ุงููุฏุฎูุงุช ุฅูู ุงููููุฐุฌ ูุฃุนุฏ ุงูุฎุฑุฌุงุช:

```py
>>> from transformers import AutoModelForImageClassification

>>> model = AutoModelForImageClassification.from_pretrained("my_awesome_food_model")
>>> with torch.no_grad():
...     logits = model(**inputs).logits
```

ุงุญุตู ุนูู ุงูุชุณููุฉ ุงููุชููุนุฉ ูุน ุฃุนูู ุงุญุชูุงูุ ูุงุณุชุฎุฏู ุชุนููู `id2label` ูููููุฐุฌ ูุชุญูููู ุฅูู ุชุณููุฉ:

```py
>>> predicted_label = logits.argmax(-1).item()
>>> model.config.id2label[predicted_label]
'beignets'
```
</pt>
</frameworkcontent>

<frameworkcontent>
<tf>
ูู ุจุชุญููู ูุนุงูุฌ ุงูุตูุฑ ููุนุงูุฌุฉ ุงูุตูุฑุฉ ูุฅุฑุฌุงุน `input` ูุฑููุฒ ุชุนุจูุฑูุฉ TensorFlow:

```py
>>> from transformers import AutoImageProcessor

>>> image_processor = AutoImageProcessor.from_pretrained("MariaK/food_classifier")
>>> inputs = image_processor(image, return_tensors="tf")
```

ูุฑุฑ ุงููุฏุฎูุงุช ุฅูู ุงููููุฐุฌ ูุฃุนุฏ ุงูุฎุฑุฌุงุช:

```py
>>> from transformers import TFAutoModelForImageClassification

>>> model = TFAutoModelForImageClassification.from_pretrained("MariaK/food_classifier")
>>> logits = model(**inputs).logits
```

ุงุญุตู ุนูู ุงูุชุณููุฉ ุงููุชููุนุฉ ูุน ุฃุนูู ุงุญุชูุงูุ ูุงุณุชุฎุฏู ุชุนููู `id2label` ูููููุฐุฌ ูุชุญูููู ุฅูู ุชุณููุฉ:

```py
>>> predicted_class_id = int(tf.math.argmax(logits, axis=-1)[0])
>>> model.config.id2label[predicted_class_id]
'beignets'
```

</tf>
</frameworkcontent>