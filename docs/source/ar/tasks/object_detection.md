# ุงูุชุดุงู ุงูุฃุฌุณุงู 

[[open-in-colab]]

ุงูุชุดุงู ุงูุฃุฌุณุงู ูู ูููุฉ ุฑุคูุฉ ุญุงุณูุจูุฉ ูููุดู ุนู ูุซููุงุช (ูุซู ุงูุจุดุฑ ุฃู ุงููุจุงูู ุฃู ุงูุณูุงุฑุงุช) ูู ุตูุฑุฉ. ุชุชููู ููุงุฐุฌ ุงูุชุดุงู ุงูุฃุฌุณุงู ุตูุฑุฉ ููุฏุฎูุงุช ูุชุฎุฑุฌ ุฅุญุฏุงุซูุงุช ุตูุงุฏูู ุงูุญุฏูุฏ ูุงูุนูุงูุงุช ุงูููุชุฑูุฉ ููุฃุฌุณุงู ุงูููุชุดูุฉ. ูููู ุฃู ุชุญุชูู ุงูุตูุฑุฉ ุนูู ุฃุฌุณุงู ูุชุนุฏุฏุฉุ ููู ูููุง ุตูุฏูู ุญุฏูุฏู ูููุตูู ุงูุฎุงุต (ุนูู ุณุจูู ุงููุซุงูุ ูููู ุฃู ุชุญุชูู ุนูู ุณูุงุฑุฉ ููุจูู)ุ ููููู ุฃู ููุฌุฏ ูู ูุงุฆู ูู ุฃุฌุฒุงุก ูุฎุชููุฉ ูู ุงูุตูุฑุฉ (ุนูู ุณุจูู ุงููุซุงูุ ูููู ุฃู ุชุญุชูู ุงูุตูุฑุฉ ุนูู ุนุฏุฉ ุณูุงุฑุงุช).

ุชูุณุชุฎุฏู ูุฐู ุงููููุฉ ุจุดูู ุดุงุฆุน ูู ุงูููุงุฏุฉ ุงูุฐุงุชูุฉ ูููุดู ุนู ุฃุดูุงุก ูุซู ุงููุดุงุฉ ูุฅุดุงุฑุงุช ุงูุทุฑู ูุฅุดุงุฑุงุช ุงููุฑูุฑ. ุชุดูู ุงูุชุทุจููุงุช ุงูุฃุฎุฑู ุญุณุงุจ ุนุฏุฏ ุงูุฃุฌุณุงู ูู ุงูุตูุฑ ูุงูุจุญุซ ุนู ุงูุตูุฑ ูุงููุฒูุฏ.

ูู ูุฐุง ุงูุฏูููุ ุณุชุชุนูู ููููุฉ:

1. ุถุจุท ูููุฐุฌ [DETR](https://huggingface.co/docs/transformers/model_doc/detr)ุ ููู ูููุฐุฌ ูุฌูุน ุจูู ุงูุนููุฏ ุงูููุฑู ุงููุญูู ุงูุชุฑููุฒู ุงูุชุฑููุฒูุ ุนูู ูุฌููุนุฉ ุจูุงูุงุช [CPPE-5](https://huggingface.co/datasets/cppe-5).
2. ุงุณุชุฎุฏุงู ูููุฐุฌ ุถุจุท ุฏููู ุงูุฎุงุต ุจู ููุงุณุชูุชุงุฌ.

<Tip>

ููุดุงูุฏุฉ ุฌููุน ุงูุชุตูููุงุช ูููุงุท ุงููุฑุงูุจุฉ ุงููุชูุงููุฉ ูุน ูุฐู ุงููููุฉุ ููุตู ุจุงูุชุญูู ูู [ุตูุญุฉ ุงููููุฉ](https://huggingface.co/tasks/object-detection)

</Tip>

ูุจู ุฃู ุชุจุฏุฃุ ุชุฃูุฏ ูู ุชุซุจูุช ุฌููุน ุงูููุชุจุงุช ุงูุถุฑูุฑูุฉ:

```bash
pip install -q datasets transformers accelerate timm
pip install -q -U albumentations>=1.4.5 torchmetrics pycocotools
```

ุณุชุณุชุฎุฏู ๐ค Datasets ูุชุญููู ูุฌููุนุฉ ุจูุงูุงุช ูู Hub Hugging Faceุ ๐ค Transformers ูุชุฏุฑูุจ ูููุฐุฌูุ
ู `albumentations` ูุฒูุงุฏุฉ ุจูุงูุงุชู.

ูุญู ูุดุฌุนู ุนูู ูุดุงุฑูุฉ ูููุฐุฌู ูุน ุงููุฌุชูุน. ูู ุจุชุณุฌูู ุงูุฏุฎูู ุฅูู ุญุณุงุจ Hugging Face ุงูุฎุงุต ุจู ูุชุญูููู ุฅูู Hub.
ุนูุฏ ูุทุงูุจุชูุ ุฃุฏุฎู ุฑูุฒู ููุชุณุฌูู:

```py
>>> from huggingface_hub import notebook_login

>>> notebook_login()
```

ููุจุฏุกุ ุณูููู ุจุชุนุฑูู ุงูุซูุงุจุช ุงูุนุงูููุฉุ ุฃู ุงุณู ุงููููุฐุฌ ูุญุฌู ุงูุตูุฑุฉ. ุจุงููุณุจุฉ ููุฐุง ุงูุจุฑูุงูุฌ ุงูุชุนููููุ ุณูุณุชุฎุฏู ูููุฐุฌ DETR ุงูุดุฑุทู ุจุณุจุจ ุชูุงุฑุจู ุงูุฃุณุฑุน. ูุง ุชุชุฑุฏุฏ ูู ุงุฎุชูุงุฑ ุฃู ูููุฐุฌ ุงูุชุดุงู ูุงุฆู ูุชุงุญ ูู ููุชุจุฉ `transformers`.

```py
>>> MODEL_NAME = "microsoft/conditional-detr-resnet-50" # ุฃู "facebook/detr-resnet-50"
>>> IMAGE_SIZE = 480
```

## ุชุญููู ูุฌููุนุฉ ุจูุงูุงุช CPPE-5

ุชุญุชูู ูุฌููุนุฉ ุจูุงูุงุช [CPPE-5](https://huggingface.co/datasets/cppe-5) ุนูู ุตูุฑ ูุน
ุชุนูููุงุช ุชูุถูุญูุฉ ุชุญุฏุฏ ูุนุฏุงุช ุงูููุงูุฉ ุงูุดุฎุตูุฉ ุงูุทุจูุฉ (PPE) ูู ุณูุงู ุฌุงุฆุญุฉ COVID-19.

ุงุจุฏุฃ ุจุชุญููู ูุฌููุนุฉ ุงูุจูุงูุงุช ูุฅูุดุงุก ุชูุณูู `validation` ูู `train`:

```py
>>> from datasets import load_dataset

>>> cppe5 = load_dataset("cppe-5")

>>> if "validation" not in cppe5:
...     split = cppe5["train"].train_test_split(0.15, seed=1337)
...     cppe5["train"] = split["train"]
...     cppe5["validation"] = split["test"]

>>> cppe5
DatasetDict({
    train: Dataset({
        features: ['image_id', 'image', 'width', 'height', 'objects'],
        num_rows: 850
    })
    test: Dataset({
        features: ['image_id', 'image', 'width', 'height', 'objects'],
        num_rows: 29
    })
    validation: Dataset({
        features: ['image_id', 'image', 'width', 'height', 'objects'],
        num_rows: 150
    })
})
```
ุณุชุฑู ุฃู ูุฐู ุงููุฌููุนุฉ ุชุญุชูู ุนูู 1000 ุตูุฑุฉ ููุฌููุนุงุช ุงูุชุฏุฑูุจ ูุงูุชุญูู ููุฌููุนุฉ ุงุฎุชุจุงุฑ ุจูุง 29 ุตูุฑุฉ.

ููุชุนุฑู ุนูู ุงูุจูุงูุงุชุ ุงุณุชูุดู ููู ุชุจุฏู ุงูุฃูุซูุฉ.

```py
>>> cppe5["train"][0]
{
  'image_id': 366,
  'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=500x290>,
  'width': 500,
  'height': 500,
  'objects': {
    'id': [1932, 1933, 1934],
    'area': [27063, 34200, 32431],
    'bbox': [[29.0, 11.0, 97.0, 279.0],
      [201.0, 1.0, 120.0, 285.0],
      [382.0, 0.0, 113.0, 287.0]],
    'category': [0, 0, 0]
  }
}
```

ุชุญุชูู ุงูุฃูุซูุฉ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุนูู ุงูุญููู ุงูุชุงููุฉ:

- `image_id`: ูุนุฑู ุตูุฑุฉ ุงููุซุงู
- `image`: ูุงุฆู `PIL.Image.Image` ูุญุชูู ุนูู ุงูุตูุฑุฉ
- `width`: ุนุฑุถ ุงูุตูุฑุฉ
- `height`: ุงุฑุชูุงุน ุงูุตูุฑุฉ
- `objects`: ูุงููุณ ูุญุชูู ุนูู ุจูุงูุงุช ุชุนุฑูู ุตูุฏูู ุงูุญุฏูุฏ ููุฃุฌุณุงู ุงูููุฌูุฏุฉ ูู ุงูุตูุฑุฉ:
  - `id`: ูุนุฑู ุงูุชุนููู ุงูุชูุถูุญู
  - `area`: ูุณุงุญุฉ ุตูุฏูู ุงูุญุฏูุฏ
  - `bbox`: ุตูุฏูู ุญุฏูุฏ ุงููุงุฆู (ุจุชูุณูู [COCO](https://albumentations.ai/docs/getting_started/bounding_boxes_augmentation/#coco))
  - `category`: ูุฆุฉ ุงููุงุฆูุ ูุน ุงูููู ุงููุญุชููุฉ ุจูุง ูู ุฐูู `Coverall (0)`ุ `Face_Shield (1)`ุ `Gloves (2)`ุ `Goggles (3)` ู` Mask (4) `

ูุฏ ุชูุงุญุธ ุฃู ุญูู `bbox` ูุชุจุน ุชูุณูู COCOุ ููู ุงูุชูุณูู ุงูุฐู ูุชููุนู ูููุฐุฌ DETR.
ููุน ุฐููุ ูุฎุชูู ุชุฌููุน ุงูุญููู ุฏุงุฎู `objects` ุนู ุชูุณูู ุงูุชุนููู ุงูุชูุถูุญู ุงูุฐู ูุชุทูุจู DETR. ุณุชุญุชุงุฌ
ูุชุทุจูู ุจุนุถ ุชุญููุงุช ูุง ูุจู ุงููุนุงูุฌุฉ ูุจู ุงุณุชุฎุฏุงู ูุฐู ุงูุจูุงูุงุช ููุชุฏุฑูุจ.

ููุญุตูู ุนูู ููู ุฃูุถู ููุจูุงูุงุชุ ูู ุจุชุตูุฑ ูุซุงู ูู ูุฌููุนุฉ ุงูุจูุงูุงุช.

```py
>>> import numpy as np
>>> import os
>>> from PIL import Image, ImageDraw

>>> image = cppe5["train"][2]["image"]
>>> annotations = cppe5["train"][2]["objects"]
>>> draw = ImageDraw.Draw(image)

>>> categories = cppe5["train"].features["objects"].feature["category"].names

>>> id2label = {index: x for index, x in enumerate(categories, start=0)}
>>> label2id = {v: k for k, v in id2label.items()}

>>> for i in range(len(annotations["id"])):
...     box = annotations["bbox"][i]
...     class_idx = annotations["category"][i]
...     x, y, w, h = tuple(box)
...     # ุชุญูู ููุง ุฅุฐุง ูุงูุช ุงูุฅุญุฏุงุซูุงุช ูููุฏุฉ ุฃู ูุง
...     if max(box) > 1.0:
...         # ุงูุฅุญุฏุงุซูุงุช ุบูุฑ ูููุฏุฉุ ูุง ุฏุงุนู ูุฅุนุงุฏุฉ ุชุญุฌูููุง
...         x1, y1 = int(x), int(y)
...         x2, y2 = int(x + w), int(y + h)
...     else:
...         # ุงูุฅุญุฏุงุซูุงุช ูููุฏุฉุ ุฅุนุงุฏุฉ ุชุญุฌูููุง
...         x1 = int(x * width)
...         y1 = int(y * height)
...         x2 = int((x + w) * width)
...         y2 = int((y + h) * height)
...     draw.rectangle((x, y, x + w, y + h), outline="red", width=1)
...     draw.text((x, y), id2label[class_idx], fill="white")

>>> image
```
<div class="flex justify-center">
    <img src="https://i.imgur.com/oVQb9SF.png" alt="ูุซุงู ุนูู ุตูุฑุฉ CPPE-5"/>
</div>


ูุนุฑุถ ุตูุงุฏูู ุงูุญุฏูุฏ ูุน ุงูุนูุงูุงุช ุงูููุชุฑูุฉุ ููููู ุงูุญุตูู ุนูู ุงูุนูุงูุงุช ูู ุงูุจูุงูุงุช ุงููุตููุฉ ููุฌููุนุฉ ุงูุจูุงูุงุชุ ูุชุญุฏูุฏุงู
ุญูู "ุงููุฆุฉ".

ุณุชุญุชุงุฌ ุฃูุถูุง ุฅูู ุฅูุดุงุก ูุงููุณูู ููููุงู ุจุชุนููู ูุนุฑู ุงูุนูุงูุฉ ุฅูู ูุฆุฉ ุงูุนูุงูุฉ (`id2label`) ูุงูุนูุณ (`label2id`).
ููููู ุงุณุชุฎุฏุงููุง ูุงุญููุง ุนูุฏ ุฅุนุฏุงุฏ ุงููููุฐุฌ. ุจูุง ูู ุฐูู ูุฐู ุงูุฎุฑุงุฆุท ุณูุฌุนู ูููุฐุฌู ูุงุจู ูุฅุนุงุฏุฉ ุงูุงุณุชุฎุฏุงู ูู ูุจู ุงูุขุฎุฑูู ุฅุฐุง ููุช ุจูุดุงุฑูุชู
ุนูู Hub Hugging Face. ูุฑุฌู ููุงุญุธุฉ ุฃู ุงูุฌุฒุก ูู ุงูุชุนูููุงุช ุงูุจุฑูุฌูุฉ ุฃุนูุงู ุงูุฐู ูุฑุณู ุตูุงุฏูู ุงูุญุฏูุฏ ููุชุฑุถ ุฃูู ูู ุชูุณูู `COCO` `(x_minุ y_minุ widthุ height)`. ูุฌุจ ุชุนุฏููู ููุนูู ุจุชูุณููุงุช ุฃุฎุฑู ูุซู `(x_minุ y_minุ x_maxุ y_max)`.

ูุฎุทูุฉ ุฃุฎูุฑุฉ ููุชุนุฑู ุนูู ุงูุจูุงูุงุชุ ูู ุจุงุณุชูุดุงููุง ุจุญุซูุง ุนู ูุดููุงุช ูุญุชููุฉ. ุชุชูุซู ุฅุญุฏู ุงููุดููุงุช ุงูุดุงุฆุนุฉ ูู ูุฌููุนุงุช ุงูุจูุงูุงุช ุงูุฎุงุตุฉ
ุงูุชุดุงู ุงูุฃุฌุณุงู ูู ุตูุงุฏูู ุงูุญุฏูุฏ ุงูุชู "ุชูุชุฏ" ุฅูู ูุง ุจุนุฏ ุญุงูุฉ ุงูุตูุฑุฉ. ูููู ุฃู ุชุณุจุจ ุตูุงุฏูู ุงูุญุฏูุฏ "ุงููุงุฑุจุฉ" ูุฐู
ุฃุฎุทุงุก ุฃุซูุงุก ุงูุชุฏุฑูุจ ููุฌุจ ูุนุงูุฌุชูุง. ููุงู ุจุถุน ุฃูุซูุฉ ุจูุง ูุฐู ุงููุดููุฉ ูู ูุฐู ุงููุฌููุนุฉ.
ููุญูุงุธ ุนูู ุงูุจุณุงุทุฉ ูู ูุฐุง ุงูุฏูููุ ุณูููู ุจุชุนููู `clip=True` ูู `BboxParams` ูู ุงูุชุญููุงุช ุฃุฏูุงู.

## ูุนุงูุฌุฉ ุงูุจูุงูุงุช ูุณุจููุง

ูุถุจุท ูููุฐุฌ ุฏูููุ ูุฌุจ ูุนุงูุฌุฉ ุงูุจูุงูุงุช ุงูุชู ุชุฎุทุท ูุงุณุชุฎุฏุงููุง ููุทุงุจูุฉ ุงูููุฌ ุงููุณุชุฎุฏู ุจุงูุถุจุท ูููููุฐุฌ ุงููุณุจู ุงูุชุฏุฑูุจ.
ูุชููู [`AutoImageProcessor`] ูุนุงูุฌุฉ ุจูุงูุงุช ุงูุตูุฑ ูุฅูุดุงุก `pixel_values` ู`pixel_mask` ู
`labels` ุงูุชู ูููู ููููุฐุฌ DETR ุงูุชุฏุฑูุจ ุนูููุง. ูุฏู ูุนุงูุฌ ุงูุตูุฑ ุจุนุถ ุงูุตูุงุช ุงูุชู ูุง ูุชุนูู ุนููู ุงูููู ุจุดุฃููุง:

- `image_mean = [0.485ุ 0.456ุ 0.406]`
- `image_std = [0.229ุ 0.224ุ 0.225]`

ูุฐู ูู ุงููุชูุณุท ูุงูุงูุญุฑุงู ุงููุนูุงุฑู ุงููุณุชุฎุฏู ูุชุทุจูุน ุงูุตูุฑ ุฃุซูุงุก ุงูุชุฏุฑูุจ ุงููุณุจู ูููููุฐุฌ. ูุฐู ุงูููู ุญุงุณูุฉ
ูุงุณุชูุณุงุฎ ุนูุฏ ุฅุฌุฑุงุก ุงูุงุณุชุฏูุงู ุฃู ุถุจุท ูููุฐุฌ ุงูุตูุฑุฉ ุงููุณุจู ุงูุชุฏุฑูุจ.

ูู ุจุชูููุฐ ูุนุงูุฌ ุงูุตูุฑ ูู ููุณ ููุทุฉ ุงููุฑุงูุจุฉ ูุซู ุงููููุฐุฌ ุงูุฐู ุชุฑูุฏ ุถุจุทู ุจุฏูุฉ.

```py
>>> from transformers import AutoImageProcessor

>>> MAX_SIZE = IMAGE_SIZE

>>> image_processor = AutoImageProcessor.from_pretrained(
...     MODEL_NAME,
...     do_resize=True,
...     size={"max_height": MAX_SIZE, "max_width": MAX_SIZE},
...     do_pad=True,
...     pad_size={"height": MAX_SIZE, "width": MAX_SIZE},
... )
```

ูุจู ุชูุฑูุฑ ุงูุตูุฑ ุฅูู `image_processor`ุ ูู ุจุชุทุจูู ุชุญูููู ูููุนุงูุฌุฉ ุงููุณุจูุฉ ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช:

- ุฒูุงุฏุฉ ุงูุตูุฑ
- ุฅุนุงุฏุฉ ุชูุณูู ุงูุชุนูููุงุช ุงูุชูุถูุญูุฉ ูุชูุจูุฉ ุชููุนุงุช DETR

ุฃููุงูุ ููุชุฃูุฏ ูู ุฃู ุงููููุฐุฌ ูุง ููุฑุท ูู ุชูุงุณุจ ุจูุงูุงุช ุงูุชุฏุฑูุจุ ููููู ุชุทุจูู ุฒูุงุฏุฉ ุงูุตูุฑุฉ ุจุงุณุชุฎุฏุงู ุฃู ููุชุจุฉ ูุฒูุงุฏุฉ ุงูุจูุงูุงุช. ููุง ูุณุชุฎุฏู [Albumentations](https://albumentations.ai/docs/).
ุชุถูู ูุฐู ุงูููุชุจุฉ ุฃู ุชุคุซุฑ ุงูุชุญููุงุช ุนูู ุงูุตูุฑุฉ ูุชุญุฏูุซ ุตูุงุฏูู ุงูุญุฏูุฏ ููููุง ูุฐูู.
ุชุญุชูู ูุซุงุฆู ููุชุจุฉ ๐ค Datasets ุนูู ุฏููู ุชูุตููู ุญูู [ููููุฉ ุฒูุงุฏุฉ ุงูุตูุฑ ูุงูุชุดุงู ุงูุฃุฌุณุงู](https://huggingface.co/docs/datasets/object_detection)ุ
ููุณุชุฎุฏู ููุณ ูุฌููุนุฉ ุงูุจูุงูุงุช ููุซุงู. ูู ุจุชุทุจูู ุจุนุถ ุงูุชุญููุงุช ุงูููุฏุณูุฉ ูุงูููููุฉ ุนูู ุงูุตูุฑุฉ. ููุญุตูู ุนูู ุฎูุงุฑุงุช ุฒูุงุฏุฉ ุฅุถุงููุฉุ ุงุณุชูุดู [ูุณุงุญุฉ ุนุฑุถ Albumentations](https://huggingface.co/spaces/qubvel-hf/albumentations-demo).

```py
>>> import albumentations as A

>>> train_augment_and_transform = A.Compose(
...     [
...         A.Perspective(p=0.1),
...         A.HorizontalFlip(p=0.5),
...         A.RandomBrightnessContrast(p=0.5),
...         A.HueSaturationValue(p=0.1),
...     ],
...     bbox_params=A.BboxParams(format="coco", label_fields=["category"], clip=True, min_area=25),
... )

>>> validation_transform = A.Compose(
...     [A.NoOp()],
...     bbox_params=A.BboxParams(format="coco", label_fields=["category"], clip=True),
... )
```

ูุชููุน `image_processor` ุฃู ุชููู ุงูุชุนูููุงุช ุงูุชูุถูุญูุฉ ุจุงูุชูุณูู ุงูุชุงูู: `{'image_id': intุ 'annotations': List [Dict]}`ุ
ุญูุซ ูููู ูู ูุงููุณ ุนุจุงุฑุฉ ุนู ุชุนููู ุชูุถูุญู ููุงุฆู COCO. ุฏุนูุง ูุถูู ุฏุงูุฉ ูุฅุนุงุฏุฉ ุชูุณูู ุงูุชุนูููุงุช ุงูุชูุถูุญูุฉ ูุตูุฑุฉ ูุงุญุฏุฉ:

```py
>>> def format_image_annotations_as_coco(image_id, categories, areas, bboxes):
...     """Format one set of image annotations to the COCO format

...     Args:
...         image_id (str): image id. e.g. "0001"
...         categories (List[int]): list of categories/class labels corresponding to provided bounding boxes
...         areas (List[float]): list of corresponding areas to provided bounding boxes
...         bboxes (List[Tuple[float]]): list of bounding boxes provided in COCO format
...             ([center_x, center_y, width, height] in absolute coordinates)

...     Returns:
...         dict: {
...             "image_id": image id,
...             "annotations": list of formatted annotations
...         }
...     """
...     annotations = []
...     for category, area, bbox in zip(categories, areas, bboxes):
...         formatted_annotation = {
...             "image_id": image_id,
...             "category_id": category,
...             "iscrowd": 0,
...             "area": area,
...             "bbox": list(bbox),
...         }
...         annotations.append(formatted_annotation)

...     return {
...         "image_id": image_id,
...         "annotations": annotations,
...     }

```

ุงูุขู ููููู ุงูุฌูุน ุจูู ุชุญููุงุช ุงูุตูุฑ ูุงูุชุนูููุงุช ุงูุชูุถูุญูุฉ ูุงุณุชุฎุฏุงููุง ูู ุฏูุนุฉ ูู ุงูุฃูุซูุฉ:

```py
>>> def augment_and_transform_batch(examples, transform, image_processor, return_pixel_mask=False):
...     """Apply augmentations and format annotations in COCO format for object detection task"""

...     images = []
...     annotations = []
...     for image_id, image, objects in zip(examples["image_id"], examples["image"], examples["objects"]):
...         image = np.array(image.convert("RGB"))

...         # apply augmentations
...         output = transform(image=image, bboxes=objects["bbox"], category=objects["category"])
...         images.append(output["image"])

...         # format annotations in COCO format
...         formatted_annotations = format_image_annotations_as_coco(
...             image_id, output["category"], objects["area"], output["bboxes"]
...         )
...         annotations.append(formatted_annotations)

...     # Apply the image processor transformations: resizing, rescaling, normalization
...     result = image_processor(images=images, annotations=annotations, return_tensors="pt")

...     if not return_pixel_mask:
...         result.pop("pixel_mask", None)

...     return result
```

ูู ุจุชุทุจูู ุฏุงูุฉ ูุง ูุจู ุงููุนุงูุฌุฉ ูุฐู ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุจุฃููููุง ุจุงุณุชุฎุฏุงู ุทุฑููุฉ [`~datasets.Dataset.with_transform`] ูู ๐ค Datasets. ุชุทุจู ูุฐู ุงูุทุฑููุฉ
ุงูุชุญูููุงุช ุฃุซูุงุก ุงูุชููู ุนูุฏ ุชุญููู ุนูุตุฑ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช.

ูู ูุฐู ุงููุฑุญูุฉุ ููููู ุงูุชุญูู ูู ูุธูุฑ ูุซุงู ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุจุนุฏ ุงูุชุญูููุงุช. ูุฌุจ ุฃู ุชุฑู ุชูุณูุฑ
ูุน `pixel_values`ุ ุชูุณูุฑ ูุน `pixel_mask`ุ ู `labels`.

```py
>>> from functools import partial

>>> # ุฅูุดุงุก ุฏุงูุงุช ุชุญููู ููุฏูุนุฉ ูุชุทุจูููุง ุนูู ุฃูุณุงู ูุฌููุนุฉ ุงูุจูุงูุงุช
>>> train_transform_batch = partial(
...     augment_and_transform_batchุ transform=train_augment_and_transformุ image_processor=image_processor
... )
>>> validation_transform_batch = partial(
...     augment_and_transform_batchุ transform=validation_transformุ image_processor=image_processor
... )

>>> cppe5["train"] = cppe5["train"].with_transform(train_transform_batch)
>>> cppe5["validation"] = cppe5["validation"].with_transform(validation_transform_batch)
>>> cppe5["test"] = cppe5["test"].with_transform(validation_transform_batch)

>>> cppe5["train"][15]
{'pixel_values': tensor([[[ 1.9235ุ 1.9407ุ 1.9749ุ ...ุ -0.7822ุ -0.7479ุ -0.6965]ุ
[ 1.9578ุ 1.9749ุ 1.9920ุ ...ุ -0.7993ุ -0.7650ุ -0.7308]ุ
[ 2.0092ุ 2.0092ุ 2.0263ุ ...ุ -0.8507ุ -0.8164ุ -0.7822]ุ
...ุ
[ 0.0741ุ 0.0741ุ 0.0741ุ ...ุ 0.0741ุ 0.0741ุ 0.0741]ุ
[ 0.0741ุ 0.0741ุ 0.0741ุ ...ุ 0.0741ุ 0.0741ุ 0.0741]ุ
[ 0.0741ุ 0.0741ุ 0.0741ุ ...ุ 0.0741ุ 0.0741ุ 0.0741]]ุ

 [[ 1.6232ุ 1.6408ุ 1.6583ุ ...ุ 0.8704ุ 1.0105ุ 1.1331]ุ
[ 1.6408ุ 1.6583ุ 1.6758ุ ...ุ 0.8529ุ 0.9930ุ 1.0980]ุ
[ 1.6933ุ 1.6933ุ 1.7108ุ ...ุ 0.8179ุ 0.9580ุ 1.0630]ุ
...ุ
[ 0.2052ุ 0.2052ุ 0.2052ุ ...ุ 0.2052ุ 0.2052ุ 0.2052]ุ
[ 0.2052ุ 0.2052ุ 0.2052ุ ...ุ 0.2052ุ 0.2052ุ 0.2052]ุ
[ 0.2052ุ 0.2052ุ 0.2052ุ ...ุ 0.2052ุ 0.2052ุ 0.2052]]ุ

 [[ 1.8905ุ 1.9080ุ 1.9428ุ ...ุ -0.1487ุ -0.0964ุ -0.0615]ุ
[ 1.9254ุ 1.9428ุ 1.9603ุ ...ุ -0.1661ุ -0.1138ุ -0.0790]ุ
[ 1.9777ุ 1.9777ุ 1.9951ุ ...ุ -0.2010ุ -0.1138ุ -0.0790]ุ
...ุ
[ 0.4265ุ 0.4265ุ 0.4265ุ ...ุ 0.4265ุ 0.4265ุ 0.4265]ุ
[ 0.4265ุ 0.4265ุ 0.4265ุ ...ุ 0.4265ุ 0.4265ุ 0.4265]ุ
[ 0.4265ุ 0.4265ุ 0.4265ุ ...ุ 0.4265ุ 0.4265ุ 0.4265]]])ุ
'labels': {'image_id': tensor([688])ุ 'class_labels': tensor([3ุ 4ุ 2ุ 0ุ 0])ุ 'boxes': tensor([[0.4700ุ 0.1933ุ 0.1467ุ 0.0767]ุ
[0.4858ุ 0.2600ุ 0.1150ุ 0.1000]ุ
[0.4042ุ 0.4517ุ 0.1217ุ 0.1300]ุ
[0.4242ุ 0.3217ุ 0.3617ุ 0.5567]ุ
[0.6617ุ 0.4033ุ 0.5400ุ 0.4533]])ุ 'area': tensor([4048.ุ 4140.ุ 5694.ุ 72478.ุ 88128.])ุ 'iscrowd': tensor([0ุ 0ุ 0ุ 0ุ 0])ุ 'orig_size': tensor([480ุ 480])}}
```

ููุฏ ูุฌุญุช ูู ุฒูุงุฏุฉ ุญุฌู ุงูุตูุฑ ุงููุฑุฏูุฉ ูุฅุนุฏุงุฏ ุชุณููุงุชูุง. ููุน ุฐููุ ูู ุชูุชู ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ุจุนุฏ. ูู ุงูุฎุทูุฉ ุงูุฃุฎูุฑุฉุ ูู ุจุฅูุดุงุก `collate_fn` ูุฎุตุต ูุฏูุฌ ุงูุตูุฑ ูุนูุง.
ูู ุจุชุจุทูู ุงูุตูุฑ (ุงูุชู ูู ุงูุขู `pixel_values`) ุฅูู ุฃูุจุฑ ุตูุฑุฉ ูู ุฏูุนุฉุ ููู ุจุฅูุดุงุก `pixel_mask`
ุงูููุงุจู ููุฅุดุงุฑุฉ ุฅูู ุงูุจูุณูุงุช ุงูุญููููุฉ (1) ูุงูุจูุณูุงุช ุงููุจุทูุฉ (0).

```py
>>> import torch

>>> def collate_fn(batch):
...     data = {}
...     data["pixel_values"] = torch.stack([x["pixel_values"] for x in batch])
...     data["labels"] = [x["labels"] for x in batch]
...     if "pixel_mask" in batch[0]:
...         data["pixel_mask"] = torch.stack([x["pixel_mask"] for x in batch])
...     return data

```

## ุฅุนุฏุงุฏ ุฏุงูุฉ ูุญุณุงุจ mAP

ุชุชู ุนุงุฏุฉู ุชูููู ููุงุฐุฌ ุงูุชุดุงู ุงููุงุฆูุงุช ุจุงุณุชุฎุฏุงู ูุฌููุนุฉ ูู <a href="https://cocodataset.org/#detection-eval">ููุงููุณ ุนูู ุบุฑุงุฑ COCO</a>. ุณูุณุชุฎุฏู `torchmetrics` ูุญุณุงุจ `mAP` (ูุชูุณุท ุงูุฏูุฉ ุงููุชูุณุทุฉ) ู `mAR` (ูุชูุณุท ุงูุงุณุชุฏุนุงุก ุงููุชูุณุท) ูุณูููู ุจุชุบููููุง ูู ุฏุงูุฉ `compute_metrics` ูุงุณุชุฎุฏุงููุง ูู [`Trainer`] ููุชูููู.

ุชูุณูู ูุณูุท ููุตูุงุฏูู ุงููุณุชุฎุฏูุฉ ููุชุฏุฑูุจ ูู `YOLO` (ูุนูุงุฑู) ูููููุง ุณูุญุณุจ ุงูููุงููุณ ููุตูุงุฏูู ุจุชูุณูู `Pascal VOC` (ุงููุทูู) ูู ุฃุฌู ุงูุชุนุงูู ุจุดูู ุตุญูุญ ูุน ููุงุทู ุงูุตูุฏูู. ุฏุนูุง ูุญุฏุฏ ุฏุงูุฉ ูุชุญููู ุญุฏูุฏ ุงูุตูุฑุฉ ุฅูู ุชูุณูู `Pascal VOC`:

```py
>>> from transformers.image_transforms import center_to_corners_format

>>> def convert_bbox_yolo_to_pascal(boxes, image_size):
...     """
...     Convert bounding boxes from YOLO format (x_center, y_center, width, height) in range [0, 1]
...     to Pascal VOC format (x_min, y_min, x_max, y_max) in absolute coordinates.

...     Args:
...         boxes (torch.Tensor): Bounding boxes in YOLO format
...         image_size (Tuple[int, int]): Image size in format (height, width)

...     Returns:
...         torch.Tensor: Bounding boxes in Pascal VOC format (x_min, y_min, x_max, y_max)
...     """
...     # convert center to corners format
...     boxes = center_to_corners_format(boxes)

...     # convert to absolute coordinates
...     height, width = image_size
...     boxes = boxes * torch.tensor([[width, height, width, height]])

...     return boxes
```
ูู ุฏุงูุฉ compute_metrics ูููู ุจุฌูุน ุงูุตูุงุฏูู ุงูุญุฏูุฏูุฉ predicted ู targetุ ุงูุฏุฑุฌุงุช ูุงูุนูุงูุงุช ูู ูุชุงุฆุฌ ุญููุฉ ุงูุชูููู ูููุฑุฑูุง ุฅูู ุฏุงูุฉ ุงูุชุณุฌูู.

```py
>>> import numpy as np
>>> from dataclasses import dataclass
>>> from torchmetrics.detection.mean_ap import MeanAveragePrecision


>>> @dataclass
>>> class ModelOutput:
...     logits: torch.Tensor
...     pred_boxes: torch.Tensor


>>> @torch.no_grad()
>>> def compute_metrics(evaluation_results, image_processor, threshold=0.0, id2label=None):
...     """
...     Compute mean average mAP, mAR and their variants for the object detection task.

...     Args:
...         evaluation_results (EvalPrediction): Predictions and targets from evaluation.
...         threshold (float, optional): Threshold to filter predicted boxes by confidence. Defaults to 0.0.
...         id2label (Optional[dict], optional): Mapping from class id to class name. Defaults to None.

...     Returns:
...         Mapping[str, float]: Metrics in a form of dictionary {<metric_name>: <metric_value>}
...     """

...     predictions, targets = evaluation_results.predictions, evaluation_results.label_ids

...     # For metric computation we need to provide:
...     #  - targets in a form of list of dictionaries with keys "boxes", "labels"
...     #  - predictions in a form of list of dictionaries with keys "boxes", "scores", "labels"

...     image_sizes = []
...     post_processed_targets = []
...     post_processed_predictions = []

...     # Collect targets in the required format for metric computation
...     for batch in targets:
...         # collect image sizes, we will need them for predictions post processing
...         batch_image_sizes = torch.tensor(np.array([x["orig_size"] for x in batch]))
...         image_sizes.append(batch_image_sizes)
...         # collect targets in the required format for metric computation
...         # boxes were converted to YOLO format needed for model training
...         # here we will convert them to Pascal VOC format (x_min, y_min, x_max, y_max)
...         for image_target in batch:
...             boxes = torch.tensor(image_target["boxes"])
...             boxes = convert_bbox_yolo_to_pascal(boxes, image_target["orig_size"])
...             labels = torch.tensor(image_target["class_labels"])
...             post_processed_targets.append({"boxes": boxes, "labels": labels})

...     # Collect predictions in the required format for metric computation,
...     # model produce boxes in YOLO format, then image_processor convert them to Pascal VOC format
...     for batch, target_sizes in zip(predictions, image_sizes):
...         batch_logits, batch_boxes = batch[1], batch[2]
...         output = ModelOutput(logits=torch.tensor(batch_logits), pred_boxes=torch.tensor(batch_boxes))
...         post_processed_output = image_processor.post_process_object_detection(
...             output, threshold=threshold, target_sizes=target_sizes
...         )
...         post_processed_predictions.extend(post_processed_output)

...     # Compute metrics
...     metric = MeanAveragePrecision(box_format="xyxy", class_metrics=True)
...     metric.update(post_processed_predictions, post_processed_targets)
...     metrics = metric.compute()

...     # Replace list of per class metrics with separate metric for each class
...     classes = metrics.pop("classes")
...     map_per_class = metrics.pop("map_per_class")
...     mar_100_per_class = metrics.pop("mar_100_per_class")
...     for class_id, class_map, class_mar in zip(classes, map_per_class, mar_100_per_class):
...         class_name = id2label[class_id.item()] if id2label is not None else class_id.item()
...         metrics[f"map_{class_name}"] = class_map
...         metrics[f"mar_100_{class_name}"] = class_mar

...     metrics = {k: round(v.item(), 4) for k, v in metrics.items()}

...     return metrics


>>> eval_compute_metrics_fn = partial(
...     compute_metrics, image_processor=image_processor, id2label=id2label, threshold=0.0
... )
```
## ุชุฏุฑูุจ ูููุฐุฌ ุงููุดู

ููุฏ ููุช ุจูุนุธู ุงูุนูู ุงูุดุงู ูู ุงูุฃูุณุงู ุงูุณุงุจูุฉุ ูุฐุง ูุฃูุช ุงูุขู ูุณุชุนุฏ ูุชุฏุฑูุจ ูููุฐุฌู!
ูุง ุชุฒุงู ุงูุตูุฑ ูู ูุฐู ุงููุฌููุนุฉ ุงูุจูุงูุงุช ูุจูุฑุฉ ุงูุญุฌูุ ุญุชู ุจุนุฏ ุชุบููุฑ ุญุฌููุง. ููุฐุง ูุนูู ุฃู ุถุจุท ูููุฐุฌ ุณูุชุทูุจ
ุนูู ุงูุฃูู ูุญุฏุฉ ูุนุงูุฌุฉ ุฑุณููุงุช (GPU) ูุงุญุฏุฉ.

ูุชุถูู ุงูุชุฏุฑูุจ ุงูุฎุทูุงุช ุงูุชุงููุฉ:

1. ูู ุจุชุญููู ุงููููุฐุฌ ุจุงุณุชุฎุฏุงู [`AutoModelForObjectDetection`] ุจุงุณุชุฎุฏุงู ููุณ ููุทุฉ ุงูุชุซุจูุช checkpoint ููุง ูู ุงููุนุงูุฌุฉ ุงููุณุจูุฉ.
2. ุญุฏุฏ ูุฑุท ูุนููุงุชู ูู [`TrainingArguments`].
3. ูุฑุฑ ูุฑุท ูุนููุงุช ุงูุชุฏุฑูุจ ุฅูู [`Trainer`] ุฌูุจูุง ุฅูู ุฌูุจ ูุน ุงููููุฐุฌ ููุฌููุนุฉ ุงูุจูุงูุงุช ููุนุงูุฌ ุงูุตูุฑ ููุฌูุน ุงูุจูุงูุงุช.
4. ุงุณุชุฏุนุงุก [`~Trainer.train`] ูุถุจุท ูููุฐุฌู.

ุนูุฏ ุชุญููู ุงููููุฐุฌ ูู ููุณ ููุทุฉ ุงูุชุซุจูุช ุงูุชู ุงุณุชุฎุฏูุชูุง ูููุนุงูุฌุฉ ุงููุณุจูุฉุ ุชุฐูุฑ ุชูุฑูุฑ ุงูุฎุฑุงุฆุท `label2id`
ู `id2label` ุงูุชู ููุช ุจุฅูุดุงุฆูุง ุณุงุจููุง ูู ุจูุงูุงุช ูุตู ูุฌููุนุฉ ุงูุจูุงูุงุช. ุจุงูุฅุถุงูุฉ ุฅูู ุฐููุ ูููู ุจุชุญุฏูุฏ `ignore_mismatched_sizes=True` ูุงุณุชุจุฏุงู ุฑุฃุณ ุงูุชุตููู ุงูููุฌูุฏ ุจูุงุญุฏ ุฌุฏูุฏ.

```py
>>> from transformers import AutoModelForObjectDetection

>>> model = AutoModelForObjectDetection.from_pretrained(
...     MODEL_NAME,
...     id2label=id2label,
...     label2id=label2id,
...     ignore_mismatched_sizes=True,
... )
```

ูู [`TrainingArguments`] ุงุณุชุฎุฏู `output_dir` ูุชุญุฏูุฏ ุงูููุงู ุงูุฐู ุณูุชู ููู ุญูุธ ูููุฐุฌูุ ุซู ูู ุจุชููุฆุฉ ูุฑุท ุงููุนููุงุช ููุง ุชุฑุงู ููุงุณุจูุง. ุจุงููุณุจุฉ ูู `num_train_epochs=30`ุ ุณูุณุชุบุฑู ุงูุชุฏุฑูุจ ุญูุงูู 35 ุฏูููุฉ ูู Google Colab T4 GPUุ ูู ุจุฒูุงุฏุฉ ุนุฏุฏ ุงูุนุตูุฑ epochs ูุชุญููู ูุชุงุฆุฌ ุฃูุถู.

ููุงุญุธุงุช ูููุฉ:
 - ูุง ุชูู ุจุฅุฒุงูุฉ ุงูุฃุนูุฏุฉ ุบูุฑ ุงููุณุชุฎุฏูุฉ ูุฃู ูุฐุง ุณูุคุฏู ุฅูู ุฅุณูุงุท ุนููุฏ ุงูุตูุฑุฉ. ุจุฏูู ุนููุฏ ุงูุตูุฑุฉุ
ูุง ููููู ุฅูุดุงุก `pixel_values`. ููุฐุง ุงูุณุจุจุ ูู ุจุชุนููู `remove_unused_columns` ุฅูู `False`.
 - ูู ุจุชุนููู `eval_do_concat_batches=False` ููุญุตูู ุนูู ูุชุงุฆุฌ ุชูููู ุตุญูุญุฉ. ุชุญุชูู ุงูุตูุฑ ุนูู ุนุฏุฏ ูุฎุชูู ูู ุตูุงุฏูู ุงููุฏูุ ุฅุฐุง ุชู ุฏูุฌ ุงูุฏูุนุงุชุ ููู ูุชููู ูู ุชุญุฏูุฏ ุงูุตูุงุฏูู ุงูุชู ุชูุชูู ุฅูู ุตูุฑุฉ ูุนููุฉ.

ุฅุฐุง ููุช ุชุฑุบุจ ูู ูุดุงุฑูุฉ ูููุฐุฌู ุนู ุทุฑูู ุฏูุนู ุฅูู Hubุ ููู ุจุชุนููู `push_to_hub` ุฅูู `True` (ูุฌุจ ุฃู ุชููู ูุฏ ุณุฌูุช ุงูุฏุฎูู ุฅูู Hugging
Face ูุชุญููู ูููุฐุฌู).

```py
>>> from transformers import TrainingArguments

>>> training_args = TrainingArguments(
...     output_dir="detr_finetuned_cppe5",
...     num_train_epochs=30,
...     fp16=False,
...     per_device_train_batch_size=8,
...     dataloader_num_workers=4,
...     learning_rate=5e-5,
...     lr_scheduler_type="cosine",
...     weight_decay=1e-4,
...     max_grad_norm=0.01,
...     metric_for_best_model="eval_map",
...     greater_is_better=True,
...     load_best_model_at_end=True,
...     eval_strategy="epoch",
...     save_strategy="epoch",
...     save_total_limit=2,
...     remove_unused_columns=False,
...     eval_do_concat_batches=False,
...     push_to_hub=True,
... )
```

ุฃุฎูุฑูุงุ ูู ุจุฌูุน ูู ุดูุก ูุนูุงุ ูุงุณุชุฏุนุงุก [`~transformers.Trainer.train`]:

```py
>>> from transformers import Trainer

>>> trainer = Trainer(
...     model=model,
...     args=training_args,
...     train_dataset=cppe5["train"],
...     eval_dataset=cppe5["validation"],
...     tokenizer=image_processor,
...     data_collator=collate_fn,
...     compute_metrics=eval_compute_metrics_fn,
... )

>>> trainer.train()
```
<div>

  <progress value='3210' max='3210' style='width:300px; height:20px; vertical-align: middle;'></progress>
  [3210/3210 26:07, Epoch 30/30]
</div>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>Epoch</th>
      <th>Training Loss</th>
      <th>Validation Loss</th>
      <th>Map</th>
      <th>Map 50</th>
      <th>Map 75</th>
      <th>Map Small</th>
      <th>Map Medium</th>
      <th>Map Large</th>
      <th>Mar 1</th>
      <th>Mar 10</th>
      <th>Mar 100</th>
      <th>Mar Small</th>
      <th>Mar Medium</th>
      <th>Mar Large</th>
      <th>Map Coverall</th>
      <th>Mar 100 Coverall</th>
      <th>Map Face Shield</th>
      <th>Mar 100 Face Shield</th>
      <th>Map Gloves</th>
      <th>Mar 100 Gloves</th>
      <th>Map Goggles</th>
      <th>Mar 100 Goggles</th>
      <th>Map Mask</th>
      <th>Mar 100 Mask</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>No log</td>
      <td>2.629903</td>
      <td>0.008900</td>
      <td>0.023200</td>
      <td>0.006500</td>
      <td>0.001300</td>
      <td>0.002800</td>
      <td>0.020500</td>
      <td>0.021500</td>
      <td>0.070400</td>
      <td>0.101400</td>
      <td>0.007600</td>
      <td>0.106200</td>
      <td>0.096100</td>
      <td>0.036700</td>
      <td>0.232000</td>
      <td>0.000300</td>
      <td>0.019000</td>
      <td>0.003900</td>
      <td>0.125400</td>
      <td>0.000100</td>
      <td>0.003100</td>
      <td>0.003500</td>
      <td>0.127600</td>
    </tr>
    <tr>
      <td>2</td>
      <td>No log</td>
      <td>3.479864</td>
      <td>0.014800</td>
      <td>0.034600</td>
      <td>0.010800</td>
      <td>0.008600</td>
      <td>0.011700</td>
      <td>0.012500</td>
      <td>0.041100</td>
      <td>0.098700</td>
      <td>0.130000</td>
      <td>0.056000</td>
      <td>0.062200</td>
      <td>0.111900</td>
      <td>0.053500</td>
      <td>0.447300</td>
      <td>0.010600</td>
      <td>0.100000</td>
      <td>0.000200</td>
      <td>0.022800</td>
      <td>0.000100</td>
      <td>0.015400</td>
      <td>0.009700</td>
      <td>0.064400</td>
    </tr>
    <tr>
      <td>3</td>
      <td>No log</td>
      <td>2.107622</td>
      <td>0.041700</td>
      <td>0.094000</td>
      <td>0.034300</td>
      <td>0.024100</td>
      <td>0.026400</td>
      <td>0.047400</td>
      <td>0.091500</td>
      <td>0.182800</td>
      <td>0.225800</td>
      <td>0.087200</td>
      <td>0.199400</td>
      <td>0.210600</td>
      <td>0.150900</td>
      <td>0.571200</td>
      <td>0.017300</td>
      <td>0.101300</td>
      <td>0.007300</td>
      <td>0.180400</td>
      <td>0.002100</td>
      <td>0.026200</td>
      <td>0.031000</td>
      <td>0.250200</td>
    </tr>
    <tr>
      <td>4</td>
      <td>No log</td>
      <td>2.031242</td>
      <td>0.055900</td>
      <td>0.120600</td>
      <td>0.046900</td>
      <td>0.013800</td>
      <td>0.038100</td>
      <td>0.090300</td>
      <td>0.105900</td>
      <td>0.225600</td>
      <td>0.266100</td>
      <td>0.130200</td>
      <td>0.228100</td>
      <td>0.330000</td>
      <td>0.191000</td>
      <td>0.572100</td>
      <td>0.010600</td>
      <td>0.157000</td>
      <td>0.014600</td>
      <td>0.235300</td>
      <td>0.001700</td>
      <td>0.052300</td>
      <td>0.061800</td>
      <td>0.313800</td>
    </tr>
    <tr>
      <td>5</td>
      <td>3.889400</td>
      <td>1.883433</td>
      <td>0.089700</td>
      <td>0.201800</td>
      <td>0.067300</td>
      <td>0.022800</td>
      <td>0.065300</td>
      <td>0.129500</td>
      <td>0.136000</td>
      <td>0.272200</td>
      <td>0.303700</td>
      <td>0.112900</td>
      <td>0.312500</td>
      <td>0.424600</td>
      <td>0.300200</td>
      <td>0.585100</td>
      <td>0.032700</td>
      <td>0.202500</td>
      <td>0.031300</td>
      <td>0.271000</td>
      <td>0.008700</td>
      <td>0.126200</td>
      <td>0.075500</td>
      <td>0.333800</td>
    </tr>
    <tr>
      <td>6</td>
      <td>3.889400</td>
      <td>1.807503</td>
      <td>0.118500</td>
      <td>0.270900</td>
      <td>0.090200</td>
      <td>0.034900</td>
      <td>0.076700</td>
      <td>0.152500</td>
      <td>0.146100</td>
      <td>0.297800</td>
      <td>0.325400</td>
      <td>0.171700</td>
      <td>0.283700</td>
      <td>0.545900</td>
      <td>0.396900</td>
      <td>0.554500</td>
      <td>0.043000</td>
      <td>0.262000</td>
      <td>0.054500</td>
      <td>0.271900</td>
      <td>0.020300</td>
      <td>0.230800</td>
      <td>0.077600</td>
      <td>0.308000</td>
    </tr>
    <tr>
      <td>7</td>
      <td>3.889400</td>
      <td>1.716169</td>
      <td>0.143500</td>
      <td>0.307700</td>
      <td>0.123200</td>
      <td>0.045800</td>
      <td>0.097800</td>
      <td>0.258300</td>
      <td>0.165300</td>
      <td>0.327700</td>
      <td>0.352600</td>
      <td>0.140900</td>
      <td>0.336700</td>
      <td>0.599400</td>
      <td>0.442900</td>
      <td>0.620700</td>
      <td>0.069400</td>
      <td>0.301300</td>
      <td>0.081600</td>
      <td>0.292000</td>
      <td>0.011000</td>
      <td>0.230800</td>
      <td>0.112700</td>
      <td>0.318200</td>
    </tr>
    <tr>
      <td>8</td>
      <td>3.889400</td>
      <td>1.679014</td>
      <td>0.153000</td>
      <td>0.355800</td>
      <td>0.127900</td>
      <td>0.038700</td>
      <td>0.115600</td>
      <td>0.291600</td>
      <td>0.176000</td>
      <td>0.322500</td>
      <td>0.349700</td>
      <td>0.135600</td>
      <td>0.326100</td>
      <td>0.643700</td>
      <td>0.431700</td>
      <td>0.582900</td>
      <td>0.069800</td>
      <td>0.265800</td>
      <td>0.088600</td>
      <td>0.274600</td>
      <td>0.028300</td>
      <td>0.280000</td>
      <td>0.146700</td>
      <td>0.345300</td>
    </tr>
    <tr>
      <td>9</td>
      <td>3.889400</td>
      <td>1.618239</td>
      <td>0.172100</td>
      <td>0.375300</td>
      <td>0.137600</td>
      <td>0.046100</td>
      <td>0.141700</td>
      <td>0.308500</td>
      <td>0.194000</td>
      <td>0.356200</td>
      <td>0.386200</td>
      <td>0.162400</td>
      <td>0.359200</td>
      <td>0.677700</td>
      <td>0.469800</td>
      <td>0.623900</td>
      <td>0.102100</td>
      <td>0.317700</td>
      <td>0.099100</td>
      <td>0.290200</td>
      <td>0.029300</td>
      <td>0.335400</td>
      <td>0.160200</td>
      <td>0.364000</td>
    </tr>
    <tr>
      <td>10</td>
      <td>1.599700</td>
      <td>1.572512</td>
      <td>0.179500</td>
      <td>0.400400</td>
      <td>0.147200</td>
      <td>0.056500</td>
      <td>0.141700</td>
      <td>0.316700</td>
      <td>0.213100</td>
      <td>0.357600</td>
      <td>0.381300</td>
      <td>0.197900</td>
      <td>0.344300</td>
      <td>0.638500</td>
      <td>0.466900</td>
      <td>0.623900</td>
      <td>0.101300</td>
      <td>0.311400</td>
      <td>0.104700</td>
      <td>0.279500</td>
      <td>0.051600</td>
      <td>0.338500</td>
      <td>0.173000</td>
      <td>0.353300</td>
    </tr>
    <tr>
      <td>11</td>
      <td>1.599700</td>
      <td>1.528889</td>
      <td>0.192200</td>
      <td>0.415000</td>
      <td>0.160800</td>
      <td>0.053700</td>
      <td>0.150500</td>
      <td>0.378000</td>
      <td>0.211500</td>
      <td>0.371700</td>
      <td>0.397800</td>
      <td>0.204900</td>
      <td>0.374600</td>
      <td>0.684800</td>
      <td>0.491900</td>
      <td>0.632400</td>
      <td>0.131200</td>
      <td>0.346800</td>
      <td>0.122000</td>
      <td>0.300900</td>
      <td>0.038400</td>
      <td>0.344600</td>
      <td>0.177500</td>
      <td>0.364400</td>
    </tr>
    <tr>
      <td>12</td>
      <td>1.599700</td>
      <td>1.517532</td>
      <td>0.198300</td>
      <td>0.429800</td>
      <td>0.159800</td>
      <td>0.066400</td>
      <td>0.162900</td>
      <td>0.383300</td>
      <td>0.220700</td>
      <td>0.382100</td>
      <td>0.405400</td>
      <td>0.214800</td>
      <td>0.383200</td>
      <td>0.672900</td>
      <td>0.469000</td>
      <td>0.610400</td>
      <td>0.167800</td>
      <td>0.379700</td>
      <td>0.119700</td>
      <td>0.307100</td>
      <td>0.038100</td>
      <td>0.335400</td>
      <td>0.196800</td>
      <td>0.394200</td>
    </tr>
    <tr>
      <td>13</td>
      <td>1.599700</td>
      <td>1.488849</td>
      <td>0.209800</td>
      <td>0.452300</td>
      <td>0.172300</td>
      <td>0.094900</td>
      <td>0.171100</td>
      <td>0.437800</td>
      <td>0.222000</td>
      <td>0.379800</td>
      <td>0.411500</td>
      <td>0.203800</td>
      <td>0.397300</td>
      <td>0.707500</td>
      <td>0.470700</td>
      <td>0.620700</td>
      <td>0.186900</td>
      <td>0.407600</td>
      <td>0.124200</td>
      <td>0.306700</td>
      <td>0.059300</td>
      <td>0.355400</td>
      <td>0.207700</td>
      <td>0.367100</td>
    </tr>
    <tr>
      <td>14</td>
      <td>1.599700</td>
      <td>1.482210</td>
      <td>0.228900</td>
      <td>0.482600</td>
      <td>0.187800</td>
      <td>0.083600</td>
      <td>0.191800</td>
      <td>0.444100</td>
      <td>0.225900</td>
      <td>0.376900</td>
      <td>0.407400</td>
      <td>0.182500</td>
      <td>0.384800</td>
      <td>0.700600</td>
      <td>0.512100</td>
      <td>0.640100</td>
      <td>0.175000</td>
      <td>0.363300</td>
      <td>0.144300</td>
      <td>0.300000</td>
      <td>0.083100</td>
      <td>0.363100</td>
      <td>0.229900</td>
      <td>0.370700</td>
    </tr>
    <tr>
      <td>15</td>
      <td>1.326800</td>
      <td>1.475198</td>
      <td>0.216300</td>
      <td>0.455600</td>
      <td>0.174900</td>
      <td>0.088500</td>
      <td>0.183500</td>
      <td>0.424400</td>
      <td>0.226900</td>
      <td>0.373400</td>
      <td>0.404300</td>
      <td>0.199200</td>
      <td>0.396400</td>
      <td>0.677800</td>
      <td>0.496300</td>
      <td>0.633800</td>
      <td>0.166300</td>
      <td>0.392400</td>
      <td>0.128900</td>
      <td>0.312900</td>
      <td>0.085200</td>
      <td>0.312300</td>
      <td>0.205000</td>
      <td>0.370200</td>
    </tr>
    <tr>
      <td>16</td>
      <td>1.326800</td>
      <td>1.459697</td>
      <td>0.233200</td>
      <td>0.504200</td>
      <td>0.192200</td>
      <td>0.096000</td>
      <td>0.202000</td>
      <td>0.430800</td>
      <td>0.239100</td>
      <td>0.382400</td>
      <td>0.412600</td>
      <td>0.219500</td>
      <td>0.403100</td>
      <td>0.670400</td>
      <td>0.485200</td>
      <td>0.625200</td>
      <td>0.196500</td>
      <td>0.410100</td>
      <td>0.135700</td>
      <td>0.299600</td>
      <td>0.123100</td>
      <td>0.356900</td>
      <td>0.225300</td>
      <td>0.371100</td>
    </tr>
    <tr>
      <td>17</td>
      <td>1.326800</td>
      <td>1.407340</td>
      <td>0.243400</td>
      <td>0.511900</td>
      <td>0.204500</td>
      <td>0.121000</td>
      <td>0.215700</td>
      <td>0.468000</td>
      <td>0.246200</td>
      <td>0.394600</td>
      <td>0.424200</td>
      <td>0.225900</td>
      <td>0.416100</td>
      <td>0.705200</td>
      <td>0.494900</td>
      <td>0.638300</td>
      <td>0.224900</td>
      <td>0.430400</td>
      <td>0.157200</td>
      <td>0.317900</td>
      <td>0.115700</td>
      <td>0.369200</td>
      <td>0.224200</td>
      <td>0.365300</td>
    </tr>
    <tr>
      <td>18</td>
      <td>1.326800</td>
      <td>1.419522</td>
      <td>0.245100</td>
      <td>0.521500</td>
      <td>0.210000</td>
      <td>0.116100</td>
      <td>0.211500</td>
      <td>0.489900</td>
      <td>0.255400</td>
      <td>0.391600</td>
      <td>0.419700</td>
      <td>0.198800</td>
      <td>0.421200</td>
      <td>0.701400</td>
      <td>0.501800</td>
      <td>0.634200</td>
      <td>0.226700</td>
      <td>0.410100</td>
      <td>0.154400</td>
      <td>0.321400</td>
      <td>0.105900</td>
      <td>0.352300</td>
      <td>0.236700</td>
      <td>0.380400</td>
    </tr>
    <tr>
      <td>19</td>
      <td>1.158600</td>
      <td>1.398764</td>
      <td>0.253600</td>
      <td>0.519200</td>
      <td>0.213600</td>
      <td>0.135200</td>
      <td>0.207700</td>
      <td>0.491900</td>
      <td>0.257300</td>
      <td>0.397300</td>
      <td>0.428000</td>
      <td>0.241400</td>
      <td>0.401800</td>
      <td>0.703500</td>
      <td>0.509700</td>
      <td>0.631100</td>
      <td>0.236700</td>
      <td>0.441800</td>
      <td>0.155900</td>
      <td>0.330800</td>
      <td>0.128100</td>
      <td>0.352300</td>
      <td>0.237500</td>
      <td>0.384000</td>
    </tr>
    <tr>
      <td>20</td>
      <td>1.158600</td>
      <td>1.390591</td>
      <td>0.248800</td>
      <td>0.520200</td>
      <td>0.216600</td>
      <td>0.127500</td>
      <td>0.211400</td>
      <td>0.471900</td>
      <td>0.258300</td>
      <td>0.407000</td>
      <td>0.429100</td>
      <td>0.240300</td>
      <td>0.407600</td>
      <td>0.708500</td>
      <td>0.505800</td>
      <td>0.623400</td>
      <td>0.235500</td>
      <td>0.431600</td>
      <td>0.150000</td>
      <td>0.325000</td>
      <td>0.125700</td>
      <td>0.375400</td>
      <td>0.227200</td>
      <td>0.390200</td>
    </tr>
    <tr>
      <td>21</td>
      <td>1.158600</td>
      <td>1.360608</td>
      <td>0.262700</td>
      <td>0.544800</td>
      <td>0.222100</td>
      <td>0.134700</td>
      <td>0.230000</td>
      <td>0.487500</td>
      <td>0.269500</td>
      <td>0.413300</td>
      <td>0.436300</td>
      <td>0.236200</td>
      <td>0.419100</td>
      <td>0.709300</td>
      <td>0.514100</td>
      <td>0.637400</td>
      <td>0.257200</td>
      <td>0.450600</td>
      <td>0.165100</td>
      <td>0.338400</td>
      <td>0.139400</td>
      <td>0.372300</td>
      <td>0.237700</td>
      <td>0.382700</td>
    </tr>
    <tr>
      <td>22</td>
      <td>1.158600</td>
      <td>1.368296</td>
      <td>0.262800</td>
      <td>0.542400</td>
      <td>0.236400</td>
      <td>0.137400</td>
      <td>0.228100</td>
      <td>0.498500</td>
      <td>0.266500</td>
      <td>0.409000</td>
      <td>0.433000</td>
      <td>0.239900</td>
      <td>0.418500</td>
      <td>0.697500</td>
      <td>0.520500</td>
      <td>0.641000</td>
      <td>0.257500</td>
      <td>0.455700</td>
      <td>0.162600</td>
      <td>0.334800</td>
      <td>0.140200</td>
      <td>0.353800</td>
      <td>0.233200</td>
      <td>0.379600</td>
    </tr>
    <tr>
      <td>23</td>
      <td>1.158600</td>
      <td>1.368176</td>
      <td>0.264800</td>
      <td>0.541100</td>
      <td>0.233100</td>
      <td>0.138200</td>
      <td>0.223900</td>
      <td>0.498700</td>
      <td>0.272300</td>
      <td>0.407400</td>
      <td>0.434400</td>
      <td>0.233100</td>
      <td>0.418300</td>
      <td>0.702000</td>
      <td>0.524400</td>
      <td>0.642300</td>
      <td>0.262300</td>
      <td>0.444300</td>
      <td>0.159700</td>
      <td>0.335300</td>
      <td>0.140500</td>
      <td>0.366200</td>
      <td>0.236900</td>
      <td>0.384000</td>
    </tr>
    <tr>
      <td>24</td>
      <td>1.049700</td>
      <td>1.355271</td>
      <td>0.269700</td>
      <td>0.549200</td>
      <td>0.239100</td>
      <td>0.134700</td>
      <td>0.229900</td>
      <td>0.519200</td>
      <td>0.274800</td>
      <td>0.412700</td>
      <td>0.437600</td>
      <td>0.245400</td>
      <td>0.417200</td>
      <td>0.711200</td>
      <td>0.523200</td>
      <td>0.644100</td>
      <td>0.272100</td>
      <td>0.440500</td>
      <td>0.166700</td>
      <td>0.341500</td>
      <td>0.137700</td>
      <td>0.373800</td>
      <td>0.249000</td>
      <td>0.388000</td>
    </tr>
    <tr>
      <td>25</td>
      <td>1.049700</td>
      <td>1.355180</td>
      <td>0.272500</td>
      <td>0.547900</td>
      <td>0.243800</td>
      <td>0.149700</td>
      <td>0.229900</td>
      <td>0.523100</td>
      <td>0.272500</td>
      <td>0.415700</td>
      <td>0.442200</td>
      <td>0.256200</td>
      <td>0.420200</td>
      <td>0.705800</td>
      <td>0.523900</td>
      <td>0.639600</td>
      <td>0.271700</td>
      <td>0.451900</td>
      <td>0.166300</td>
      <td>0.346900</td>
      <td>0.153700</td>
      <td>0.383100</td>
      <td>0.247000</td>
      <td>0.389300</td>
    </tr>
    <tr>
      <td>26</td>
      <td>1.049700</td>
      <td>1.349337</td>
      <td>0.275600</td>
      <td>0.556300</td>
      <td>0.246400</td>
      <td>0.146700</td>
      <td>0.234800</td>
      <td>0.516300</td>
      <td>0.274200</td>
      <td>0.418300</td>
      <td>0.440900</td>
      <td>0.248700</td>
      <td>0.418900</td>
      <td>0.705800</td>
      <td>0.523200</td>
      <td>0.636500</td>
      <td>0.274700</td>
      <td>0.440500</td>
      <td>0.172400</td>
      <td>0.349100</td>
      <td>0.155600</td>
      <td>0.384600</td>
      <td>0.252300</td>
      <td>0.393800</td>
    </tr>
    <tr>
      <td>27</td>
      <td>1.049700</td>
      <td>1.350782</td>
      <td>0.275200</td>
      <td>0.548700</td>
      <td>0.246800</td>
      <td>0.147300</td>
      <td>0.236400</td>
      <td>0.527200</td>
      <td>0.280100</td>
      <td>0.416200</td>
      <td>0.442600</td>
      <td>0.253400</td>
      <td>0.424000</td>
      <td>0.710300</td>
      <td>0.526600</td>
      <td>0.640100</td>
      <td>0.273200</td>
      <td>0.445600</td>
      <td>0.167000</td>
      <td>0.346900</td>
      <td>0.160100</td>
      <td>0.387700</td>
      <td>0.249200</td>
      <td>0.392900</td>
    </tr>
    <tr>
      <td>28</td>
      <td>1.049700</td>
      <td>1.346533</td>
      <td>0.277000</td>
      <td>0.552800</td>
      <td>0.252900</td>
      <td>0.147400</td>
      <td>0.240000</td>
      <td>0.527600</td>
      <td>0.280900</td>
      <td>0.420900</td>
      <td>0.444100</td>
      <td>0.255500</td>
      <td>0.424500</td>
      <td>0.711200</td>
      <td>0.530200</td>
      <td>0.646800</td>
      <td>0.277400</td>
      <td>0.441800</td>
      <td>0.170900</td>
      <td>0.346900</td>
      <td>0.156600</td>
      <td>0.389200</td>
      <td>0.249600</td>
      <td>0.396000</td>
    </tr>
    <tr>
      <td>29</td>
      <td>0.993700</td>
      <td>1.346575</td>
      <td>0.277100</td>
      <td>0.554800</td>
      <td>0.252900</td>
      <td>0.148400</td>
      <td>0.239700</td>
      <td>0.523600</td>
      <td>0.278400</td>
      <td>0.420000</td>
      <td>0.443300</td>
      <td>0.256300</td>
      <td>0.424000</td>
      <td>0.705600</td>
      <td>0.529600</td>
      <td>0.647300</td>
      <td>0.273900</td>
      <td>0.439200</td>
      <td>0.174300</td>
      <td>0.348700</td>
      <td>0.157600</td>
      <td>0.386200</td>
      <td>0.250100</td>
      <td>0.395100</td>
    </tr>
    <tr>
      <td>30</td>
      <td>0.993700</td>
      <td>1.346446</td>
      <td>0.277400</td>
      <td>0.554700</td>
      <td>0.252700</td>
      <td>0.147900</td>
      <td>0.240800</td>
      <td>0.523600</td>
      <td>0.278800</td>
      <td>0.420400</td>
      <td>0.443300</td>
      <td>0.256100</td>
      <td>0.424200</td>
      <td>0.705500</td>
      <td>0.530100</td>
      <td>0.646800</td>
      <td>0.275600</td>
      <td>0.440500</td>
      <td>0.174500</td>
      <td>0.348700</td>
      <td>0.157300</td>
      <td>0.386200</td>
      <td>0.249200</td>
      <td>0.394200</td>
    </tr>
  </tbody>
</table><p>

ุฅุฐุง ููุช ุจุชุนููู `push_to_hub` ุฅูู `True` ูู `training_args`ุ ูุชู ุฏูุน ููุงุท ุชุซุจูุช ุงูุชุฏุฑูุจ ุฅูู
Hub ุงูุฎุงุต ุจู Hugging Face. ุนูุฏ ุงูุชูุงู ุงูุชุฏุฑูุจุ ูู ุฃูุถูุง ุจุฏูุน ุงููููุฐุฌ ุงูููุงุฆู ุฅูู Hub ุนู ุทุฑูู ุงุณุชุฏุนุงุก ุทุฑููุฉ [`~transformers.Trainer.push_to_hub`].

```py
>>> trainer.push_to_hub()
```

## ุชูููู

```py
>>> from pprint import pprint

>>> metrics = trainer.evaluate(eval_dataset=cppe5["test"], metric_key_prefix="test")
>>> pprint(metrics)
{'epoch': 30.0ุ
  'test_loss': 1.0877351760864258ุ
  'test_map': 0.4116ุ
  'test_map_50': 0.741ุ
  'test_map_75': 0.3663ุ
  'test_map_Coverall': 0.5937ุ
  'test_map_Face_Shield': 0.5863ุ
  'test_map_Gloves': 0.3416ุ
  'test_map_Goggles': 0.1468ุ
  'test_map_Mask': 0.3894ุ
  'test_map_large': 0.5637ุ
  'test_map_medium': 0.3257ุ
  'test_map_small': 0.3589ุ
  'test_mar_1': 0.323ุ
  'test_mar_10': 0.5237ุ
  'test_mar_100': 0.5587ุ
  'test_mar_100_Coverall': 0.6756ุ
  'test_mar_100_Face_Shield': 0.7294ุ
  'test_mar_100_Gloves': 0.4721ุ
  'test_mar_100_Goggles': 0.4125ุ
  'test_mar_100_Mask': 0.5038ุ
  'test_mar_large': 0.7283ุ
  'test_mar_medium': 0.4901ุ
  'test_mar_small': 0.4469ุ
  'test_runtime': 1.6526ุ
  'test_samples_per_second': 17.548ุ
  'test_steps_per_second': 2.42}
```

ูููู ุชุญุณูู ูุฐู ุงููุชุงุฆุฌ ุนู ุทุฑูู ุถุจุท ูุฑุท ุงููุนููุงุช ูู [`TrainingArguments`]. ุฌุฑุจู!

## ุงูุงุณุชูุชุงุฌ

ุงูุขู ุจุนุฏ ุฃู ููุช ุจุถุจุท ูููุฐุฌุ ูุชูููููุ ูุชุญูููู ุฅูู Hub ุงูุฎุงุต ุจู Hugging Faceุ ููููู ุงุณุชุฎุฏุงูู ููุงุณุชูุชุงุฌ.

```py
>>> import torch
>>> import requests

>>> from PIL import Image, ImageDraw
>>> from transformers import AutoImageProcessor, AutoModelForObjectDetection

>>> url = "https://images.pexels.com/photos/8413299/pexels-photo-8413299.jpeg?auto=compress&cs=tinysrgb&w=630&h=375&dpr=2"
>>> image = Image.open(requests.get(url, stream=True).raw)
```

ูู ุจุชุญููู ุงููููุฐุฌ ููุนุงูุฌ ุงูุตูุฑ ูู Hub ุงูุฎุงุต ุจู Hugging Face (ุชุฎุทู ูุงุณุชุฎุฏุงู ูุง ุชู ุชุฏุฑูุจู ุจุงููุนู ูู ูุฐู ุงูุฌูุณุฉ):
```py
>>> device = "cuda"
>>> model_repo = "qubvel-hf/detr_finetuned_cppe5"

>>> image_processor = AutoImageProcessor.from_pretrained(model_repo)
>>> model = AutoModelForObjectDetection.from_pretrained(model_repo)
>>> model = model.to(device)
```

ููุดู ุญุฏูุฏ ุงูุตูุงุฏูู:

```py

>>> with torch.no_grad():
...     inputs = image_processor(images=[image], return_tensors="pt")
...     outputs = model(**inputs.to(device))
...     target_sizes = torch.tensor([[image.size[1], image.size[0]]])
...     results = image_processor.post_process_object_detection(outputs, threshold=0.3, target_sizes=target_sizes)[0]

>>> for score, label, box in zip(results["scores"], results["labels"], results["boxes"]):
...     box = [round(i, 2) for i in box.tolist()]
...     print(
...         f"Detected {model.config.id2label[label.item()]} with confidence "
...         f"{round(score.item(), 3)} at location {box}"
...     )
ุชู ุงููุดู ุนู ุงูููุงุฒุงุช ุจุซูุฉ 0.683 ูู ุงููููุน [244.58ุ 124.33ุ 300.35ุ 185.13]
ุชู ุงููุดู ุนู ููุงุน ุจุซูุฉ 0.517 ูู ุงููููุน [143.73ุ 64.58ุ 219.57ุ 125.89]
ุชู ุงููุดู ุนู ุงูููุงุฒุงุช ุจุซูุฉ 0.425 ูู ุงููููุน [179.15ุ 155.57ุ 262.4ุ 226.35]
ุชู ุงููุดู ุนู ุฑุฏุงุก ูุงูู ุจุซูุฉ 0.407 ูู ุงููููุน [307.13ุ -1.18ุ 477.82ุ 318.06]
ุชู ุงููุดู ุนู ุฑุฏุงุก ูุงูู ุจุซูุฉ 0.391 ูู ุงููููุน [68.61ุ 126.66ุ 309.03ุ 318.89]
```

ุฏุนููุง ูุฑุณู ุงููุชูุฌุฉ:

```py
>>> draw = ImageDraw.Draw(image)

>>> for score, label, box in zip(results["scores"], results["labels"], results["boxes"]):
...     box = [round(i, 2) for i in box.tolist()]
...     x, y, x2, y2 = tuple(box)
...     draw.rectangle((x, y, x2, y2), outline="red", width=1)
...     draw.text((x, y), model.config.id2label[label.item()], fill="white")

>>> image
```

<div class="flex justify-center">
    <img src="https://i.imgur.com/oDUqD0K.png" alt="ูุชูุฌุฉ ุงููุดู ุนู ุงููุงุฆูุงุช ุนูู ุตูุฑุฉ ุฌุฏูุฏุฉ"/>
</div>