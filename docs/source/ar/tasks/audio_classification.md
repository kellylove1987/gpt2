# ุชุตููู ุงูุตูุช

[[open-in-colab]]

<Youtube id="KWwzcmG98Ds"/>

ูุตูู ุชุตููู ุงูุตูุช - ุชูุงููุง ูุซู ุงููุต - ุชุณููุฉ ูุฆุฉ ุงูุฅุฎุฑุงุฌ ูู ุจูุงูุงุช ุงูุฅุฏุฎุงู. ูุงููุฑู ุงููุญูุฏ ูู ุจุฏูุงู ูู ุฅุฏุฎุงูุงุช ุงููุตุ ูุฏูู ุฃุดูุงู ููุฌูุฉ ุตูุชูุฉ ุฎุงู. ุชุดูู ุงูุชุทุจููุงุช ุงูุนูููุฉ ูุชุตููู ุงูุตูุช ุงูุชุนุฑู ุนูู ููุฉ ุงููุชุญุฏุซุ ูุชุตููู ุงููุบุฉุ ูุญุชู ุงูุฃููุงุน ุงูุญููุงููุฉ ูู ุฃุตูุงุชูุง.

ุณููุถุญ ูู ูุฐุง ุงูุฏููู ููููุฉ:

1. ุถุจุท ูููุฐุฌ [Wav2Vec2](https://huggingface.co/facebook/wav2vec2-base) ุงูุฏููู ุนูู ูุฌููุนุฉ ุจูุงูุงุช [MInDS-14](https://huggingface.co/datasets/PolyAI/minds14) ูุชุตููู ููุฉ ุงููุชุญุฏุซ.
2. ุงุณุชุฎุฏุงู ูููุฐุฌู ุงูุฏููู ููุงุณุชูุชุงุฌ.

<Tip>

ููุดุงูุฏุฉ ุฌููุน ุงูุจููุงุช ูููุงุท ุงูุชุญูู ุงููุชูุงููุฉ ูุน ูุฐู ุงููููุฉุ ููุตู ุจุงูุชุญูู ูู [ุตูุญุฉ ุงููููุฉ](https://huggingface.co/tasks/audio-classification)

</Tip>

ูุจู ุฃู ุชุจุฏุฃุ ุชุฃูุฏ ูู ุชุซุจูุช ุฌููุน ุงูููุชุจุงุช ุงูุถุฑูุฑูุฉ:

```bash
pip install transformers datasets evaluate
```

ูุดุฌุนู ุนูู ุชุณุฌูู ุงูุฏุฎูู ุฅูู ุญุณุงุจ Hugging Face ุงูุฎุงุต ุจู ุญุชู ุชุชููู ูู ุชุญููู ููุดุงุฑูุฉ ูููุฐุฌู ูุน ุงููุฌุชูุน. ุนูุฏูุง ููุทูุจ ููู ุฐููุ ุฃุฏุฎู ุฑูุฒู ููุชุณุฌูู:

```py
>>> from huggingface_hub import notebook_login

>>> notebook_login()
```

## ุชุญููู ูุฌููุนุฉ ุจูุงูุงุช MInDS-14

ุงุจุฏุฃ ุจุชุญููู ูุฌููุนุฉ ุจูุงูุงุช MInDS-14 ูู ููุชุจุฉ Datasets ๐ค:

```py
>>> from datasets import load_dataset, Audio

>>> minds = load_dataset("PolyAI/minds14", name="en-US", split="train")
```

ูุณููู ุชูุณูู "ุงูุชุฏุฑูุจ" ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุฅูู ูุฌููุนุฉ ุชุฏุฑูุจ ูุงุฎุชุจุงุฑ ุฃุตุบุฑ ุจุงุณุชุฎุฏุงู ุทุฑููุฉ [`~datasets.Dataset.train_test_split`]. ุณูุนุทูู ูุฐุง ูุฑุตุฉ ูุชุฌุฑุจุฉ ุงูุชุฃูุฏ ูู ุฃู ูู ุดูุก ูุนูู ูุจู ูุถุงุก ุงููุฒูุฏ ูู ุงูููุช ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงููุงููุฉ.

```py
>>> minds = minds.train_test_split(test_size=0.2)
```

ุซู ุงูู ูุธุฑุฉ ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช:

```py
>>> minds
DatasetDict({
    train: Dataset({
        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],
        num_rows: 450
    })
    test: Dataset({
        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],
        num_rows: 113
    })
})
```

ูู ุญูู ุฃู ูุฌููุนุฉ ุงูุจูุงูุงุช ุชุญุชูู ุนูู ุงููุซูุฑ ูู ุงููุนูููุงุช ุงููููุฏุฉุ ูุซู `lang_id` ู`english_transcription`ุ ูุณูู ุชุฑูุฒ ุนูู `audio` ู`intent_class` ูู ูุฐุง ุงูุฏููู. ุฃุฒู ุงูุฃุนูุฏุฉ ุงูุฃุฎุฑู ุจุงุณุชุฎุฏุงู ุทุฑููุฉ [`~datasets.Dataset.remove_columns`]:

```py
>>> minds = minds.remove_columns(["path", "transcription", "english_transcription", "lang_id"])
```

ุงูู ูุธุฑุฉ ุนูู ูุซุงู ุงูุขู:

```py
>>> minds["train"][0]
{'audio': {'array': array([ 0.        ,  0.        ,  0.        , ..., -0.00048828,
         -0.00024414, -0.00024414], dtype=float32),
  'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602b9a5fbb1e6d0fbce91f52.wav',
  'sampling_rate': 8000},
 'intent_class': 2}
```

ููุงู ุญููุงู:

- `audio`: ูุตูููุฉ ุฃุญุงุฏูุฉ ุงูุจุนุฏ ููุฅุดุงุฑุฉ ุงูุตูุชูุฉ ุงูุชู ูุฌุจ ุงุณุชุฏุนุงุคูุง ูุชุญููู ูุฅุนุงุฏุฉ ุฃุฎุฐ ุนููุงุช ููู ุงูุตูุช.
- `intent_class`: ููุซู ูุนุฑู ูุฆุฉ ููุฉ ุงููุชุญุฏุซ.

ููุชุณููู ุงูุฃูุฑ ุนูู ุงููููุฐุฌ ููุญุตูู ุนูู ุงุณู ุงูุชุณููุฉ ูู ูุนุฑู ุงูุชุณููุฉุ ูู ุจุฅูุดุงุก ูุงููุณ ูููู ุจุชุนููู ุงุณู ุงูุชุณููุฉ ุฅูู ุนุฏุฏ ุตุญูุญ ูุงูุนูุณ ุตุญูุญ:

```py
>>> labels = minds["train"].features["intent_class"].names
>>> label2id, id2label = dict(), dict()
>>> for i, label in enumerate(labels):
...     label2id[label] = str(i)
...     id2label[str(i)] = label
```

ุงูุขู ููููู ุชุญููู ูุนุฑู ุงูุชุณููุฉ ุฅูู ุงุณู ุงูุชุณููุฉ:

```py
>>> id2label[str(2)]
'app_error'
```

## ูุนุงูุฌุฉ ูุณุจูุฉ

ุงูุฎุทูุฉ ุงูุชุงููุฉ ูู ุชุญููู ูุณุชุฎุฑุฌ ููุฒุงุช Wav2Vec2 ููุนุงูุฌุฉ ุงูุฅุดุงุฑุฉ ุงูุตูุชูุฉ:

```py
>>> from transformers import AutoFeatureExtractor

>>> feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base")
```

ุชุญุชูู ูุฌููุนุฉ ุจูุงูุงุช MInDS-14 ุนูู ูุนุฏู ุฃุฎุฐ ุนููุงุช ูุจูุบ 8000 ูููู ูุฑุชุฒ (ููููู ุงูุนุซูุฑ ุนูู ูุฐู ุงููุนูููุงุช ูู [ุจุทุงูุฉ ูุฌููุนุฉ ุงูุจูุงูุงุช](https://huggingface.co/datasets/PolyAI/minds14))ุ ููุง ูุนูู ุฃูู ุณูุชุนูู ุนููู ุฅุนุงุฏุฉ ุฃุฎุฐ ุนููุงุช ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุฅูู 16000 ูููู ูุฑุชุฒ ูุงุณุชุฎุฏุงู ูููุฐุฌ Wav2Vec2 ุงููุฏุฑุจ ูุณุจููุง:

```py
>>> minds = minds.cast_column("audio", Audio(sampling_rate=16_000))
>>> minds["train"][0]
{'audio': {'array': array([ 2.2098757e-05,  4.6582241e-05, -2.2803260e-05, ...,
         -2.8419291e-04, -2.3305941e-04, -1.1425107e-04], dtype=float32),
  'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602b9a5fbb1e6d0fbce91f52.wav',
  'sampling_rate': 1600Multiplier: 1000
>>> minds = minds.cast_column("audio", Audio(sampling_rate=16_000))
>>> minds["train"][0]
{'audio': {'array': array([ 2.2098757e-05,  4.6582241e-05, -2.2803260e-05, ...,
         -2.8419291e-04, -2.3305941e-04, -1.1425107e-04], dtype=float32),
  'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602b9a5fbb1e6d0fbce91f52.wav',
  'sampling_rate': 16000},
 'intent_class': 2}
```

ุงูุขู ูู ุจุฅูุดุงุก ุฏุงูุฉ ูุนุงูุฌุฉ ูุณุจูุฉ ุชููู ุจูุง ููู:

1. ุงุณุชุฏุนุงุก ุนููุฏ "ุงูุตูุช" ูุชุญูููุ ูุฅุฐุง ูุฒู ุงูุฃูุฑุ ุฅุนุงุฏุฉ ุฃุฎุฐ ุนููุงุช ููู ุงูุตูุช.
2. ุงูุชุญูู ููุง ุฅุฐุง ูุงู ูุนุฏู ุฃุฎุฐ ุงูุนููุงุช ูููู ุงูุตูุช ูุชุทุงุจู ูุน ูุนุฏู ุฃุฎุฐ ุงูุนููุงุช ูุจูุงูุงุช ุงูุตูุช ุงูุชู ุชู ุชุฏุฑูุจ ุงููููุฐุฌ ุนูููุง. ููููู ุงูุนุซูุฑ ุนูู ูุฐู ุงููุนูููุงุช ูู [ุจุทุงูุฉ ูููุฐุฌ](https://huggingface.co/facebook/wav2vec2-base) Wav2Vec2.
3. ูู ุจุชุนููู ุทูู ุฅุฏุฎุงู ุฃูุตู ูุฏูุนุงุช ุงููุฏุฎูุงุช ุงูุฃุทูู ุฏูู ุงูุชุทุงุนูุง.

```py
>>> def preprocess_function(examples):
...     audio_arrays = [x["array"] for x in examples["audio"]]
...     inputs = feature_extractor(
...         audio_arrays, sampling_rate=feature_extractor.sampling_rate, max_length=16000, truncation=True
...     )
...     return inputs
```

ูุชุทุจูู ุฏุงูุฉ ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุจุฃููููุงุ ุงุณุชุฎุฏู ูุธููุฉ [`~datasets.Dataset.map`] ูู Datasets ๐ค. ููููู ุชุณุฑูุน `map` ุนู ุทุฑูู ุชุนููู `batched=True` ููุนุงูุฌุฉ ุนูุงุตุฑ ูุชุนุฏุฏุฉ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ูู ููุช ูุงุญุฏ. ุฃุฒู ุงูุฃุนูุฏุฉ ุงูุชู ูุง ุชุญุชุงุฌูุงุ ูุฃุนุฏ ุชุณููุฉ `intent_class` ุฅูู `label` ูุฃู ูุฐุง ูู ุงูุงุณู ุงูุฐู ูุชููุนู ุงููููุฐุฌ:

```py
>>> encoded_minds = minds.map(preprocess_function, remove_columns="audio", batched=True)
>>> encoded_minds = encoded_minds.rename_column("intent_class", "label")
```

## ุชูููู

ุบุงูุจูุง ูุง ูููู ุชุถููู ูููุงุณ ุฃุซูุงุก ุงูุชุฏุฑูุจ ูููุฏูุง ูุชูููู ุฃุฏุงุก ูููุฐุฌู. ููููู ุชุญููู ุทุฑููุฉ ุชูููู ุจุณุฑุนุฉ ุจุงุณุชุฎุฏุงู ููุชุจุฉ ๐ค [Evaluate](https://huggingface.co/docs/evaluate/index). ุจุงููุณุจุฉ ููุฐู ุงููููุฉุ ูู ุจุชุญููู ูููุงุณ [ุงูุฏูุฉ](https://huggingface.co/spaces/evaluate-metric/accuracy) (ุฑุงุฌุน ุฌููุฉ ๐ค Evaluate [ุงูุณุฑูุนุฉ](https://huggingface.co/docs/evaluate/a_quick_tour) ููุนุฑูุฉ ุงููุฒูุฏ ุญูู ููููุฉ ุชุญููู ูุญุณุงุจ ูููุงุณ):

```py
>>> import evaluate

>>> accuracy = evaluate.load("accuracy")
```

ุซู ูู ุจุฅูุดุงุก ุฏุงูุฉ ุชูุฑุฑ ุชูุจุคุงุชู ูุชุณููุงุชู ุฅูู [`~evaluate.EvaluationModule.compute`] ูุญุณุงุจ ุงูุฏูุฉ:

```py
>>> import numpy as np


>>> def compute_metrics(eval_pred):
...     predictions = np.argmax(eval_pred.predictions, axis=1)
...     return accuracy.compute(predictions=predictions, references=eval_pred.label_ids)
```

ุฏุงูุฉ `compute_metrics` ุงูุฎุงุตุฉ ุจู ุฌุงูุฒุฉ ุงูุขูุ ูุณุชุนูุฏ ุฅูููุง ุนูุฏ ุฅุนุฏุงุฏ ุงูุชุฏุฑูุจ ุงูุฎุงุต ุจู.

## ุชุฏุฑูุจ

<frameworkcontent>
<pt>
<Tip>

ุฅุฐุง ูู ุชูู ุนูู ุฏุฑุงูุฉ ุจุถุจุท ูููุฐุฌ ุจุงุณุชุฎุฏุงู [`Trainer`]]ุ ูุฑุงุฌุน ุงูุจุฑูุงูุฌ ุงูุชุนูููู ุงูุฃุณุงุณู [ููุง](../training#train-with-pytorch-trainer)!

</Tip>
<frameworkcontent>
<pt>
<Tip>

ุฅุฐุง ูู ุชูู ุนูู ุฏุฑุงูุฉ ุจุถุจุท ูููุฐุฌ ุจุงุณุชุฎุฏุงู [`Trainer`]]ุ ูุฑุงุฌุน ุงูุจุฑูุงูุฌ ุงูุชุนูููู ุงูุฃุณุงุณู [ููุง](../training#train-with-pytorch-trainer)!

</Tip>

ุฃูุช ูุณุชุนุฏ ุงูุขู ูุจุฏุก ุชุฏุฑูุจ ูููุฐุฌู! ูู ุจุชุญููู Wav2Vec2 ุจุงุณุชุฎุฏุงู [`AutoModelForAudioClassification`] ุฌูุจูุง ุฅูู ุฌูุจ ูุน ุนุฏุฏ ุงูุชุณููุงุช ุงููุชููุนุฉุ ูุฎุฑุงุฆุท ุงูุชุณููุงุช:

```py
>>> from transformers import AutoModelForAudioClassification, TrainingArguments, Trainer

>>> num_labels = len(id2label)
>>> model = AutoModelForAudioClassification.from_pretrained(
...     "facebook/wav2vec2-base", num_labels=num_labels, label2id=label2id, id2label=id2label
... )
```

ูู ูุฐู ุงููุฑุญูุฉุ ููุงู ุซูุงุซ ุฎุทูุงุช ููุท:

1. ุญุฏุฏ ูุฑุท ูุนููุงุช ุงูุชุฏุฑูุจ ุงูุฎุงุตุฉ ุจู ูู [`TrainingArguments`]. ุงููุนููุฉ ุงููุทููุจุฉ ุงููุญูุฏุฉ ูู `output_dir` ุงูุชู ุชุญุฏุฏ ููุงู ุญูุธ ูููุฐุฌู. ุณุชููู ุจุงูุฏูุน ุจูุฐุง ุงููููุฐุฌ ุฅูู Hub ุนู ุทุฑูู ุชุนููู `push_to_hub=True` (ูุฌุจ ุฃู ุชููู ูุณุฌู ุงูุฏุฎูู ุฅูู Hugging Face ูุชุญููู ูููุฐุฌู). ูู ููุงูุฉ ูู ุญูุจุฉุ ุณูููู [`Trainer`] ุจุชูููู ุงูุฏูุฉ ูุญูุธ ููุทุฉ ุงูุชุญูู ุงูุชุฏุฑูุจูุฉ.
2. ูู ุจุชูุฑูุฑ ุงูุญุฌุฌ ุงูุชุฏุฑูุจูุฉ ุฅูู [`Trainer`] ุฌูุจูุง ุฅูู ุฌูุจ ูุน ุงููููุฐุฌุ ููุฌููุนุฉ ุงูุจูุงูุงุชุ ููุนุงูุฌ ุงูุฑููุฒุ ูููู ุชุฌููุน ุงูุจูุงูุงุชุ ูุฏุงูุฉ `compute_metrics`.
3. ุงุณุชุฏุนุงุก [`~Trainer.train`] ูุถุจุท ูููุฐุฌู ุจุดูู ุฏููู.


```py
>>> training_args = TrainingArguments(
...     output_dir="my_awesome_mind_model",
...     eval_strategy="epoch",
...     save_strategy="epoch",
...     learning_rate=3e-5,
...     per_device_train_batch_size=32,
...     gradient_accumulation_steps=4,
...     per_device_eval_batch_Multiplier: 1000
>>> training_args = TrainingArguments(
...     output_dir="my_awesome_mind_model",
...     eval_strategy="epoch",
...     save_strategy="epoch",
...     learning_rate=3e-5,
...     per_device_train_batch_size=32,
...     gradient_accumulation_steps=4,
...     per_device_eval_batch_size=32,
...     num_train_epochs=10,
...     warmup_ratio=0.1,
...     logging_steps=10,
...     load_best_model_at_end=True,
...     metric_for_best_model="accuracy",
...     push_to_hub=True,
... )

>>> trainer = Trainer(
...     model=model,
...     args=training_args,
...     train_dataset=encoded_minds["train"],
...     eval_dataset=encoded_minds["test"],
...     tokenizer=feature_extractor,
...     compute_metrics=compute_metrics,
... )

>>> trainer.train()
```

ุจูุฌุฑุฏ ุงูุชูุงู ุงูุชุฏุฑูุจ ุดุงุฑู ูููุฐุฌู ูู Hub ุจุงุณุชุฎุฏุงู ุทุฑููุฉ [`~transformers.Trainer.push_to_hub`] ุญุชู ูุชููู ุงูุฌููุน ูู ุงุณุชุฎุฏุงู ูููุฐุฌู:

```py
>>> trainer.push_to_hub()
```
</pt>
</frameworkcontent>

<Tip>

ููุญุตูู ุนูู ูุซุงู ุฃูุซุฑ ุดูููุงู ุญูู ููููุฉ ุถุจุท ูููุฐุฌ ุฏููู ูุชุตููู ุงูุตูุชุ ุฑุงุฌุน ุงูุฏูุชุฑ [ุงูููุงุจู ูู PyTorch](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/audio_classification.ipynb).

</Tip>

## ุงูุงุณุชุฏูุงู

ุฑุงุฆุนุ ุงูุขู ุจุนุฏ ุฃู ุถุจุทุช ูููุฐุฌูุง ุฏููููุงุ ููููู ุงุณุชุฎุฏุงูู ููุงุณุชุฏูุงู!

ูู ุจุชุญููู ููู ุตูุชู ุชุฑูุฏ ุชุดุบูู ุงูุงุณุชุฏูุงู ุนููู. ุชุฐูุฑ ุฅุนุงุฏุฉ ุฃุฎุฐ ุนููุงุช ูุนุฏู ุฃุฎุฐ ุงูุนููุงุช ูููู ุงูุตูุช ููุทุงุจูุฉ ูุนุฏู ุฃุฎุฐ ุงูุนููุงุช ูููููุฐุฌ ุฅุฐุง ูุฒู ุงูุฃูุฑ!

```py
>>> from datasets import load_dataset, Audio

>>> dataset = load_dataset("PolyAI/minds14", name="en-US", split="train")
>>> dataset = dataset.cast_column("audio", Audio(sampling_rate=16000))
>>> sampling_rate = dataset.features["audio"].sampling_rate
>>> audio_file = dataset[0]["audio"]["path"]
```

ุฃุจุณุท ุทุฑููุฉ ูุชุฌุฑุจุฉ ูููุฐุฌู ุงูุฏููู ููุงุณุชุฏูุงู ูู ุงุณุชุฎุฏุงูู ูู [`pipeline`]. ูู ุจุชูููุฐ ูุซูู `pipeline` ูุชุตููู ุงูุตูุช ุจุงุณุชุฎุฏุงู ูููุฐุฌูุ ููุฑุฑ ููู ุงูุตูุช ุงูุฎุงุต ุจู ุฅููู:

```py
>>> from transformers import pipeline

>>> classifier = pipeline("audio-classification", model="stevhliu/my_awesome_minds_model")
>>> classifier(audio_file)
[
    {'score': 0.09766869246959686, 'label': 'cash_deposit'},
    {'score': 0.07998877018690109, 'label': 'app_error'},
    {'score': 0.0781070664525032, 'label': 'joint_account'},
    {'score': 0.07667109370231628, 'label': 'pay_bill'},
    {'score': 0.0755252093076706, 'label': 'balance'}
]
```

ููููู ุฃูุถูุง ุฅุนุงุฏุฉ ุฅูุชุงุฌ ูุชุงุฆุฌ `pipeline` ูุฏูููุง ุฅุฐุง ููุช ุชุฑูุฏ ุฐูู:

<frameworkcontent>
<pt>
ูู ุจุชุญููู ูุณุชุฎุฑุฌ ููุฒุงุช ููุนุงูุฌุฉ ููู ุงูุตูุช ูุฅุฑุฌุงุน `input` ูุฑููุฒ ุชุนุจูุฑูุฉ PyTorch:

```py
>>> from transformers import AutoFeatureExtractor

>>> feature_extractor = AutoFeatureExtractor.from_pretrained("stevhliu/my_awesome_minds_model")
>>> inputs = feature_extractor(dataset[0]["audio"]["array"], sampling_rate=sampling_rate, return_tensors="pt")
```

Pass your inputs to the model and return the logits:

```py
>>> from transformers import AutoModelForAudioClassification

>>> model = AutoModelForAudioClassification.from_pretrained("stevhliu/my_awesome_minds_model")
>>> with torch.no_grad():
...     logits = model(**inputs).logits
```

Get the class with the highest probability, and use the model's `id2label` mapping to convert it to a label:

```py
>>> import torch

>>> predicted_class_ids = torch.argmax(logits).item()
>>> predicted_label = model.config.id2label[predicted_class_ids]
>>> predicted_label
'cash_deposit'
```
</pt>
</frameworkcontent>