# ุงูุฅุฌุงุจุฉ ุนูู ุงูุฃุณุฆูุฉ ุงูุจุตุฑูุฉ

[[open-in-colab]]

ุงูุฅุฌุงุจุฉ ุนูู ุงูุฃุณุฆูุฉ ุงูุจุตุฑูุฉ (VQA) ูู ูููุฉ ุงูุฅุฌุงุจุฉ ุนูู ุงูุฃุณุฆูุฉ ุงูููุชูุญุฉ ุจูุงุกู ุนูู ุตูุฑุฉ. ุนุงุฏุฉู ูุง ูููู ุงูุฅุฏุฎุงู ุฅูู ุงูููุงุฐุฌ ุงูุชู ุชุฏุนู ูุฐู ุงููููุฉ ุนุจุงุฑุฉ ุนู ูุฒูุฌ ูู ุงูุตูุฑุฉ ูุงูุณุคุงูุ ูุงููุฎุฑุฌ ูู ุฅุฌุงุจุฉ ูุนุจุฑ ุนููุง ุจุงููุบุฉ ุงูุทุจูุนูุฉ.

ูููุง ููู ุจุนุถ ุฃูุซูุฉ ุญุงูุงุช ุงูุงุณุชุฎุฏุงู ุงูุฌุฏูุฑุฉ ุจุงูููุงุญุธุฉ ูู VQA:

- ุชุทุจููุงุช ุงููุตูู ููุณุงุนุฏุฉ ุงูุฃูุฑุงุฏ ุฐูู ุงูุฅุนุงูุฉ ุงูุจุตุฑูุฉ.
- ุงูุชุนููู: ุทุฑุญ ุฃุณุฆูุฉ ุญูู ุงูููุงุฏ ุงููุฑุฆูุฉ ุงูููุฏูุฉ ูู ุงููุญุงุถุฑุงุช ุฃู ุงููุชุจ ุงููุฏุฑุณูุฉ. ูููู ุฃูุถูุง ุงุณุชุฎุฏุงู VQA ูู ุงููุนุงุฑุถ ุงูุชูุงุนููุฉ ูู ุงููุชุงุญู ุฃู ุงูููุงูุน ุงูุชุงุฑูุฎูุฉ.
- ุฎุฏูุฉ ุงูุนููุงุก ูุงูุชุฌุงุฑุฉ ุงูุฅููุชุฑูููุฉ: ูููู ูู VQA ุชุนุฒูุฒ ุชุฌุฑุจุฉ ุงููุณุชุฎุฏู ูู ุฎูุงู ุงูุณูุงุญ ูููุณุชุฎุฏููู ุจุทุฑุญ ุฃุณุฆูุฉ ุญูู ุงูููุชุฌุงุช.
- ุงุณุชุฑุฌุงุน ุงูุตูุฑ: ูููู ุงุณุชุฎุฏุงู ููุงุฐุฌ VQA ูุงุณุชุฑุฏุงุฏ ุงูุตูุฑ ุฐุงุช ุงูุฎุตุงุฆุต ุงููุญุฏุฏุฉ. ุนูู ุณุจูู ุงููุซุงูุ ูููู ูููุณุชุฎุฏู ุฃู ูุณุฃู "ูู ููุงู ููุจุ" ููุนุซูุฑ ุนูู ุฌููุน ุงูุตูุฑ ุงูุชู ุชุญุชูู ุนูู ููุงุจ ูู ูุฌููุนุฉ ูู ุงูุตูุฑ.

ูู ูุฐุง ุงูุฏูููุ ุณุชุชุนูู ููููุฉ:

- ุถุจุท ูููุฐุฌ ุชุตููู VQAุ ูุชุญุฏูุฏูุง [ViLT]ุ ุนูู ูุฌููุนุฉ ุจูุงูุงุช [`Graphcore/vqa`]
- ุงุณุชุฎุฏุงู ViLT ุงููุถุจูุท ูุณุจููุง ููุงุณุชูุชุงุฌ.
- ุชุดุบูู ุงูุงุณุชุฏูุงู VQA ุจุฏูู ุจูุงูุงุช ุจุงุณุชุฎุฏุงู ูููุฐุฌ ุชูููุฏูุ ูุซู BLIP-2.

## ุถุจุท ViLT

ูุถู ูููุฐุฌ ViLT ุชุถููู ุงููุต ูู ูุญูู ุงูุฑุคูุฉ (ViT)ุ ููุง ูุณูุญ ูู ุจุชุตููู ุงูุญุฏ ุงูุฃุฏูู ููุชุนูู ุงููุณุจู ููุฑุคูุฉ ูุงููุบุฉ (VLP). ูููู ุงุณุชุฎุฏุงู ูุฐุง ุงููููุฐุฌ ูุนุฏุฉ ููุงู ุฃุณูู ุงูููุฑ. ููููุฉ VQAุ ูุชู ูุถุน ุฑุฃุณ ูุตูู ุฃุนูู (ุทุจูุฉ ุฎุทูุฉ ุฃุนูู ุงูุญุงูุฉ ุงููุฎููุฉ ุงูููุงุฆูุฉ ููุฑูุฒ `[CLS]`) ููุชู ุชููุฆุชูุง ุจุดูู ุนุดูุงุฆู. ูุจุงูุชุงููุ ูุชู ุงูุชุนุงูู ูุน ุงูุฅุฌุงุจุฉ ุนูู ุงูุฃุณุฆูุฉ ุงูุจุตุฑูุฉ ููุดููุฉ **ุชุตููู**.

ุชุชุนุงูู ุงูููุงุฐุฌ ุงูุฃุญุฏุซุ ูุซู BLIP ูBLIP-2 ูInstructBLIPุ ูุน VQA ููููุฉ ุชูููุฏูุฉ. ูู ููุช ูุงุญู ูู ูุฐุง ุงูุฏูููุ ููุถุญ ููููุฉ ุงุณุชุฎุฏุงููุง ููุงุณุชุฏูุงู VQA ุจุฏูู ุจูุงูุงุช.

ูุจู ุงูุจุฏุกุ ุชุฃูุฏ ูู ุชุซุจูุช ุฌููุน ุงูููุชุจุงุช ุงูุถุฑูุฑูุฉ.

```bash
pip install -q transformers datasets
```

ูุญู ูุดุฌุนู ุนูู ูุดุงุฑูุฉ ูููุฐุฌู ูุน ุงููุฌุชูุน. ูู ุจุชุณุฌูู ุงูุฏุฎูู ุฅูู ุญุณุงุจ Hugging Face ุงูุฎุงุต ุจู ูุชุญูููู ุฅูู ๐ค Hub.
ุนูุฏ ุงููุทุงูุจุฉุ ุฃุฏุฎู ุฑูุฒู ููุชุณุฌูู:

```py
>>> from huggingface_hub import notebook_login

>>> notebook_login()
```

ุฏุนูุง ูุญุฏุฏ ููุทุฉ ุชูุชูุด ุงููููุฐุฌ ููุชุบูุฑ ุนุงููู.

```py
>>> model_checkpoint = "dandelin/vilt-b32-mlm"
```

## ุชุญููู ุงูุจูุงูุงุช

ูุฃุบุฑุงุถ ุงูุชูุถูุญุ ูู ูุฐุง ุงูุฏูููุ ูุณุชุฎุฏู ุนููุฉ ุตุบูุฑุฉ ุฌุฏูุง ูู ูุฌููุนุฉ ุจูุงูุงุช ุงูุฅุฌุงุจุฉ ุนูู ุงูุฃุณุฆูุฉ ุงูุจุตุฑูุฉ ุงูููุนููููุฉ `Graphcore/vqa`.
ููููู ุงูุนุซูุฑ ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงููุงููุฉ ุนูู [๐ค Hub].

ูุจุฏูู ููุฌููุนุฉ ุจูุงูุงุช [`Graphcore/vqa`]]ุ ููููู ุชูุฒูู ููุณ ุงูุจูุงูุงุช ูุฏูููุง ูู ุตูุญุฉ ูุฌููุนุฉ ุจูุงูุงุช VQA ุงูุฑุณููุฉ. ุฅุฐุง ููุช ุชูุถู ุงุชุจุงุน ุงูุจุฑูุงูุฌ ุงูุชุนูููู ุจุงุณุชุฎุฏุงู ุจูุงูุงุชู ุงููุฎุตุตุฉุ ูุฑุงุฌุน ููููุฉ [ุฅูุดุงุก ูุฌููุนุฉ ุจูุงูุงุช ุงูุตูุฑ] ูู ูุซุงุฆู ๐ค Datasets.

ุฏุนูุง ูุญูู ุฃูู 200 ูุซุงู ูู ุงูุงููุณุงู ุงูุชุญูู ูู ุงูุตุญุฉ ูุงุณุชูุดุงู ููุฒุงุช ูุฌููุนุฉ ุงูุจูุงูุงุช:

```python
>>> from datasets import load_dataset

>>> dataset = load_dataset("Graphcore/vqa", split="validation[:200]")
>>> dataset
Dataset({
    features: ['question', 'question_type', 'question_id', 'image_id', 'answer_type', 'label'],
    num_rows: 200
})
```

ุฏุนูุง ูููู ูุธุฑุฉ ุนูู ูุซุงู ูููู ููุฒุงุช ูุฌููุนุฉ ุงูุจูุงูุงุช:

```py
>>> dataset[0]
{'question': 'Where is he looking?',
 'question_type': 'none of the above',
 'question_id': 262148000,
 'image_id': '/root/.cache/huggingface/datasets/downloads/extracted/ca733e0e000fb2d7a09fbcc94dbfe7b5a30750681d0e965f8e0a23b1c2f98c75/val2014/COCO_val2014_000000262148.jpg',
 'answer_type': 'other',
 'label': {'ids': ['at table', 'down', 'skateboard', 'table'],
  'weights': [0.30000001192092896,
   1.0,
   0.30000001192092896,
   0.30000001192092896]}}
```

ุงูููุฒุงุช ุฐุงุช ุงูุตูุฉ ุจุงููููุฉ ุชุดูู:

- `question`: ุงูุณุคุงู ุงูุฐู ูุฌุจ ุงูุฅุฌุงุจุฉ ุนููู ูู ุงูุตูุฑุฉ
- `image_id`: ูุณุงุฑ ุงูุตูุฑุฉ ุงูุชู ูุดูุฑ ุฅูููุง ุงูุณุคุงู
- `label`: ุงูุชุณููุงุช ุงูุชูุถูุญูุฉ

ูููููุง ุฅุฒุงูุฉ ุจููุฉ ุงูููุฒุงุช ุญูุซ ูู ุชููู ุถุฑูุฑูุฉ:

```py
>>> dataset = dataset.remove_columns(['question_type', 'question_id', 'answer_type'])
```

ููุง ุชุฑููุ ุชุญุชูู ููุฒุฉ `label` ุนูู ุนุฏุฉ ุฅุฌุงุจุงุช ูููุณ ุงูุณุคุงู (ุชุณูู `ids` ููุง) ุงูุชู ุฌูุนูุง ูุนููููู ุจุดุฑููู ูุฎุชูููู.
ูุฐุง ูุฃู ุฅุฌุงุจุฉ ุงูุณุคุงู ูููู ุฃู ุชููู ุฐุงุชูุฉ. ูู ูุฐู ุงูุญุงูุฉุ ุงูุณุคุงู ูู "ุฃูู ููุธุฑุ". ูุงู ุจุนุถ ุงูุฃุดุฎุงุต
ูุถุน ุนูุงูุฉ ุนูู ูุฐุง ุจู "down"ุ ูุงูุจุนุถ ุงูุขุฎุฑ ุจู "at table"ุ ูุขุฎุฑ ุจู "skateboard"ุ ุฅูุฎ.

ุงูู ูุธุฑุฉ ุนูู ุงูุตูุฑุฉ ูุงุนุชุจุฑ ุงูุฅุฌุงุจุฉ ุงูุชู ุณุชูุฏููุง:

```python
>>> from PIL import Image

>>> image = Image.open(dataset[0]['image_id'])
>>> image
```

<div class="flex justify-center">
     <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/vqa-example.png" alt="VQA Image Example"/>
</div>

ุจุณุจุจ ุบููุถ ุงูุฃุณุฆูุฉ ูุงูุฅุฌุงุจุงุชุ ุชุชู ูุนุงููุฉ ูุฌููุนุงุช ุงูุจูุงูุงุช ูุซู ูุฐู ููุดููุฉ ุชุตููู ูุชุนุฏุฏุฉ ุงูุชุตูููุงุช (ุญูุซ
ูุฏ ุชููู ุฅุฌุงุจุงุช ูุชุนุฏุฏุฉ ุตุงูุญุฉ). ุนูุงูุฉ ุนูู ุฐููุ ุจุฏูุงู ูู ุฅูุดุงุก ุชุฑููุฒ ุซูุงุฆูุ ูุชู ุฅูุดุงุก ุชุฑููุฒ ูุงุนูุ ุจูุงุกู ุนูู ุนุฏุฏ ุงููุฑุงุช
ุชูุช ุงูุฅุดุงุฑุฉ ุฅูู ุฅุฌุงุจุฉ ูุนููุฉ ูู ุงูุชุณููุงุช ุงูุชูุถูุญูุฉ.

ุนูู ุณุจูู ุงููุซุงูุ ูู ุงููุซุงู ุฃุนูุงูุ ูุฃู ุงูุฅุฌุงุจุฉ "down" ุชู ุชุญุฏูุฏูุง ุจุดูู ุฃูุจุฑ ุจูุซูุฑ ูู ุงูุฅุฌุงุจุงุช ุงูุฃุฎุฑูุ ููู ุชุญุชูู ุนูู
ุฏุฑุฌุฉ (ุชุณูู `weight` ูู ูุฌููุนุฉ ุงูุจูุงูุงุช) ูู 1.0ุ ูุจููุฉ ุงูุฅุฌุงุจุงุช ููุง ุฏุฑุฌุงุช <1.0.

ููุงุญูุงู ุฅูุดุงุก ุฑุฃุณ ุชุตููู ููุงุณุจ ูููููุฐุฌุ ุฏุนูุง ููุดุฆ ูุงููุณูู: ูุงุญุฏ ูููู ุจุชุนููู
ุงุณู ุงูุชุณููุฉ ุฅูู ุฑูู ุตุญูุญ ูุงูุนูุณ ุตุญูุญ:

```py
>>> import itertools

>>> labels = [item['ids'] for item in dataset['label']]
>>> flattened_labels = list(itertools.chain(*labels))
>>> unique_labels = list(set(flattened_labels))

>>> label2id = {label: idx for idx, label in enumerate(unique_labels)}
>>> id2label = {idx: label for label, idx in label2id.items()}
```

ุงูุขู ุจุนุฏ ุฃู ุญุตููุง ุนูู ุงูุฎุฑุงุฆุทุ ูููููุง ุงุณุชุจุฏุงู ุงูุฅุฌุงุจุงุช ุงููุตูุฉ ุจูุนุฑูุงุชูุงุ ูุชุณุทูุญ ูุฌููุนุฉ ุงูุจูุงูุงุช ููุฒูุฏ ูู ุงููุนุงูุฌุฉ ุงููุณุจูุฉ.

```python
>>> def replace_ids(inputs):
...   inputs["label"]["ids"] = [label2id[x] for x in inputs["label"]["ids"]]
...   return inputs


>>> dataset = dataset.map(replace_ids)
>>> flat_dataset = dataset.flatten()
>>> flat_dataset.features
{'question': Value(dtype='string', id=None),
 'image_id': Value(dtype='string', id=None),
 'label.ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),
 'label.weights': Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None)}
```

## ูุนุงูุฌุฉ ุงูุจูุงูุงุช ูุณุจููุง

ุงูุฎุทูุฉ ุงูุชุงููุฉ ูู ุชุญููู ูุนุงูุฌ ViLT ูุชุญุถูุฑ ุจูุงูุงุช ุงูุตูุฑุฉ ูุงููุต ูููููุฐุฌ.
[`ViltProcessor`] ูุฌูุน ุจูู ูุนุงูุฌ BERT ููุฑููุฒ ููุนุงูุฌ ุตูุฑ ViLT ูู ูุนุงูุฌ ูุงุญุฏ ููุงุณุจ:

```py
>>> from transformers import ViltProcessor

>>> processor = ViltProcessor.from_pretrained(model_checkpoint)
```

ููุนุงูุฌุฉ ุงูุจูุงูุงุชุ ูุญุชุงุฌ ุฅูู ุชุดููุฑ ุงูุตูุฑ ูุงูุฃุณุฆูุฉ ุจุงุณุชุฎุฏุงู [`ViltProcessor`]. ุณูุณุชุฎุฏู ุงููุนุงูุฌ
[`BertTokenizerFast`] ูุชูููููุฒ ุงููุต ูุฅูุดุงุก `input_ids` ู`attention_mask` ู`token_type_ids` ูุจูุงูุงุช ุงููุต.
ุฃูุง ุจุงููุณุจุฉ ููุตูุฑุ ูุณูุณุชููุฏ ุงููุนุงูุฌ ูู [`ViltImageProcessor`] ูุชุตุบูุฑ ุญุฌู ุงูุตูุฑุฉ ูุชุทุจูุนูุงุ ูุฅูุดุงุก `pixel_values` ู`pixel_mask`.

ูุชู ุชูููุฐ ุฌููุน ุฎุทูุงุช ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ูุฐู ุชููุงุฆููุงุ ููุง ูุญุชุงุฌ ุฅูุง ุฅูู ุงุณุชุฏุนุงุก `processor`. ููุน ุฐููุ ูุง ุฒููุง ุจุญุงุฌุฉ ุฅูู
ุฅุนุฏุงุฏ ุงูุชุณููุงุช ุงูุชูุถูุญูุฉ ุงููุณุชูุฏูุฉ. ูู ูุฐุง ุงูุชูุซููุ ูุชูุงูู ูู ุนูุตุฑ ูุน ุฅุฌุงุจุฉ ูุญุชููุฉ (ุชุณููุฉ). ููุฅุฌุงุจุงุช ุงูุตุญูุญุฉุ ูุญุชูู ุงูุนูุตุฑ ุนูู
ุฏุฑุฌุงุชูู (ุฃูุฒุงููู)ุ ุจูููุง ูุชู ุชุนููู ุงูุนูุงุตุฑ ุงููุชุจููุฉ ุฅูู ุงูุตูุฑ.

ุชููู ุงูุฏุงูุฉ ุงูุชุงููุฉ ุจุชุทุจูู `processor` ุนูู ุงูุตูุฑ ูุงูุฃุณุฆูุฉ ูุชูุณูู ุงูุชุณููุงุช ุงูุชูุถูุญูุฉ ููุง ูู ููุถุญ ุฃุนูุงู:

```py
>>> import torch

>>> def preprocess_data(examples):
...     image_paths = examples['image_id']
...     images = [Image.open(image_path) for image_path in image_paths]
...     texts = examples['question']

...     encoding = processor(images, texts, padding="max_length", truncation=True, return_tensors="pt")

...     for k, v in encoding.items():
...           encoding[k] = v.squeeze()

...     targets = []

...     for labels, scores in zip(examples['label.ids'], examples['label.weights']):
...         target = torch.zeros(len(id2label))

...         for label, score in zip(labels, scores):
...             target[label] = score

...         targets.append(target)

...     encoding["labels"] = targets

...     return encoding
```

ูุชุทุจูู ุฏุงูุฉ ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ุนูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุจุฃููููุงุ ุงุณุชุฎุฏู ูุธููุฉ [`~datasets.map`] ูู ๐ค Datasets. ููููู ุชุณุฑูุน `map` ุนู ุทุฑูู
ุชุนููู `batched=True` ููุนุงูุฌุฉ ุนุฏุฉ ุนูุงุตุฑ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ูู ููุช ูุงุญุฏ. ูู ูุฐู ุงููุฑุญูุฉุ ูุง ุชุชุฑุฏุฏ ูู ุฅุฒุงูุฉ ุงูุฃุนูุฏุฉ ุงูุชู ูุง ุชุญุชุงุฌูุง.

```py
>>> processed_dataset = flat_dataset.map(preprocess_data, batched=True, remove_columns=['question','question_type',  'question_id', 'image_id', 'answer_type', 'label.ids', 'label.weights'])
>>> processed_dataset
Dataset({
    features: ['input_ids', 'token_type_ids', 'attention_mask', 'pixel_values', 'pixel_mask', 'labels'],
    num_rows: 200
})
```

ูุฎุทูุฉ ุฃุฎูุฑุฉุ ูู ุจุฅูุดุงุก ุฏูุนุฉ ูู ุงูุฃูุซูุฉ ุจุงุณุชุฎุฏุงู [`DefaultDataCollator`]:

```py
>>> from transformers import DefaultDataCollator

>>> data_collator = DefaultDataCollator()
```

## ุชุฏุฑูุจ ุงููููุฐุฌ

ุฃูุช ูุณุชุนุฏ ุงูุขู ูุจุฏุก ุชุฏุฑูุจ ูููุฐุฌู! ูู ุจุชุญููู ViLT ุจุงุณุชุฎุฏุงู [`ViltForQuestionAnswering`]. ุญุฏุฏ ุนุฏุฏ ุงูุชุตูููุงุช
ุฌูุจุง ุฅูู ุฌูุจ ูุน ุงูุฎุฑุงุฆุท ุงูุชุตููู:

```py
>>> from transformers import ViltForQuestionAnswering

>>> model = ViltForQuestionAnswering.from_pretrained(model_checkpoint, num_labels=len(id2label), id2label=id2label, label2id=label2id)
```

ูู ูุฐู ุงููุฑุญูุฉุ ููุงู ุซูุงุซ ุฎุทูุงุช ููุท:

1. ุญุฏุฏ ูุนููุงุช ุงูุชุฏุฑูุจ ุงูุฎุงุตุฉ ุจู ูู [`TrainingArguments`]:

```py
>>> from transformers import TrainingArguments

>>> repo_id = "MariaK/vilt_finetuned_200"

>>> training_args = TrainingArguments(
...     output_dir=repo_id,
...     per_device_train_batch_Multiplier = 4,
...     num_train_epochs=20,
...     save_steps=200,
...     logging_steps=50,
...     learning_rate=5e-5,
...     save_total_limit=2,
...     remove_unused_columns=False,
...     push_to_hub=True,
... )
```

2. ูู ุจุชูุฑูุฑ ุงูุญุฌุฌ ุงูุชุฏุฑูุจูุฉ ุฅูู [`Trainer`] ุฌูุจูุง ุฅูู ุฌูุจ ูุน ุงููููุฐุฌ ููุฌููุนุฉ ุงูุจูุงูุงุช ูุงููุนุงูุฌ ููุนุงุฏู ุงูุจูุงูุงุช.

```py
>>> from transformers import Trainer

>>> trainer = Trainer(
...     model=model,
...     args=training_args,
...     data_collator=data_collator,
...     train_dataset=processed_dataset,
...     tokenizer=processor,
... )
```

3. ุงุณุชุฏุนุงุก [`~Trainer.train`] ูุถุจุท ูููุฐุฌู ุจุดูู ุฏููู.

```py
>>> trainer.train()
```

3. ุงุณุชุฏุนุงุก [`~Trainer.train`] ูุถุจุท ูููุฐุฌู ุจุดูู ุฏููู.

```py
>>> trainer.train()
```

ุจูุฌุฑุฏ ุงูุงูุชูุงุก ูู ุงูุชุฏุฑูุจุ ุดุงุฑู ูููุฐุฌู ุนูู Hub ุจุงุณุชุฎุฏุงู ุทุฑููุฉ [`~Trainer.push_to_hub`] ููุดุงุฑูุฉ ูููุฐุฌู ุงูููุงุฆู ุนูู ๐ค Hub:

```py
>>> trainer.push_to_hub()
```

## ุงูุงุณุชุฏูุงู

ุงูุขู ุจุนุฏ ุฃู ููุช ุจุถุจุท ูููุฐุฌ ViLT ูุชุญูููู ุฅูู ๐ค Hubุ ููููู ุงุณุชุฎุฏุงูู ููุงุณุชุฏูุงู. ุฃุณูู
ุทุฑููุฉ ูุชุฌุฑุจุฉ ูููุฐุฌู ุงููุถุจูุท ูุณุจููุง ููุงุณุชุฏูุงู ูู ุงุณุชุฎุฏุงูู ูู [`Pipeline`].

```py
>>> from transformers import pipeline

>>> pipe = pipeline("visual-question-answering", model="MariaK/vilt_finetuned_200")
```

ุชู ุชุฏุฑูุจ ุงููููุฐุฌ ูู ูุฐุง ุงูุฏููู ุนูู 200 ูุซุงู ููุทุ ูุฐุง ูุง ุชุชููุน ุงููุซูุฑ ููู. ุฏุนูุง ูุฑู ุฅุฐุง ูุงู ุนูู ุงูุฃูู
ุชุนูู ุดูุฆูุง ูู ุงูุจูุงูุงุช ูุฎุฐ ุงููุซุงู ุงูุฃูู ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ูุชูุถูุญ ุงูุงุณุชุฏูุงู:

```py
>>> example = dataset[0]
>>> image = Image.open(example['image_id'])
>>> question = example['question']
>>> print(question)
>>> pipe(image, question, top_k=1)
"Where is he looking?"
[{'score': 0.5498199462890625, 'answer': 'down'}]
```

ุนูู ุงูุฑุบู ูู ุนุฏู ุซูุชูุ ุฅูุง ุฃู ุงููููุฐุฌ ูุฏ ุชุนูู ุจุงููุนู ุดูุฆูุง ูุง. ูุน ุงููุฒูุฏ ูู ุงูุฃูุซูุฉ ููุชุฑุฉ ุงูุชุฏุฑูุจ ุงูุฃุทููุ ุณุชุญุตู ุนูู ูุชุงุฆุฌ ุฃูุถู ุจูุซูุฑ!

ููููู ุฃูุถูุง ุฅุนุงุฏุฉ ุฅูุชุงุฌ ูุชุงุฆุฌ ุงูุฃูุจูุจ ูุฏูููุง ุฅุฐุง ุฃุฑุฏุช:

1. ุฎุฐ ุตูุฑุฉ ูุณุคุงูุ ููู ุจุฅุนุฏุงุฏููุง ูููููุฐุฌ ุจุงุณุชุฎุฏุงู ุงููุนุงูุฌ ูู ูููุฐุฌู.
2. ูู ุจุชูููุฐ ุงูุฅุฎุฑุงุฌ ุฃู ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ูู ุฎูุงู ุงููููุฐุฌ.
3. ูู logitsุ ุงุญุตู ุนูู ูุนุฑู ุงูุฅุฌุงุจุฉ ุงูุฃูุซุฑ ุงุญุชูุงููุงุ ูุงุนุซุฑ ุนูู ุงูุฅุฌุงุจุฉ ุงููุนููุฉ ูู `id2label`.

```py
>>> processor = ViltProcessor.from_pretrained("MariaK/vilt_finetuned_200")

>>> image = Image.open(example['image_id'])
>>> question = example['question']

>>> # prepare inputs
>>> inputs = processor(image, question, return_tensors="pt")

>>> model = ViltForQuestionAnswering.from_pretrained("MariaK/vilt_finetuned_200")

>>> # forward pass
>>> with torch.no_grad():
...     outputs = model(**inputs)

>>> logits = outputs.logits
>>> idx = logits.argmax(-1).item()
>>> print("Predicted answer:", model.config.id2label[idx])
Predicted answer: down
```

## VQA ุจุฏูู ุชุฏุฑูุจ

ุนุงูู ุงููููุฐุฌ ุงูุณุงุจู VQA ููููุฉ ุชุตููู. ุจุนุถ ุงูููุงุฐุฌ ุงูุญุฏูุซุฉุ ูุซู BLIPุ ูBLIP-2ุ ูInstructBLIP ุชุนุงูุฌ VQA ููููุฉ ุชูููุฏูุฉ. ุฏุนููุง ูุฃุฎุฐ [BLIP-2](../model_doc/blip-2) ููุซุงู. ููุฏ ูุฏู ูููุฐุฌูุง ุฌุฏูุฏูุง ูููุฐุฌุฉ ุงููุบุฉ ุงููุฑุฆูุฉ ุญูุซ ูููู ุงุณุชุฎุฏุงู ุฃู ูุฒูุฌ ูู ูุดูุฑ ุงูุฑุคูุฉ LLM ููุดูุฑ ุงููุบุฉ ุงููุณุจู ุงูุชุฏุฑูุจ (ุชุนุฑู ุนูู ุงููุฒูุฏ ูู [ููุดูุฑ ุงููุฏููุฉ BLIP-2](https://huggingface.co/blog/blip-2)).

ูุฐุง ููููู ูู ุชุญููู ูุชุงุฆุฌ ุฑุงุฆุฏุฉ ุนูู ูุณุชูู ุงูููุงู ุงููุฑุฆูุฉ ุงููุบููุฉ ุงููุชุนุฏุฏุฉ ุจูุง ูู ุฐูู ุงูุฅุฌุงุจุฉ ุนูู ุงูุฃุณุฆูุฉ ุงูุจุตุฑูุฉ.

ุฏุนููุง ููุถุญ ููู ููููู ุงุณุชุฎุฏุงู ูุฐุง ุงููููุฐุฌ ูู VQA. ุฃููุงูุ ุฏุนููุง ูุญูู ุงููููุฐุฌ. ููุง ุณูุฑุณู ุงููููุฐุฌ ุจุดูู ุตุฑูุญ ุฅูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุชุ ุฅุฐุง ูุงูุช ูุชููุฑุฉุ ูุงูุชู ูู ููู ุจุญุงุฌุฉ ุฅูู ุงูููุงู ุจูุง ุณุงุจููุง ุฃุซูุงุก ุงูุชุฏุฑูุจุ ุญูุซ ูุชุนุงูู [`Trainer`] ูุน ูุฐุง ุชููุงุฆููุง:

```py
>>> from transformers import AutoProcessorุ Blip2ForConditionalGeneration
>>> import torch

>>> processor = AutoProcessor.from_pretrained("Salesforce/blip2-opt-2.7b")
>>> model = Blip2ForConditionalGeneration.from_pretrained("Salesforce/blip2-opt-2.7b"ุ torch_dtype=torch.float16)
>>> device = "cuda" if torch.cuda.is_available() else "cpu"
>>> model.to(device)
```

ูุฃุฎุฐ ุงููููุฐุฌ ุงูุตูุฑุฉ ูุงููุต ูุฅุฏุฎุงูุ ูุฐุง ุฏุนูุง ูุณุชุฎุฏู ููุณ ุงูุตูุฑุฉ/ุฒูุฌ ุงูุณุคุงู ุจุงูุถุจุท ูู ุงููุซุงู ุงูุฃูู ูู ูุฌููุนุฉ ุจูุงูุงุช VQA:

```py 
>>> example = dataset[0]
>>> image = Image.open(example['image_id'])
>>> question = example['question']
```

ูุงุณุชุฎุฏุงู BLIP-2 ููููุฉ ุงูุฅุฌุงุจุฉ ุนูู ุงูุฃุณุฆูุฉ ุงููุฑุฆูุฉุ ูุฌุจ ุฃู ูุชุจุน ุงููุต ุงูููุฑู ุชูุณูููุง ูุญุฏุฏูุง: `Question: {} Answer:`.

```py
>>> prompt = f"Question: {question} Answer:" 
```

ุงูุขู ูุญุชุงุฌ ุฅูู ูุนุงูุฌุฉ ุงูุตูุฑุฉ/ุงูููุฑูุฉ ุจุงุณุชุฎุฏุงู ูุนุงูุฌ ุงููููุฐุฌุ ูุชูุฑูุฑ ุงูุฅุฏุฎุงู ุงููุนุงูุฌ ุนุจุฑ ุงููููุฐุฌุ ููู ุชุดููุฑ ุงูุฅุฎุฑุงุฌ:

```py
>>> inputs = processor(imageุ text=promptุ return_tensors="pt").to(deviceุ torch.float16)

>>> generated_ids = model.generate(**inputsุ max_new_tokens=10)
>>> generated_text = processor.batch_decode(generated_idsุ skip_special_tokens=True)[0].strip()
>>> print(generated_text)
"ุฅูู ููุธุฑ ุฅูู ุงูุญุดุฏ" 
```

ููุง ุชุฑููุ ุชุนุฑู ุงููููุฐุฌ ุนูู ุงูุญุดุฏุ ูุงุชุฌุงู ุงููุฌู (ููุธุฑ ุฅูู ุงูุฃุณูู)ุ ููุน ุฐููุ ูุจุฏู ุฃูู ูุบูู ุนู ุญูููุฉ ุฃู ุงูุญุดุฏ ุฎูู ุงููุชุฒูุฌ. ููุน ุฐููุ ูู ุงูุญุงูุงุช ุงูุชู ูููู ูู ุบูุฑ ุงูุนููู ูููุง ุงูุญุตูู ุนูู ูุฌููุนุงุช ุจูุงูุงุช ุจุดุฑูุฉ ููุณููุฉุ ูููู ุฃู ููุชุฌ ูุฐุง ุงูููุฌ ูุชุงุฆุฌ ูููุฏุฉ ุจุณุฑุนุฉ.