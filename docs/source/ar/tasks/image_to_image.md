ูุฐุง ุฏููู ููููุฉ Image-to-Imageุ ูุงูุชู ูุชู ูููุง ุฅุฏุฎุงู ุตูุฑุฉ ุฅูู ุชุทุจูู ูุฅุฎุฑุงุฌ ุตูุฑุฉ ุฃุฎุฑู. ูุฏููุง ุงูุนุฏูุฏ ูู ุงูููุงู ุงููุฑุนูุฉุ ุจูุง ูู ุฐูู ุชุญุณูู ุงูุตูุฑุฉ (ุงููุฑุงุฑ ุงููุงุฆูุ ูุชุญุณูู ุงูุฅุถุงุกุฉ ุงูููุฎูุถุฉุ ูุฅุฒุงูุฉ ุงููุทุฑุ ูุบูุฑ ุฐูู)ุ ูุฅููุงู ุงูุตูุฑุฉุ ูุงููุฒูุฏ.

ุณููุถุญ ูุฐุง ุงูุฏููู ููููุฉ:

- ุงุณุชุฎุฏุงู ุฎุท ุฃูุงุจูุจ image-to-image ููููุฉ super resolution
- ุชุดุบูู ููุงุฐุฌ image-to-image ูููุณ ุงููููุฉ ุจุฏูู ุฎุท ุฃูุงุจูุจ

ููุงุญุธุฉ: ุงุนุชุจุงุฑูุง ูู ููุช ุฅุตุฏุงุฑ ูุฐุง ุงูุฏูููุ ูุฏุนู ุฎุท ุฃูุงุจูุจ "image-to-image" ูููุฉ super resolution ููุท.

ููุจุฏุฃ ุจุชุซุจูุช ุงูููุชุจุงุช ุงููุงุฒูุฉ.

```bash
pip install transformers
```

ูููููุง ุงูุขู ุชููุฆุฉ ุฎุท ุงูุฃูุงุจูุจ ุจุงุณุชุฎุฏุงู ูููุฐุฌ [Swin2SR](https://huggingface.co/caidas/swin2SR-lightweight-x2-64). ุจุนุฏ ุฐููุ ูููููุง ุฅุฌุฑุงุก ุงูุงุณุชุฏูุงู ุจุงุณุชุฎุฏุงู ุฎุท ุงูุฃูุงุจูุจ ุนู ุทุฑูู ุงุณุชุฏุนุงุฆู ูุน ุตูุฑุฉ. ูู ุงูููุช ุงูุญุงููุ ุชุฏุนู ุฎุทูุท ุงูุฃูุงุจูุจ ูุฐู ููุท ููุงุฐุฌ [Swin2SR](https://huggingface.co/models?sort=trending&search=swin2sr).

```python
from transformers import pipeline

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
pipe = pipeline(task="image-to-image", model="caidas/swin2SR-lightweight-x2-64", device=device)
```

ุงูุขูุ ุฏุนูุง ูููู ุจุชุญููู ุตูุฑุฉ.

```python
from PIL import Image
import requests

url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/cat.jpg"
image = Image.open(requests.get(url, stream=True).raw)

print(image.size)
```
```bash
# (532, 432)
```
<div class="flex justify-center">
     <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/cat.jpg" alt="ุตูุฑุฉ ููุทุฉ"/>
</div>

ูููููุง ุงูุขู ุฅุฌุฑุงุก ุงูุงุณุชุฏูุงู ุจุงุณุชุฎุฏุงู ุฎุท ุงูุฃูุงุจูุจ. ุณูุญุตู ุนูู ูุณุฎุฉ ููุณุนุฉ ูู ุตูุฑุฉ ุงููุทุฉ.

```python
upscaled = pipe(image)
print(upscaled.size)
```
```bash
# (1072, 880)
```

ุฅุฐุง ููุช ุชุฑุบุจ ูู ุฅุฌุฑุงุก ุงูุงุณุชุฏูุงู ุจููุณู ุจุฏูู ุฎุท ุฃูุงุจูุจุ ูููููู ุงุณุชุฎุฏุงู ุงููุฆุงุช `Swin2SRForImageSuperResolution` ู`Swin2SRImageProcessor` ูู ููุชุจุฉ Transformers. ุณูุณุชุฎุฏู ููุณ ููุทุฉ ุชูุชูุด ุงููููุฐุฌ ููุฐุง ุงูุบุฑุถ. ุฏุนููุง ูููู ุจุชููุฆุฉ ุงููููุฐุฌ ูุงููุนุงูุฌ.

```python
from transformers import Swin2SRForImageSuperResolution, Swin2SRImageProcessor

model = Swin2SRForImageSuperResolution.from_pretrained("caidas/swin2SR-lightweight-x2-64").to(device)
processor = Swin2SRImageProcessor("caidas/swin2SR-lightweight-x2-64")
```

ูููู `pipeline` ุจุชุจุณูุท ุฎุทูุงุช ูุง ูุจู ุงููุนุงูุฌุฉ ููุง ุจุนุฏ ุงููุนุงูุฌุฉ ุงูุชู ูุชุนูู ุนูููุง ุงูููุงู ุจูุง ุจุฃููุณูุงุ ูุฐูู ุฏุนูุง ูููู ุจูุนุงูุฌุฉ ุงูุตูุฑุฉ ูุณุจููุง. ุณูููู ุจุชูุฑูุฑ ุงูุตูุฑุฉ ุฅูู ุงููุนุงูุฌุ ุซู ููู ููู ุงูุจูุณู ุฅูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช (GPU).

```python
pixel_values = processor(image, return_tensors="pt").pixel_values
print(pixel_values.shape)

pixel_values = pixel_values.to(device)
```

ุงูุขู ูููููุง ุงุณุชูุชุงุฌ ุงูุตูุฑุฉ ุนู ุทุฑูู ุชูุฑูุฑ ููู ุงูุจูุณู ุฅูู ุงููููุฐุฌ.

```python
import torch

with torch.no_grad():
  outputs = model(pixel_values)
```
ุงูุฅุฎุฑุงุฌ ุนุจุงุฑุฉ ุนู ูุงุฆู ูู ุงูููุน `ImageSuperResolutionOutput` ูุจุฏู ููุง ููู ๐

```python
import torch

with torch.no_grad():
  outputs = model(pixel_values)
```
ุงูุฅุฎุฑุงุฌ ุนุจุงุฑุฉ ุนู ูุงุฆู ูู ุงูููุน `ImageSuperResolutionOutput` ูุจุฏู ููุง ููู ๐

```
(loss=None, reconstruction=tensor([[[[0.8270, 0.8269, 0.8275,  ..., 0.7463, 0.7446, 0.7453],
          [0.8287, 0.8278, 0.8283,  ..., 0.7451, 0.7448, 0.7457],
          [0.8280, 0.8273, 0.8269,  ..., 0.7447, 0.7446, 0.7452],
          ...,
          [0.5923, 0.5933, 0.5924,  ..., 0.0697, 0.0695, 0.0706],
          [0.5926, 0.5932, 0.5926,  ..., 0.0673, 0.0687, 0.0705],
          [0.5927, 0.5914, 0.5922,  ..., 0.0664, 0.0694, 0.0718]]]],
       device='cuda:0'), hidden_states=None, attentions=None)
```
ูุญุชุงุฌ ุฅูู ุงูุญุตูู ุนูู `reconstruction` ููุนุงูุฌุชูุง ุจุนุฏ ุงููุนุงูุฌุฉ ูู ุฃุฌู ุงูุนุฑุถ ุงููุฑุฆู. ุฏุนููุง ูุฑู ููู ุชุจุฏู.

```python
outputs.reconstruction.data.shape
# torch.Size([1, 3, 880, 1072])
```

ูุญุชุงุฌ ุฅูู ุถุบุท ุงูุฅุฎุฑุงุฌ ูุงูุชุฎูุต ูู ุงููุญูุฑ 0ุ ููุต ุงููููุ ุซู ุชุญููููุง ุฅูู float ูููุจู. ุจุนุฏ ุฐููุ ุณูููู ุจุชุฑุชูุจ ุงููุญุงูุฑ ุจุญูุซ ูููู ุงูุดูู [1072ุ 880]ุ ูุฃุฎูุฑุงูุ ุฅุนุงุฏุฉ ุฅุฎุฑุงุฌ ุงูููู ุฅูู ุงููุทุงู [0ุ 255].

```python
import numpy as np

# ุถุบุทุ ูููู ุฅูู ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉุ ููุต ุงูููู
output = outputs.reconstruction.data.squeeze().cpu().clamp_(0, 1).numpy()
# ุฅุนุงุฏุฉ ุชุฑุชูุจ ุงููุญุงูุฑ
output = np.moveaxis(output, source=0, destination=-1)
# ุฅุนุงุฏุฉ ุงูููู ุฅูู ูุทุงู ููู ุงูุจูุณู
output = (output * 255.0).round().astype(np.uint8)
Image.fromarray(output)
```
<div class="flex justify-center">
     <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/cat_upscaled.png" alt="ุตูุฑุฉ ููุจุฑุฉ ููุทุฉ"/>
</div>