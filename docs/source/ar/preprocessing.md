# ูุนุงูุฌุฉ ูุณุจูุฉ

[[open-in-colab]]

ูุจู ุฃู ุชุชููู ูู ุชุฏุฑูุจ ูููุฐุฌ ุนูู ูุฌููุนุฉ ุจูุงูุงุชุ ูุฌุจ ูุนุงูุฌุชูุง ูุณุจููุง ุฅูู ุชูุณูู ุฅุฏุฎุงู ุงููููุฐุฌ ุงููุชููุน. ุณูุงุก ูุงูุช ุจูุงูุงุชู ูุตูุฉ ุฃู ุตูุฑูุง ุฃู ุตูุชูุงุ ููุฌุจ ุชุญููููุง ูุชุฌููุนูุง ูู ุฏูุนุงุช ูู ุงูููุณูุฌุงุช. ูููุฑ ๐ค Transformers ูุฌููุนุฉ ูู ูุฆุงุช ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ูููุณุงุนุฏุฉ ูู ุฅุนุฏุงุฏ ุจูุงูุงุชู ูููููุฐุฌ. ูู ูุฐุง ุงูุจุฑูุงูุฌ ุงูุชุนููููุ ุณุชุชุนูู ุฃูู ุจุงููุณุจุฉ ูู:

* ูููุตุ ุงุณุชุฎุฏู [ููุนุฑููู ุงูุฑููุฒ](./main_classes/tokenizer) ูุชุญููู ุงููุต ุฅูู ุชุณูุณู ูู ุงูุฑููุฒุ ูุฅูุดุงุก ุชูุซูู ุฑููู ููุฑููุฒุ ูุชุฌููุนูุง ูู ููุณูุฌุงุช.
* ููููุงู ูุงูุตูุชุ ุงุณุชุฎุฏู [ูุณุชุฎุฑุฌ ุงูููุฒุงุช](./main_classes/feature_extractor) ูุงุณุชุฎุฑุงุฌ ููุฒุงุช ูุชุณูุณูุฉ ูู ุฃุดูุงู ููุฌุงุช ุงูุตูุช ูุชุญููููุง ุฅูู ููุณูุฌุงุช.
* ุชุณุชุฎุฏู ูุฏุฎูุงุช ุงูุตูุฑุฉ [ImageProcessor](./main_classes/image_processor) ูุชุญููู ุงูุตูุฑ ุฅูู ููุณูุฌุงุช.
* ุชุณุชุฎุฏู ุงูุฅุฏุฎุงูุงุช ูุชุนุฏุฏุฉ ุงููุณุงุฆุท [ูุนุงูุฌูุง](./main_classes/processors) ูุฏูุฌ ููุนุฑููู ุงูุฑููุฒ ููุณุชุฎุฑุฌ ุงูููุฒุงุช ุฃู ูุนุงูุฌ ุงูุตูุฑ.

<Tip>

`AutoProcessor` **ูุนูู ุฏุงุฆููุง** ููุฎุชุงุฑ ุชููุงุฆููุง ุงููุฆุฉ ุงูุตุญูุญุฉ ูููููุฐุฌ ุงูุฐู ุชุณุชุฎุฏููุ ุณูุงุก ููุช ุชุณุชุฎุฏู ููุนุฑููู ุฑููุฒ ุฃู ูุนุงูุฌ ุตูุฑ ุฃู ูุณุชุฎุฑุฌ ููุฒุงุช ุฃู ูุนุงูุฌูุง.

</Tip>

ูุจู ุงูุจุฏุกุ ูู ุจุชุซุจูุช ๐ค Datasets ุญุชู ุชุชููู ูู ุชุญููู ุจุนุถ ูุฌููุนุงุช ุงูุจูุงูุงุช ูุชุฌุฑุจุชูุง:

```bash
pip install datasets
```

## ูุนุงูุฌุฉ ุงููุบุฉ ุงูุทุจูุนูุฉ

<Youtube id="Yffk5aydLzg"/>

ุฃุฏุงุฉ ุงููุนุงูุฌุฉ ุงููุณุจูุฉ ุงูุฑุฆูุณูุฉ ููุจูุงูุงุช ุงููุตูุฉ ูู [ููุนุฑููู ุงูุฑููุฒ](main_classes/tokenizer). ูููู ููุนุฑููู ุงูุฑููุฒ ุจุชูุณูู ุงููุต ุฅูู *ุฑููุฒ* ููููุง ููุฌููุนุฉ ูู ุงูููุงุนุฏ. ูุชู ุชุญููู ุงูุฑููุฒ ุฅูู ุฃุฑูุงู ุซู ุฅูู ููุณูุฌุงุชุ ูุงูุชู ุชุตุจุญ ุฅุฏุฎุงูุงุช ุงููููุฐุฌ. ุชุชู ุฅุถุงูุฉ ุฃู ุฅุฏุฎุงูุงุช ุฅุถุงููุฉ ูุทููุจุฉ ุจูุงุณุทุฉ ุงููููุฐุฌ ุจูุงุณุทุฉ ููุนุฑููู ุงูุฑููุฒ.

<Tip>

ุฅุฐุง ููุช ุชุฎุทุท ูุงุณุชุฎุฏุงู ูููุฐุฌ ููุฏุฑุจ ูุณุจููุงุ ููู ุงูููู ุงุณุชุฎุฏุงู ููุนุฑููู ุงูุฑููุฒ ุงูููุฏุฑุจ ูุณุจููุง ุงูููุชุฑู ุจู. ูุถูู ุฐูู ุชูุณูู ุงููุต ุจููุณ ุงูุทุฑููุฉ ุงูุชู ุชู ุจูุง ุชูุณูู ูุฌููุนุฉ ุจูุงูุงุช ูุง ูุจู ุงูุชุฏุฑูุจุ ูุงุณุชุฎุฏุงู ููุณ ุงูุฑููุฒ ุงูููุงุจูุฉ ููููุฑุณ (ููุดุงุฑ ุฅูููุง ุนุงุฏุฉู ุจุงุณู *vocab*) ุฃุซูุงุก ุงูุชุฏุฑูุจ ุงููุณุจู.

</Tip>

ุงุจุฏุฃ ุจุชุญููู ููุนุฑููู ุฑููุฒ ููุฏุฑุจ ูุณุจููุง ุจุงุณุชุฎุฏุงู ุทุฑููุฉ [`AutoTokenizer.from_pretrained`]. ูููู ูุฐุง ุจุชูุฒูู *vocab* ุงูุฐู ุชู ุชุฏุฑูุจ ุงููููุฐุฌ ุนููู:

```py
>>> from transformers import AutoTokenizer

>>> tokenizer = AutoTokenizer.from_pretrained("google-bert/bert-base-cased")
```

ุซู ูุฑุฑ ูุตู ุฅูู ููุนุฑููู ุงูุฑููุฒ:

```py
>>> encoded_input = tokenizer("Do not meddle in the affairs of wizards, for they are subtle and quick to anger.")
>>> print(encoded_input)
{'input_ids': [101, 2079, 2025, 19960, 10362, 1999, 1996, 3821, 1997, 16657, 1010, 2005, 2027, 2024, 11259, 1998, 4248, 2000, 4963, 1012, 102],
 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
```

ูุนูุฏ ููุนุฑููู ุงูุฑููุฒ ูุงููุณูุง ูุญุชูู ุนูู ุซูุงุซุฉ ุนูุงุตุฑ ูููุฉ:

* [input_ids](glossary#input-ids) ูู ุงูููุงุฑุณ ุงูููุงุจูุฉ ููู ุฑูุฒ ูู ุงูุฌููุฉ.
* [attention_mask](glossary#attention-mask) ูุดูุฑ ุฅูู ูุง ุฅุฐุง ูุงู ูุฌุจ ุงูุงูุชูุงู ุจุงูุฑูุฒ ุฃู ูุง.
* [token_type_ids](glossary#token-type-ids) ูุญุฏุฏ ุงูุชุณูุณู ุงูุฐู ููุชูู ุฅููู ุงูุฑูุฒ ุนูุฏูุง ูููู ููุงู ุฃูุซุฑ ูู ุชุณูุณู ูุงุญุฏ.

ุฃุนุฏ ุฅุฏุฎุงูู ุนู ุทุฑูู ูู ุชุฑููุฒ `input_ids`:
ุฃุนุฏ ุฅุฏุฎุงูู ุนู ุทุฑูู ูู ุชุฑููุฒ `input_ids`:

```py
>>> tokenizer.decode(encoded_input["input_ids"])
'[CLS] Do not meddle in the affairs of wizards, for they are subtle and quick to anger. [SEP]'
```

ููุง ุชุฑูุ ุฃุถุงู ููุนุฑููู ุงูุฑููุฒ ุฑูุฒูู ุฎุงุตูู - `CLS` ู`SEP` (ูุตูู ููุงุตู) - ุฅูู ุงูุฌููุฉ. ูุง ุชุญุชุงุฌ ุฌููุน ุงูููุงุฐุฌ ุฅูู
ุฑููุฒ ุฎุงุตุฉุ ูููู ุฅุฐุง ูุนููุง ุฐููุ ูุฅู ููุนุฑููู ุงูุฑููุฒ ูุถูููุง ุชููุงุฆููุง ูู.

ุฅุฐุง ูุงู ููุงู ุนุฏุฉ ุฌูู ุชุฑูุฏ ูุนุงูุฌุชูุง ูุณุจููุงุ ููู ุจุชูุฑูุฑูุง ููุงุฆูุฉ ุฅูู ููุนุฑููู ุงูุฑููุฒ:

```py
>>> batch_sentences = [
...     "But what about second breakfast?",
...     "Don't think he knows about second breakfast, Pip.",
...     "What about elevensies?",
... ]
>>> encoded_inputs = tokenizer(batch_sentences)
>>> print(encoded_inputs)
{'input_ids': [[101, 1252, 1184, 1164, 1248, 6462, 136, 102],
               [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102],
               [101, 1327, 1164, 5450, 23434, 136, 102]],
 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0],
                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                    [0, 0, 0, 0, 0, 0, 0]],
 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1],
                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
                    [1, 1, 1, 1, 1, 1, 1]]}
```

### ุงูุญุดู Padding

ููุณุช ุงูุฌูู ุฏุงุฆููุง ุจููุณ ุงูุทููุ ูุงูุฐู ูููู ุฃู ูููู ูุดููุฉ ูุฃู ุงูููุณูุฌุงุชุ ุฅุฏุฎุงูุงุช ุงููููุฐุฌุ ุชุญุชุงุฌ ุฅูู ุดูู ููุญุฏ. ุงูุชุจุทูู ูู ุงุณุชุฑุงุชูุฌูุฉ ูุถูุงู ุฃู ุชููู ุงูููุณูุฌุงุช ูุณุชุทููุฉ ุนู ุทุฑูู ุฅุถุงูุฉ ุฑูุฒ *padding* ุฎุงุต ุฅูู ุงูุฌูู ุงูุฃูุตุฑ.

ูู ุจุชุนููู ูุนููุฉ `padding` ุฅูู `True` ูุชุจุทูู ุงูุชุณูุณูุงุช ุงูุฃูุตุฑ ูู ุงูุฏูุนุฉ ููุทุงุจูุฉ ุงูุชุณูุณู ุงูุฃุทูู:

```py
>>> batch_sentences = [
...     "But what about second breakfast?",
...     "Don't think he knows about second breakfast, Pip.",
...     "What about elevensies?",
... ]
>>> encoded_input = tokenizer(batch_sentences, padding=True)
>>> print(encoded_input)
{'input_ids': [[101, 1252, 1184, 1164, 1248, 6462, 136, 102, 0, 0, 0, 0, 0, 0, 0],
               [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102],
               [101, 1327, 1164, 5450, 23434, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0]],
 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],
 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],
                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
                    [1, 1, Multiplier, 1, 1, 1, 1, 0ุ 0ุ 0ุ 0ุ 0ุ 0ุ 0ุ 0]]}
```

ุชู ุงูุขู ุชุจุทูู ุงูุฌููุชูู ุงูุฃููู ูุงูุซุงูุซุฉ ุจู `0` ูุฃูููุง ุฃูุตุฑ.

### ุงูุจุชุฑ Truncation

ูู ูุงุญูุฉ ุฃุฎุฑู ูู ุงูุทููุ ูุฏ ูููู ุงูุชุณูุณู ุทููููุง ุฌุฏูุง ุจุงููุณุจุฉ ูููููุฐุฌ ููุชุนุงูู ูุนู. ูู ูุฐู ุงูุญุงูุฉุ ุณุชุญุชุงุฌ ุฅูู ุจุชุฑ ุงูุชุณูุณู ุฅูู ุทูู ุฃูุตุฑ.

ูู ุจุชุนููู ูุนููุฉ `truncation` ุฅูู `True` ูุชูููู ุชุณูุณู ุฅูู ุงูุทูู ุงูุฃูุตู ุงูุฐู ููุจูู ุงููููุฐุฌ:

```py
>>> batch_sentences = [
...     "But what about second breakfast?",
...     "Don't think he knows about second breakfast, Pip.",
...     "What about elevensies?",
... ]
>>> encoded_input = tokenizer(batch_sentences, padding=True, truncation=True)
>>> print(encoded_input)
{'input_ids': [[101, 1252, 1184, 1164, 1248, 6462, 136, 102, 0, 0, 0, 0, 0, 0, 0],
               [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102],
               [101, 1327, 1164, 5450, 23434, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0]],
 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0ุ 0ุ 0ุ 0ุ 0]]ุ
 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0ุ 0ุ 0ุ 0],
                    [1, 1, 1, 1, 1, 1, 1ุ 1ุ 1ุ 1ุ 1ุ 1ุ 1ุ 1ุ 1ุ 1],
                    [1ุ 1ุ 1ุ 1ุ 1ุ 1ุ 1ุ 0ุ 0ุ 0ุ 0ุ 0ุ 0ุ 0ุ 0ุ 0]]}
```

<Tip>
<Tip>

ุชุญูู ูู ุฏููู ุงูููุงููู [Padding and truncation](./pad_truncation) ููุนุฑูุฉ ุงููุฒูุฏ ุญูู ูุณุงุฏุงุช ูุญุฌุฌ ุงูุจุชุฑ ุงููุฎุชููุฉ.

</Tip>

### ุจูุงุก ุงูุชูุณุฑุงุช Build tensors

ุฃุฎูุฑูุงุ ุชุฑูุฏ ุฃู ูููู ููุนุฑููู ุงูุฑููุฒ ุจุฅุฑุฌุงุน ุงูุชูุณุฑุงุช ุงููุนููุฉ ุงูุชู ูุชู ุชุบุฐูุชูุง ูู ุงููููุฐุฌ.

ูู ุจุชุนููู ูุนููุฉ `return_tensors` ุฅูู ุฅูุง `pt` ูู PyTorchุ ุฃู `tf` ูู TensorFlow:

<frameworkcontent>
<pt>

```py
>>> batch_sentences = [
...     "But what about second breakfast?",
...     "Don't think he knows about second breakfast, Pip.",
...     "What about elevensies?",
... ]
>>> encoded_input = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors="pt")
>>> print(encoded_input)
{'input_ids': tensor([[101, 1252, 1184, 1164, 1248, 6462, 136, 102, 0, 0, 0, 0, 0, 0, 0],
                      [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102],
                      [101, 1327, 1164, 5450, 23434, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0]]),
 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),
 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],
                           [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
                           [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}
```
</pt>
<tf>
```py
>>> batch_sentences = [
...     "But what about second breakfast?",
...     "Don't think he knows about second breakfast, Pip.",
...     "What about elevensies?",
... ]
>>> encoded_input = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors="tf")
>>> print(encoded_input)
{'input_ids': <tf.Tensor: shape=(2, 9), dtype=int32
## ุฑุคูุฉ ุงูููุจููุชุฑ

ุจุงููุณุจุฉ ูููุงู ุฑุคูุฉ ุงูููุจููุชุฑุ ุณุชุญุชุงุฌ ุฅูู ูุนุงูุฌ ุตูุฑ [image processor](main_classes/image_processor) ูุฅุนุฏุงุฏ ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจู ููููุฐุฌุฉ. ุชุชููู ูุนุงูุฌุฉ ุงูุตูุฑ ุงููุณุจูุฉ ูู ุนุฏุฉ ุฎุทูุงุช ูุชุญููู ุงูุตูุฑ ุฅูู ุงูุฅุฏุฎุงู ุงูุฐู ูุชููุนู ุงููููุฐุฌ. ูุชุดูู ูุฐู ุงูุฎุทูุงุชุ ุนูู ุณุจูู ุงููุซุงู ูุง ุงูุญุตุฑุ ุชุบููุฑ ุงูุญุฌู ูุงูุชุทุจูุน ูุชุตุญูุญ ููุงุฉ ุงูุฃููุงู ูุชุญููู ุงูุตูุฑ ุฅูู ุชูุณูุฑุงุช.

<Tip>

ุนุงุฏุฉ ูุง ุชุชุจุน ูุนุงูุฌุฉ ุงูุตูุฑ ุงููุณุจูุฉ ุดููุงู ูู ุฃุดูุงู ุฒูุงุฏุฉ ุงูุตูุฑ. ูู ูู ูุนุงูุฌุฉ ุงูุตูุฑ ุงููุณุจูุฉ ูุฒูุงุฏุฉ ุงูุตูุฑ ุชุญููู ุจูุงูุงุช ุงูุตูุฑุ ูููููุง ุชุฎุฏู ุฃุบุฑุงุถูุง ูุฎุชููุฉ:

* ุชุบููุฑ ุงูุตูุฑ ุนู ุทุฑูู ุฒูุงุฏุฉ ุงูุตูุฑ ุจุทุฑููุฉ ูููู ุฃู ุชุณุงุนุฏ ูู ููุน ุงูุฅูุฑุงุท ูู ุงูุชุฌููุฒ ูุฒูุงุฏุฉ ูุชุงูุฉ ุงููููุฐุฌ. ููููู ุฃู ุชููู ูุจุฏุนูุง ูู ููููุฉ ุฒูุงุฏุฉ ุจูุงูุงุชู - ุถุจุท ุงูุณุทูุน ูุงูุฃููุงูุ ูุงููุญุงุตููุ ูุงูุฏูุฑุงูุ ุชุบููุฑ ุงูุญุฌูุ ุงูุชูุจูุฑุ ุฅูุฎ. ููุน ุฐููุ ูู ุญุฐุฑูุง ูู ุนุฏู ุชุบููุฑ ูุนูู ุงูุตูุฑ ุจุงุณุชุฎุฏุงู ุงูุฒูุงุฏุงุช ุงูุฎุงุตุฉ ุจู.
* ุชุถูู ูุนุงูุฌุฉ ุงูุตูุฑ ุงููุณุจูุฉ ุฃู ุชุชุทุงุจู ุงูุตูุฑ ูุน ุชูุณูู ุงูุฅุฏุฎุงู ุงููุชููุน ูููููุฐุฌ. ุนูุฏ ุถุจุท ูููุฐุฌ ุฑุคูุฉ ุงูููุจููุชุฑ ุจุฏูุฉุ ูุฌุจ ูุนุงูุฌุฉ ุงูุตูุฑ ุจุงูุถุจุท ููุง ูุงูุช ุนูุฏ ุชุฏุฑูุจ ุงููููุฐุฌ ูุฃูู ูุฑุฉ.

ููููู ุงุณุชุฎุฏุงู ุฃู ููุชุจุฉ ุชุฑูุฏูุง ูุฒูุงุฏุฉ ุงูุตูุฑ. ููุนุงูุฌุฉ ุงูุตูุฑ ุงููุณุจูุฉุ ุงุณุชุฎุฏู `ImageProcessor` ุงููุฑุชุจุท ุจุงููููุฐุฌ.

</Tip>

ูู ุจุชุญููู ูุฌููุนุฉ ุจูุงูุงุช [food101](https://huggingface.co/datasets/food101) (ุฑุงุฌุน ุฏููู ๐ค [Datasets tutorial](https://huggingface.co/docs/datasets/load_hub) ููุฒูุฏ ูู ุงูุชูุงุตูู ุญูู ููููุฉ ุชุญููู ูุฌููุนุฉ ุจูุงูุงุช) ููุนุฑูุฉ ููู ููููู ุงุณุชุฎุฏุงู ูุนุงูุฌ ุงูุตูุฑ ูุน ูุฌููุนุงุช ุจูุงูุงุช ุฑุคูุฉ ุงูููุจููุชุฑ:

<Tip>

ุงุณุชุฎุฏู ูุนููุฉ `split` ูู ๐ค Datasets ูุชุญููู ุนููุฉ ุตุบูุฑุฉ ููุท ูู ุงูุงููุณุงู ุงูุชุฏุฑูุจู ูุธุฑูุง ูุฃู ูุฌููุนุฉ ุงูุจูุงูุงุช ูุจูุฑุฉ ุฌุฏูุง!

</Tip>

```py
>>> from datasets import load_dataset

>>> dataset = load_dataset("food101", split="train[:100]")
```

ุจุนุฏ ุฐููุ ุงูู ูุธุฑุฉ ุนูู ุงูุตูุฑุฉ ูุน ููุฒุฉ ๐ค Datasets [`Image`](https://huggingface.co/docs/datasets/package_reference/main_classes?highlight=image#datasets.Image):

```py
>>> dataset[0]["image"]
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/vision-preprocess-tutorial.png"/>
</div>

ูู ุจุชุญููู ูุนุงูุฌ ุงูุตูุฑ ุจุงุณุชุฎุฏุงู [`AutoImageProcessor.from_pretrained`]:

```py
>>> from transformers import AutoImageProcessor

>>> image_processor = AutoImageProcessor.from_pretrained("google/vit-base-patch16-224")
```

ุฃููุงูุ ุฏุนูุง ูุถูู ุจุนุถ ุงูุฒูุงุฏุงุช ุฅูู ุงูุตูุฑ. ููููู ุงุณุชุฎุฏุงู ุฃู ููุชุจุฉ ุชูุถููุงุ ูููู ูู ูุฐุง ุงูุฏูููุ ุณูุณุชุฎุฏู ูุญุฏุฉ [`transforms`](https://pytorch.org/vision/stable/transforms.html) ูู torchvision. ุฅุฐุง ููุช ููุชููุง ุจุงุณุชุฎุฏุงู ููุชุจุฉ ุฒูุงุฏุฉ ุจูุงูุงุช ุฃุฎุฑูุ ูุชุนุฑู ุนูู ููููุฉ ุงูููุงู ุจุฐูู ูู [ุฏูุงุชุฑ Albumentations](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification_albumentations.ipynb) ุฃู [ุฏูุงุชุฑ Kornia](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification_kornia.ipynb).

1. ููุง ูุณุชุฎุฏู [`Compose`](https://pytorch.org/vision/master/generated/torchvision.transforms.Compose.html) ูุฑุจุท ุจุนุถ ุงูุชุญููุงุช ูุนูุง - [`RandomResizedCrop`](https://pytorch.org/vision/main/generated/torchvision.transforms.RandomResizedCrop.html) ู [`ColorJitter`](https://pytorch.org/vision/main/generated/torchvision.transforms.ColorJitter.html).
ูุงุญุธ ุฃูู ุจุงููุณุจุฉ ูุชุบููุฑ ุงูุญุฌูุ ูููููุง ุงูุญุตูู ุนูู ูุชุทูุจุงุช ุญุฌู ุงูุตูุฑุฉ ูู `image_processor`. ุจุงููุณุจุฉ ูุจุนุถ ุงูููุงุฐุฌุ ููุชููุน ุงุฑุชูุงุน ูุนุฑุถ ูุญุฏุฏุงู ุจุงูุถุจุทุ ุจูููุง ุจุงููุณุจุฉ ููููุงุฐุฌ ุงูุฃุฎุฑูุ ูุชู ุชุญุฏูุฏ `shortest_edge` ููุท.

```py
>>> from torchvision.transforms import RandomResizedCrop, ColorJitter, Compose

>>> size = (
...     image_processor.size["shortest_edge"]
...     if "shortest_edge" in image_processor.size
...     else (image_processor.size["height"], image_processor.size["width"])
... )

>>> _transforms = Compose([RandomResizedCrop(size), ColorJitter(brightness=0.5, hue=0.5)])
```

2. ููุจู ุงููููุฐุฌ [`pixel_values`](model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel.forward.pixel_values)
ูุฅุฏุฎุงู ูู. ูููู ูู `ImageProcessor` ุงูุชุนุงูู ูุน ุชุทุจูุน ุงูุตูุฑุ ูุชูููุฏ ุงูุชูุณูุฑุงุช ุงูููุงุณุจุฉ.
ูู ุจุฅูุดุงุก ุฏุงูุฉ ุชุฌูุน ุจูู ุฒูุงุฏุฉ ุงูุตูุฑ ููุนุงูุฌุฉ ุงูุตูุฑ ุงููุณุจูุฉ ููุฌููุนุฉ ูู ุงูุตูุฑ ูุชูููุฏ `pixel_values`:

```py
>>> def transforms(examples):
...     images = [_transforms(img.convert("RGB")) for img in examples["image"]]
...     examples["pixel_values"] = image_processor(images, do_resize=False, return_tensors="pt")["pixel_values"]
...     return examples
```

<Tip>

ูู ุงููุซุงู ุฃุนูุงูุ ูููุง ุจุชุนููู `do_resize=False` ูุฃููุง ูููุง ุจุงููุนู ุจุชุบููุฑ ุญุฌู ุงูุตูุฑ ูู ุชุญููู ุฒูุงุฏุฉ ุงูุตูุฑุ
ูุงุณุชูุฏูุง ูู ุฎุงุตูุฉ `size` ูู `image_processor` ุงูููุงุณุจ. ุฅุฐุง ูู ุชูู ุจุชุบููุฑ ุญุฌู ุงูุตูุฑ ุฃุซูุงุก ุฒูุงุฏุฉ ุงูุตูุฑุ
ูุงุชุฑู ูุฐุง ุงููุนููุฉ. ุจุดูู ุงูุชุฑุงุถูุ ุณุชุชุนุงูู `ImageProcessor` ูุน ุชุบููุฑ ุงูุญุฌู.

ุฅุฐุง ููุช ุชุฑุบุจ ูู ุชุทุจูุน ุงูุตูุฑ ูุฌุฒุก ูู ุชุญููู ุฒูุงุฏุฉ ุงูุตูุฑุ ูุงุณุชุฎุฏู ููู `image_processor.image_mean`ุ
ู `image_processor.image_std`.
</Tip>

3. ุซู ุงุณุชุฎุฏู ๐ค Datasets[`~datasets.Dataset.set_transform`] ูุชุทุจูู ุงูุชุญููุงุช ุฃุซูุงุก ุงูุชููู:
```py
>>> dataset.set_transform(transforms)
```

4. ุงูุขู ุนูุฏ ุงููุตูู ุฅูู ุงูุตูุฑุฉุ ุณุชูุงุญุธ ุฃู ูุนุงูุฌ ุงูุตูุฑ ูุฏ ุฃุถุงู `pixel_values`. ููููู ุชูุฑูุฑ ูุฌููุนุฉ ุงูุจูุงูุงุช ุงููุนุงูุฌุฉ ุฅูู ุงููููุฐุฌ ุงูุขู!

```py
>>> dataset[0].keys()
```

ููุฐุง ุชุจุฏู ุงูุตูุฑุฉ ุจุนุฏ ุชุทุจูู ุงูุชุญููุงุช. ุชู ุงูุชุตุงุต ุงูุตูุฑุฉ ุจุดูู ุนุดูุงุฆู ูุชุฎุชูู ุฎุตุงุฆุต ุงูุฃููุงู ุจูุง.

```py
>>> import numpy as np
>>> import matplotlib.pyplot as plt

>>> img = dataset[0]["pixel_values"]
>>> plt.imshow(img.permute(1, 2, 0))
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/preprocessed_image.png"/>
</div>

<Tip>

ุจุงููุณุจุฉ ููููุงู ูุซู ุงููุดู ุนู ุงูุฃุดูุงุกุ ูุงูุชุฌุฒุฆุฉ ุงูุฏูุงููุฉุ ูุงูุชุฌุฒุฆุฉ ุงููุซุงููุฉุ ูุงูุชุฌุฒุฆุฉ ุงูุดุงููุฉุ ูููุฑ `ImageProcessor`
ุฃุณุงููุจ ูุง ุจุนุฏ ุงููุนุงูุฌุฉ. ุชุญูู ูุฐู ุงูุฃุณุงููุจ ุงููุฎุฑุฌุงุช ุงูุฎุงู ูููููุฐุฌ ุฅูู ุชูุจุคุงุช ุฐุงุช ูุนูู ูุซู ุตูุงุฏูู ุงูุญุฏูุฏุ
ุฃู ุฎุฑุงุฆุท ุงูุชุฌุฒุฆุฉ.

</Tip>

### ุงูุญุดู Pad

ูู ุจุนุถ ุงูุญุงูุงุชุ ุนูู ุณุจูู ุงููุซุงูุ ุนูุฏ ุถุจุท ูููุฐุฌ [DETR](./model_doc/detr) ุจุฏูุฉุ ูููู ุงููููุฐุฌ ุจุชุทุจูู ุฒูุงุฏุฉ ุงููููุงุณ ูู ููุช ุงูุชุฏุฑูุจ. ูุฏ ูุชุณุจุจ ุฐูู ูู ุงุฎุชูุงู ุฃุญุฌุงู ุงูุตูุฑ ูู ุฏูุนุฉ ูุงุญุฏุฉ. ููููู ุงุณุชุฎุฏุงู [`DetrImageProcessor.pad`]
ูู [`DetrImageProcessor`] ูุชุนุฑูู `collate_fn` ูุฎุตุต ูุชุฌููุน ุงูุตูุฑ ูุนูุง.

```py
>>> def collate_fn(batch):
...     pixel_values = [item["pixel_values"] for item in batch]
...     encoding = image_processor.pad(pixel_values, return_tensors="pt")
...     labels = [item["labels"] for item in batch]
...     batch = {}
...     batch["pixel_values"] = encoding["pixel_values"]
...     batch["pixel_mask"] = encoding["pixel_mask"]
...     batch["labels"] = labels
...     return batch
```

## ูุชุนุฏุฏ ุงููุณุงุฆุท Mulimodal

ุจุงููุณุจุฉ ููููุงู ุงูุชู ุชุชุถูู ุฅุฏุฎุงูุงุช ูุชุนุฏุฏุฉ ุงููุณุงุฆุทุ ุณุชุญุชุงุฌ ุฅูู ูุนุงูุฌ [processor](main_classes/processors) ูุฅุนุฏุงุฏ ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจู ููููุฐุฌุฉ. ูุฑุจุท ุงููุนุงูุฌ ุจูู ูุงุฆููู ูููุนุงูุฌุฉ ูุซู ุงูุฑููุฒ ุงููููุฒุฉ ููุณุชุฎุฑุฌ ุงูููุฒุงุช.

ูู ุจุชุญููู ูุฌููุนุฉ ุจูุงูุงุช [LJ Speech](https://huggingface.co/datasets/lj_speech) (ุฑุงุฌุน ุฏููู ๐ค [Datasets tutorial](https://huggingface.co/docs/datasets/load_hub) ููุฒูุฏ ูู ุงูุชูุงุตูู ุญูู ููููุฉ ุชุญููู ูุฌููุนุฉ ุจูุงูุงุช) ููุนุฑูุฉ ููู ููููู ุงุณุชุฎุฏุงู ูุนุงูุฌ ููุชุนุฑู ุงูุชููุงุฆู ุนูู ุงูููุงู (ASR):

```py
>>> from datasets import load_dataset

>>> lj_speech = load_dataset("lj_speech", split="train")
```

ุจุงููุณุจุฉ ูู ASRุ ูุฃูุช ุชุฑูุฒ ุจุดูู ุฃุณุงุณู ุนูู `audio` ู `text` ูุฐุง ููููู ุฅุฒุงูุฉ ุงูุฃุนูุฏุฉ ุงูุฃุฎุฑู:

```py
>>> lj_speech = lj_speech.map(remove_columns=["file", "id", "normalized_text"])
```

ุงูุขู ุงูู ูุธุฑุฉ ุนูู ุฃุนูุฏุฉ `audio` ู `text`:
```py
>>> lj_speech = lj_speech.map(remove_columns=["file", "id", "normalized_text"])
```

ุงูุขู ุงูู ูุธุฑุฉ ุนูู ุฃุนูุฏุฉ `audio` ู `text`:

```py
>>> lj_speech[0]["audio"]
{'array': array([-7.3242188e-04, -7.6293945e-04, -6.4086914e-04, ...,
         7.3242188e-04,  2.1362305e-04,  6.1035156e-05], dtype=float32),
 'path': '/root/.cache/huggingface/datasets/downloads/extracted/917ece08c95cf0c4115e45294e3cd0dee724a1165b7fc11798369308a465bd26/LJSpeech-1.1/wavs/LJ001-0001.wav',
 'sampling_rate': 22050}

>>> lj_speech[0]["text"]
'Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition'
```

ุชุฐูุฑ ุฃูู ูุฌุจ ุนููู ุฏุงุฆููุง [ุฅุนุงุฏุฉ ุฃุฎุฐ ุงูุนููุงุช](preprocessing#audio) ููุนุฏู ุฃุฎุฐ ุงูุนููุงุช ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงูุตูุชูุฉ ุงูุฎุงุตุฉ ุจู ููุทุงุจูุฉ ูุนุฏู ุฃุฎุฐ ุงูุนููุงุช ูู ูุฌููุนุฉ ุงูุจูุงูุงุช ุงููุณุชุฎุฏูุฉ ูุชุฏุฑูุจ ุงููููุฐุฌ ูุณุจููุง!

```py
>>> lj_speech = lj_speech.cast_column("audio", Audio(sampling_rate=16_000))
```

ูู ุจุชุญููู ูุนุงูุฌ ุจุงุณุชุฎุฏุงู [`AutoProcessor.from_pretrained`]:

```py
>>> from transformers import AutoProcessor

>>> processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")
```

1. ูู ุจุฅูุดุงุก ุฏุงูุฉ ููุนุงูุฌุฉ ุจูุงูุงุช ุงูุตูุช ุงูููุฌูุฏุฉ ูู `array` ุฅูู `input_values`ุ ูุฑููุฒ `text` ุฅูู `labels`. ูุฐู ูู ุงููุฏุฎูุงุช ูููููุฐุฌ:

```py
>>> def prepare_dataset(example):
...     audio = example["audio"]

...     example.update(processor(audio=audio["array"], text=example["text"], sampling_rate=16000))

...     return example
```

2. ูู ุจุชุทุจูู ุฏุงูุฉ `prepare_dataset` ุนูู ุนููุฉ:

```py
>>> prepare_dataset(lj_speech[0])
```

ููุฏ ุฃุถุงู ุงููุนุงูุฌ ุงูุขู `input_values` ู `labels`ุ ูุชู ุฃูุถูุง ุฅุนุงุฏุฉ ุฃุฎุฐ ุงูุนููุงุช ููุนุฏู ุฃุฎุฐ ุงูุนููุงุช ุจุดูู ุตุญูุญ ุฅูู 16 ูููู ูุฑุชุฒ. ููููู ุชูุฑูุฑ ูุฌููุนุฉ ุงูุจูุงูุงุช ุงููุนุงูุฌุฉ ุฅูู ุงููููุฐุฌ ุงูุขู!